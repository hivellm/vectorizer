# Vectorizer Server Configuration File
# This is a comprehensive YAML configuration file that allows you to customize
# every aspect of the Vectorizer server after build. Copy this file to config.yml
# and modify the settings according to your needs.

# =============================================================================
# FILE WATCHER CONFIGURATION
# =============================================================================
file_watcher:
  enabled: true
  debounce_delay_ms: 1000
  min_file_size_bytes: 1
  max_file_size_bytes: 10485760  # 10MB
  hash_validation_enabled: true
  grpc_enabled: true
  collection_name: "workspace-files"

# Projects configuration (empty for now)
projects: []

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
server:
  # Basic server settings
  host: "127.0.0.1"          # Server bind address (127.0.0.1 for internal, 0.0.0.0 for cloud)
  port: 15001                # Server port (default: 15001, above 15000 as requested)
  grpc_port: 15003           # GRPC server port (default: 15003)
  mcp_port: 15002            # MCP server port (default: 15002)
  workers: 4                 # Number of async workers (default: 4)
  max_connections: 1000      # Maximum concurrent connections (default: 1000)
  timeout_seconds: 30        # Request timeout in seconds (default: 30)

  # Server identification
  name: "Vectorizer Server"  # Server instance name
  version: "1.0.0"           # Server version (for API responses)
  environment: "production"  # Environment (development/production/staging)

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================
security:
  # API Key Management
  require_api_keys: true     # Enforce API key authentication for all operations
  api_key_length: 32         # Generated API key length (default: 32)
  api_key_prefix: "vk_"      # API key prefix (default: "vk_")

  # Rate Limiting (per API key)
  rate_limiting:
    enabled: true
    requests_per_minute: 1000  # Max requests per minute per API key
    burst_limit: 100           # Burst limit for rate limiting

  # CORS Configuration (for cloud deployments)
  cors:
    enabled: true
    allowed_origins:           # List of allowed origins
      - "https://your-app.com"
      - "https://app.your-domain.com"
    allowed_methods:           # HTTP methods to allow
      - "GET"
      - "POST"
      - "PUT"
      - "DELETE"
      - "PATCH"
    allowed_headers:           # Headers to allow
      - "Content-Type"
      - "Authorization"
      - "X-API-Key"
    allow_credentials: true    # Allow credentials in CORS

  # Audit Logging
  audit:
    enabled: true
    log_operations: true       # Log all operations with API key reference
    log_errors: true           # Log authentication failures and errors
    retention_days: 30         # Audit log retention in days
    max_log_size_mb: 100       # Maximum audit log size before rotation

# =============================================================================
# DASHBOARD CONFIGURATION
# =============================================================================
dashboard:
  enabled: true               # Enable localhost dashboard
  bind_address: "127.0.0.1"   # Dashboard bind address (always localhost for security)
  port: 15002                 # Dashboard port (default: server.port + 1 = 15002)
  theme: "auto"               # UI theme: light/dark/auto
  locale: "en"                # Interface language: en/pt/es/fr
  session_timeout_minutes: 60 # Dashboard session timeout

  # Dashboard features
  features:
    api_key_management: true  # Allow API key creation/deletion
    collection_management: true # Allow collection operations
    vector_inspection: true   # Allow vector browsing (read-only)
    search_preview: true      # Allow search demonstrations
    server_monitoring: true   # Show server metrics
    audit_logs: true          # Show audit logs

# =============================================================================
# NETWORK CONFIGURATION
# =============================================================================
network:
  mode: "internal"            # Network mode: internal/cloud

  # Internal mode settings (localhost only)
  internal:
    bind_address: "127.0.0.1"
    allowed_clients:           # Additional allowed IPs (for internal networks)
      - "192.168.1.0/24"

  # Cloud mode settings (external access)
  cloud:
    bind_address: "0.0.0.0"
    tls:
      enabled: false          # Enable TLS/HTTPS
      cert_path: "/path/to/cert.pem"
      key_path: "/path/to/key.pem"
    load_balancer: false      # Running behind load balancer
    trusted_proxies:          # Trusted proxy IPs
      - "10.0.0.0/8"

# =============================================================================
# PERFORMANCE CONFIGURATION
# =============================================================================
performance:
  # Memory Management
  memory:
    max_usage_gb: 32.0        # Maximum memory usage (GB)
    gc_threshold_mb: 1024     # Garbage collection threshold
    memory_pool_size_mb: 512  # Memory pool size for vectors

  # Threading and Concurrency
  threading:
    max_blocking_threads: 512 # Maximum blocking threads
    async_runtime_threads: 4  # Async runtime worker threads

  # Parallel Processing Configuration
  parallel:
    embedding_threads: 8      # Number of threads for embedding (default: CPU cores / 2)
    indexing_threads: 4       # Number of threads for indexing (default: CPU cores / 4)
    blas_threads: 1           # BLAS threads per worker (keep at 1 to avoid oversubscription)
    channel_size: 10000       # Channel buffer size for pipeline
    batch_size: 128           # Default batch size for processing

  # Caching
  cache:
    enabled: true
    vector_cache_size_mb: 256 # Vector data cache size
    query_cache_size_mb: 128  # Query result cache size
    cache_ttl_seconds: 3600   # Cache TTL (1 hour)
    cache_compression: true   # Compress cached data

  # Embedding Cache Configuration
  embedding_cache:
    enabled: true
    cache_dir: "./cache/embeddings"  # Embedding cache directory
    max_size_gb: 10           # Maximum cache size (10GB)
    use_mmap: true            # Use memory-mapped files for zero-copy loading
    num_shards: 16            # Number of cache shards for parallel access

  # Resource Limits
  limits:
    max_collections: 100      # Maximum number of collections
    max_vectors_per_collection: 10000000  # Max vectors per collection (10M)
    max_payload_size_kb: 1024 # Maximum payload size (1MB)
    max_batch_size: 1000      # Maximum batch operation size

# =============================================================================
# BATCH OPERATIONS CONFIGURATION - Phase 6
# =============================================================================
batch_operations:
  # Basic batch settings
  max_batch_size: 1000        # Maximum vectors per batch operation
  max_memory_usage_mb: 512    # Maximum memory usage for batch operations
  parallel_workers: 4         # Number of parallel workers for processing
  chunk_size: 100             # Size of chunks for streaming large batches
  
  # Operation behavior
  atomic_by_default: true     # Whether operations should be atomic by default
  progress_reporting: true    # Whether to report progress during long operations
  
  # Error handling
  error_retry_attempts: 3     # Number of retry attempts for failed operations
  error_retry_delay_ms: 100   # Delay between retry attempts in milliseconds
  operation_timeout_seconds: 300 # Timeout for individual batch operations (5 minutes)
  
  # Performance and monitoring
  enable_metrics: true        # Whether to enable performance metrics collection
  max_concurrent_batches: 10  # Maximum concurrent batch operations
  
  # Compression settings
  enable_compression: false   # Whether to enable compression for large payloads
  compression_threshold_bytes: 1048576 # Compression threshold (1MB)
  
  # Performance presets
  presets:
    # High-performance configuration for production
    production:
      max_batch_size: 10000
      max_memory_usage_mb: 2048
      parallel_workers: 8
      chunk_size: 500
      atomic_by_default: true
      progress_reporting: false  # Disable for production performance
      error_retry_attempts: 5
      error_retry_delay_ms: 50
      operation_timeout_seconds: 600  # 10 minutes
      enable_metrics: true
      max_concurrent_batches: 20
      enable_compression: true
      compression_threshold_bytes: 524288  # 512KB
    
    # Development configuration with verbose logging
    development:
      max_batch_size: 100
      max_memory_usage_mb: 128
      parallel_workers: 2
      chunk_size: 10
      atomic_by_default: true
      progress_reporting: true
      error_retry_attempts: 1
      error_retry_delay_ms: 1000
      operation_timeout_seconds: 60  # 1 minute
      enable_metrics: true
      max_concurrent_batches: 3
      enable_compression: false
      compression_threshold_bytes: 1048576
    
    # Testing configuration
    testing:
      max_batch_size: 10
      max_memory_usage_mb: 64
      parallel_workers: 1
      chunk_size: 5
      atomic_by_default: true
      progress_reporting: false
      error_retry_attempts: 0
      error_retry_delay_ms: 10
      operation_timeout_seconds: 30
      enable_metrics: false
      max_concurrent_batches: 1
      enable_compression: false
      compression_threshold_bytes: 1024

# =============================================================================
# COMPRESSION CONFIGURATION
# =============================================================================
compression:
  # Global compression settings
  enabled: true               # Enable compression globally
  algorithm: "lz4"            # Compression algorithm: lz4/none
  default_threshold_bytes: 1024 # Default compression threshold

  # Per-operation compression
  operations:
    api_responses: true       # Compress API responses
    persistence: true         # Compress persisted data
    network: true             # Compress network traffic

  # Algorithm-specific settings
  lz4:
    compression_level: 1      # LZ4 compression level (1-16, 1=fastest)
    checksum: false           # Enable LZ4 checksums

# =============================================================================
# PERSISTENCE CONFIGURATION
# =============================================================================
persistence:
  # Storage settings
  enabled: true
  storage_path: "./data"      # Base storage directory
  auto_backup: true           # Automatic backups
  backup_interval_hours: 24   # Backup frequency

  # Binary serialization
  format: "bincode"           # Serialization format: bincode/json
  compression: true           # Compress persisted data

  # Recovery settings
  recovery:
    auto_recover: true        # Auto-recover on startup
    max_recovery_time_seconds: 300 # Maximum recovery time
    recovery_parallelism: 4   # Parallel recovery threads

# =============================================================================
# DEFAULT COLLECTION CONFIGURATION
# =============================================================================
collections:
  defaults:
    # Vector settings
    dimension: 512            # Default vector dimension
    metric: "cosine"          # Default distance metric: cosine/euclidean/dot_product

    # Quantization (memory optimization)
    quantization:
      type: "pq"              # Quantization type: none/pq/sq/binary
      pq:
        n_centroids: 256      # PQ centroids (256 recommended)
        n_subquantizers: 8    # PQ sub-quantizers
      sq:
        bits: 8               # SQ bits per dimension
      binary:
        enabled: false        # Use binary quantization

    # Embedding settings
    embedding:
      model: "native_bow"     # Default embedding: native_bow/native_hash/native_ngram/bm25/real_model/onnx_model
      bow:
        vocab_size: 50000     # BOW vocabulary size
        max_sequence_length: 512 # Maximum sequence length
      hash:
        hash_size: 1000000    # Feature hash size
      ngram:
        ngram_range: [1, 3]   # N-gram range [min, max]
        vocab_size: 100000    # N-gram vocabulary size
      bm25:
        k1: 1.5               # BM25 k1 parameter
        b: 0.75               # BM25 b parameter
      real_model:
        model_type: "MiniLMMultilingual"  # Real model type
        cache_dir: "./models" # Model cache directory
      onnx_model:
        model_type: "MiniLMMultilingual384"  # ONNX model type
        batch_size: 128       # Batch size for inference
        use_int8: true        # Enable INT8 quantization
        num_threads: 1        # Threads per worker

    # Compression settings
    compression:
      enabled: true
      threshold_bytes: 1024   # Compress payloads > 1KB
      algorithm: "lz4"

    # Index settings (HNSW)
    index:
      type: "hnsw"            # Index type: hnsw/optimized_hnsw
      hnsw:
        m: 16                 # HNSW connections per layer
        ef_construction: 200  # Construction search width
        ef_search: 64         # Query search width
      optimized_hnsw:
        batch_size: 1000      # Batch insertion size
        parallel: true        # Enable parallel construction
        initial_capacity: 100000  # Pre-allocation size
        max_connections: 16   # Maximum connections per layer
        max_connections_0: 32 # Connections for layer 0

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
logging:
  # Log levels
  level: "info"               # Global log level: error/warn/info/debug/trace
  format: "json"              # Log format: json/text
  
  # Request/Response logging
  log_requests: true          # Log all requests
  log_responses: false        # Log responses (can be verbose)
  log_errors: true            # Log errors
  log_connections: true       # Log connection events

  # Log outputs
  outputs:
    console:
      enabled: true
      level: "info"
    file:
      enabled: true
      path: "./.logs/vectorizer-server-{date}.log"
      level: "debug"
      max_size_mb: 100
      max_files: 5

  # Module-specific log levels
  modules:
    vectorizer::api: "debug"
    vectorizer::auth: "info"
    vectorizer::compression: "warn"
    vectorizer::dashboard: "info"

# =============================================================================
# MONITORING CONFIGURATION
# =============================================================================
monitoring:
  # Health checks
  health_check:
    enabled: true
    interval_seconds: 30      # Health check frequency
    failure_threshold: 3      # Failures before marking unhealthy

  # Metrics collection
  metrics:
    enabled: true
    collection_interval_seconds: 60 # Metrics collection frequency

    # Metrics to collect
    collections:
      - vector_count
      - index_size
      - memory_usage
      - query_latency
      - compression_ratio

  # External monitoring integration
  external:
    prometheus:
      enabled: false
      port: 9090
      path: "/metrics"
    statsd:
      enabled: false
      host: "localhost"
      port: 8125
      prefix: "vectorizer"

# =============================================================================
# INTEGRATION CONFIGURATION
# =============================================================================
integrations:
  # LangChain integration
  langchain:
    enabled: true
    vectorstore_class: "VectorizerStore"
    embedding_function: "native_bow"

  # Aider integration
  aider:
    enabled: true
    hooks_enabled: true
    auto_chunking: true
    chunk_size: 512

  # External API integrations
  external_apis:
    openai:
      enabled: false          # Use external OpenAI (overrides native embeddings)
      api_key: "your-key"     # OpenAI API key
      model: "text-embedding-ada-002"
    huggingface:
      enabled: false          # Use HuggingFace models
      api_key: "your-key"
      model: "sentence-transformers/all-MiniLM-L6-v2"

# =============================================================================
# DEVELOPMENT/DEBUG CONFIGURATION
# =============================================================================
development:
  debug_mode: false           # Enable debug features
  profile: false              # Enable performance profiling
  trace_requests: false       # Log all incoming requests
  mock_data: false            # Use mock data for testing

  # Development tools
  tools:
    query_profiler: false     # Profile query performance
    memory_profiler: false    # Profile memory usage
    request_tracer: false     # Trace request lifecycle

# =============================================================================
# MAINTENANCE CONFIGURATION
# =============================================================================
maintenance:
  # Automatic maintenance
  auto_maintenance:
    enabled: true
    schedule: "0 2 * * *"    # Cron schedule (daily at 2 AM)
    operations:
      - optimize_indexes
      - cleanup_temp_files
      - rotate_logs
      - backup_data

  # Manual maintenance operations
  manual_operations:
    index_optimization: true  # Allow manual index optimization
    data_compaction: true     # Allow data compaction
    cache_invalidation: true  # Allow cache clearing

# =============================================================================
# EXPERIMENTAL FEATURES
# =============================================================================
experimental:
  # Features under development
  features:
    distributed_collections: false  # Multi-node collection sharding
    gpu_acceleration: false         # GPU-accelerated operations
    advanced_quantization: false    # Experimental quantization methods
    federated_search: false         # Cross-server search federation
    hybrid_search: true             # Hybrid sparse+dense search
    svd_embeddings: true            # SVD dimensionality reduction

  # Performance optimizations
  optimizations:
    simd_operations: true          # SIMD vector operations
    async_io: true                 # Asynchronous I/O operations
    zero_copy_serialization: false # Zero-copy data serialization
    fast_tokenization: true        # Ultra-fast tokenization with caching
    onnx_inference: true           # ONNX Runtime for inference
    embedding_cache_mmap: true     # Memory-mapped embedding cache

# =============================================================================
# GRPC CONFIGURATION
# =============================================================================
grpc:
  # GRPC server configuration
  server:
    enabled: true                 # Enable GRPC server
    host: "127.0.0.1"            # GRPC server bind address
    port: 15003                   # GRPC server port (default: server.port + 2)
    max_connections: 100          # Maximum concurrent GRPC connections
    keep_alive_timeout: 30        # Keep-alive timeout in seconds
    max_message_size: 4194304     # Maximum message size (4MB)
    enable_reflection: true       # Enable GRPC reflection for debugging
  
  # GRPC client configuration
  client:
    server_url: "http://127.0.0.1:15003"  # GRPC server URL for clients
    timeout_seconds: 30           # Client request timeout
    retry_attempts: 3             # Number of retry attempts
    retry_delay_ms: 1000          # Delay between retries (milliseconds)
    keep_alive_interval: 30       # Keep-alive interval in seconds
    max_receive_message_length: 4194304  # Max receive message size (4MB)
    max_send_message_length: 4194304     # Max send message size (4MB)
  
  # GRPC service-specific configurations
  services:
    search:
      timeout_seconds: 10         # Search operation timeout
      max_results: 1000           # Maximum search results
    
    list_collections:
      timeout_seconds: 5          # List collections timeout
      max_results: null           # No limit on collection count
    
    get_collection_info:
      timeout_seconds: 5          # Get collection info timeout
      max_results: null           # No limit
    
    embed_text:
      timeout_seconds: 15         # Text embedding timeout
      max_results: null           # No limit
    
    get_indexing_progress:
      timeout_seconds: 5          # Indexing progress timeout
      max_results: null           # No limit
    
    update_indexing_progress:
      timeout_seconds: 5          # Update progress timeout
      max_results: null           # No limit

# =============================================================================
# MCP (MODEL CONTEXT PROTOCOL) CONFIGURATION
# =============================================================================
mcp:
  # Enable MCP server for IDE integration
  enabled: true
  
  # Server configuration
  host: "127.0.0.1"              # MCP server bind address
  port: 15002                    # MCP server port (default: server.port + 1)
  
  # Connection management
  max_connections: 10            # Maximum concurrent MCP connections
  connection_timeout: 300        # Connection timeout in seconds (5 minutes)
  
  # Authentication
  auth_required: true            # Require authentication for MCP access
  allowed_api_keys:              # List of API keys allowed for MCP
    - "mcp_api_key_1"
    - "mcp_api_key_2"
  
  # Server information
  server_info:
    name: "Vectorizer MCP Server"
    version: "1.0.0"
    description: "Model Context Protocol server for Vectorizer vector database"
    protocol_version: "2024-11-05"
    capabilities:
      tools: true
      resources: true
      prompts: false
      logging: true
  
  # Available MCP tools
  tools:
    - name: "search_vectors"
      description: "Search for similar vectors in a collection"
      input_schema:
        type: "object"
        properties:
          collection:
            type: "string"
            description: "Collection name"
          query:
            type: "string"
            description: "Search query"
          limit:
            type: "integer"
            description: "Maximum number of results"
            default: 10
          threshold:
            type: "number"
            description: "Similarity threshold (0.0-1.0)"
            default: 0.0
        required: ["collection", "query"]
    
    - name: "list_collections"
      description: "List all available collections"
      input_schema:
        type: "object"
        properties: {}
    
    - name: "get_collection_info"
      description: "Get information about a specific collection"
      input_schema:
        type: "object"
        properties:
          collection:
            type: "string"
            description: "Collection name"
        required: ["collection"]
    
    - name: "embed_text"
      description: "Generate embeddings for text using the default embedding model"
      input_schema:
        type: "object"
        properties:
          text:
            type: "string"
            description: "Text to embed"
          model:
            type: "string"
            description: "Embedding model to use (optional)"
        required: ["text"]
    
    - name: "insert_texts"
      description: "Insert vectors into a collection"
      input_schema:
        type: "object"
        properties:
          collection:
            type: "string"
            description: "Collection name"
          vectors:
            type: "array"
            description: "Array of vectors to insert"
            items:
              type: "object"
              properties:
                id:
                  type: "string"
                  description: "Vector ID"
                data:
                  type: "array"
                  description: "Vector data"
                  items:
                    type: "number"
                payload:
                  type: "object"
                  description: "Optional payload data"
        required: ["collection", "vectors"]
    
    - name: "delete_vectors"
      description: "Delete vectors from a collection"
      input_schema:
        type: "object"
        properties:
          collection:
            type: "string"
            description: "Collection name"
          vector_ids:
            type: "array"
            description: "Array of vector IDs to delete"
            items:
              type: "string"
        required: ["collection", "vector_ids"]
    
    - name: "get_vector"
      description: "Get a specific vector by ID"
      input_schema:
        type: "object"
        properties:
          collection:
            type: "string"
            description: "Collection name"
          vector_id:
            type: "string"
            description: "Vector ID"
        required: ["collection", "vector_id"]
    
    - name: "create_collection"
      description: "Create a new collection"
      input_schema:
        type: "object"
        properties:
          name:
            type: "string"
            description: "Collection name"
          dimension:
            type: "integer"
            description: "Vector dimension"
            default: 512
          metric:
            type: "string"
            description: "Distance metric"
            enum: ["euclidean", "cosine", "dot_product"]
            default: "cosine"
          embedding_model:
            type: "string"
            description: "Embedding model to use"
            default: "bm25"
        required: ["name"]
    
    - name: "delete_collection"
      description: "Delete a collection"
      input_schema:
        type: "object"
        properties:
          name:
            type: "string"
            description: "Collection name"
        required: ["name"]
    
    - name: "get_database_stats"
      description: "Get database statistics"
      input_schema:
        type: "object"
        properties: {}
    
    - name: "get_indexing_progress"
      description: "Get indexing progress for collections"
      input_schema:
        type: "object"
        properties:
          collection:
            type: "string"
            description: "Collection name (optional, returns all if not specified)"
    
    - name: "workspace_search"
      description: "Search across workspace collections"
      input_schema:
        type: "object"
        properties:
          query:
            type: "string"
            description: "Search query"
          workspace:
            type: "string"
            description: "Workspace name (optional)"
          limit:
            type: "integer"
            description: "Maximum number of results"
            default: 10
        required: ["query"]
  
  # Available MCP resources
  resources:
    - uri: "vectorizer://collections"
      name: "Collections"
      description: "List of all collections in the vector database"
      mime_type: "application/json"
    
    - uri: "vectorizer://stats"
      name: "Database Statistics"
      description: "Current database statistics and performance metrics"
      mime_type: "application/json"
    
    - uri: "vectorizer://workspace/{name}"
      name: "Workspace Information"
      description: "Information about a specific workspace"
      mime_type: "application/json"
    
    - uri: "vectorizer://collection/{name}"
      name: "Collection Details"
      description: "Detailed information about a specific collection"
      mime_type: "application/json"
  
  # Performance settings
  performance:
    # Enable connection pooling
    connection_pooling: true
    
    # Maximum message size (bytes)
    max_message_size: 1048576    # 1MB
    
    # Heartbeat interval (seconds)
    heartbeat_interval: 30
    
    # Cleanup interval for inactive connections (seconds)
    cleanup_interval: 300         # 5 minutes
    
    # Request timeout (seconds)
    request_timeout: 60
    
    # Enable compression for large responses
    enable_compression: true
  
  # Logging for MCP
  logging:
    level: "info"                 # MCP-specific log level
    log_requests: true            # Log all MCP requests
    log_responses: false          # Log MCP responses (can be verbose)
    log_errors: true              # Log MCP errors
    log_connections: true         # Log connection events
    log_file: "./.logs/vectorizer-mcp-server-{date}.log"    # MCP-specific log file

# =============================================================================
# WORKSPACE CONFIGURATION
# =============================================================================
workspace:
  # Enable workspace functionality
  enabled: true
  
  # Default workspace file
  default_workspace_file: "./vectorize-workspace.yml"
  
  # Workspace processing settings
  processing:
    parallel_processing: true
    max_concurrent_projects: 6
    max_concurrent_collections: 12
    
    # File processing
    file_processing:
      batch_size: 100
      max_file_size_mb: 10
      skip_hidden_files: true
      skip_binary_files: true
    
    # Memory management
    memory:
      max_memory_usage_gb: 16.0
      gc_threshold_mb: 2048
    
    # Error handling
    error_handling:
      max_retries: 3
      retry_delay_seconds: 5
      continue_on_error: true
      log_errors: true
  
  # Workspace monitoring
  monitoring:
    health_check:
      enabled: true
      interval_seconds: 60
      check_projects: true
      check_collections: true
    
    metrics:
      enabled: true
      collection_interval_seconds: 300
      
      project_metrics:
        - file_count
        - total_size_mb
        - processing_time_seconds
        - error_count
      
      collection_metrics:
        - vector_count
        - index_size_mb
        - query_latency_ms
        - memory_usage_mb
    
    logging:
      level: "info"
      log_file: "./.logs/vectorizer-workspace-{date}.log"
      max_log_size_mb: 100
      max_log_files: 5
  
  # Workspace validation
  validation:
    paths:
      validate_existence: true
      validate_permissions: true
      create_missing_dirs: false
    
    config:
      validate_embedding_models: true
      validate_dimensions: true
      validate_collections: true
    
    data:
      validate_file_types: true
      validate_file_sizes: true
      validate_encoding: true

# =============================================================================
# REST-GRPC INTEGRATION CONFIGURATION
# =============================================================================
integration:
  # REST to GRPC integration
  rest_grpc:
    enabled: true                 # Enable REST-GRPC bridge
    grpc_client_pool_size: 10     # GRPC client connection pool size
    request_timeout: 30           # Request timeout in seconds
    retry_policy:
      max_attempts: 3
      initial_delay_ms: 100
      max_delay_ms: 5000
      backoff_multiplier: 2.0
    
    # Circuit breaker configuration
    circuit_breaker:
      enabled: true
      failure_threshold: 5        # Failures before opening circuit
      recovery_timeout: 30        # Seconds before attempting recovery
      half_open_max_calls: 3      # Max calls in half-open state
    
    # Load balancing
    load_balancing:
      strategy: "round_robin"     # round_robin, least_connections, random
      health_check_interval: 10   # Health check interval in seconds
  
  # MCP to GRPC integration
  mcp_grpc:
    enabled: true                 # Enable MCP-GRPC bridge
    grpc_client_pool_size: 5      # GRPC client connection pool size
    request_timeout: 60           # Request timeout in seconds (longer for MCP)
    
    # MCP-specific settings
    streaming:
      enabled: true               # Enable streaming responses
      buffer_size: 1024           # Stream buffer size
      flush_interval_ms: 100      # Flush interval for streaming
  
  # Service discovery
  service_discovery:
    enabled: false                # Enable service discovery
    provider: "static"            # static, consul, etcd
    
    # Static configuration
    static:
      grpc_servers:
        - "127.0.0.1:15003"
    
    # Health checking
    health_check:
      enabled: true
      interval_seconds: 10
      timeout_seconds: 5

# =============================================================================
# CUSTOM EXTENSIONS
# =============================================================================
extensions:
  # Custom plugins/modules
  plugins: []                    # List of plugin paths
  custom_modules: []             # Custom Rust modules to load

  # Webhooks and callbacks
  webhooks:
    enabled: false
    endpoints: []                # Webhook URLs for events
    events:                      # Events to trigger webhooks
      - collection_created
      - api_key_created
      - high_memory_usage
      - mcp_connection_established
      - mcp_tool_called

# =============================================================================
# SUMMARIZATION CONFIGURATION
# =============================================================================
    summarization:
      enabled: true           # Enable automatic summarization
      auto_summarize: true    # Automatically summarize during indexing
      summary_collection: "summaries"  # Collection name for summaries
      
      # Default summarization method
      default_method: "extractive"  # extractive, abstractive, keyword, sentence
      
      # Method-specific settings
      methods:
        extractive:
          enabled: true
          compression_ratio: 0.3  # Keep 30% of original text
          max_sentences: 5        # Maximum sentences in summary
          min_sentence_length: 10 # Minimum sentence length
          use_tfidf: true         # Use TF-IDF for sentence scoring
          
        abstractive:
          enabled: false          # Requires external LLM
          model: "gpt-3.5-turbo" # LLM model for abstractive summarization
          api_key: ""            # API key for LLM service
          max_tokens: 150        # Maximum tokens in summary
          temperature: 0.3       # Temperature for generation
          
        keyword:
          enabled: true
          max_keywords: 10       # Maximum keywords to extract
          min_keyword_length: 3  # Minimum keyword length
          use_stopwords: true    # Remove stopwords
          language: "en"         # Language for stopwords
          
        sentence:
          enabled: true
          compression_ratio: 0.4  # Keep 40% of sentences
          max_sentences: 3        # Maximum sentences
          min_sentence_length: 15 # Minimum sentence length
          use_position_weight: true # Weight sentences by position
          
      # Language support
      languages:
        en:
          stopwords: true
          stemming: true
        pt:
          stopwords: true
          stemming: true
        es:
          stopwords: true
          stemming: true
        fr:
          stopwords: true
