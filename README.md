# Vectorizer

A high-performance vector database and search engine built in Rust, designed for semantic search, document indexing, and AI-powered applications.

## âœ¨ **Version 0.4.0 - File Watcher System Release**

### ğŸš€ **Major Feature: Real-time File Monitoring**
- âœ… **Complete File Watcher System**: Real-time file monitoring with automatic indexing and reindexing
- âœ… **File Discovery**: Automatic discovery and indexing of files in workspace directories
- âœ… **Smart Debouncing**: Intelligent event debouncing to prevent excessive processing
- âœ… **Hash Validation**: Content-based change detection using file hashing
- âœ… **Pattern Filtering**: Configurable include/exclude patterns for file types and directories
- âœ… **31 Comprehensive Tests**: Complete test suite with 100% success rate
- âœ… **Zero External Dependencies**: Pure Rust implementation with no external tool dependencies

### ğŸš€ **File Operations Module** (v0.3.2+)
- âœ… **6 Production-Ready MCP Tools**: Complete file-level operations for AI assistants
  - `get_file_content` - Retrieve complete files with metadata
  - `list_files_in_collection` - Advanced file listing and filtering
  - `get_file_summary` - Extractive and structural summaries
  - `get_project_outline` - Hierarchical project visualization
  - `get_related_files` - Semantic file similarity search
  - `search_by_file_type` - File type-specific search
- âš¡ **Smart Caching**: Multi-tier LRU caching (10min, 5min, 30min TTLs)
- ğŸ”’ **Security**: Path validation preventing directory traversal
- ğŸ“Š **Rich Metadata**: File types, sizes, language detection

### ğŸ” **Discovery System**
- âœ… **9-Stage Pipeline**: Collection filtering â†’ Query expansion â†’ Broad search â†’ Focus search â†’ README promotion â†’ Evidence compression â†’ Answer planning â†’ Prompt rendering
- ğŸ§  **Intelligent Query Expansion**: Automatic variations (definition, features, architecture, API)
- ğŸ¯ **MMR Diversification**: Maximal Marginal Relevance for diverse results
- ğŸ“š **Evidence Compression**: Key sentences (8-30 words) with citations
- ğŸ”„ **Hybrid Search**: RRF combining sparse and dense retrieval

### ğŸ§ª **Test Suite**
- âœ… **282 tests passing** (100% pass rate)
- âš¡ **2.01s execution time** (optimized from >60s)
- ğŸ¯ **Production-ready** with comprehensive coverage
- âœ… **File Watcher Tests**: 31 dedicated tests for real-time monitoring system

## ğŸŒŸ **Key Features**

- **ğŸ” Real-time File Watcher**: Complete file monitoring system with automatic discovery, indexing, and reindexing
- **ğŸ“ File System Monitoring**: Live detection of file changes (create, modify, delete, move) with smart debouncing
- **ğŸ¯ Pattern-based Filtering**: Configurable include/exclude patterns for file types and directories
- **ğŸ” Hash Validation**: Content-based change detection using SHA-256 hashing to avoid unnecessary reindexing
- **ğŸ’¾ Dynamic Collection Persistence**: Collections automatically saved and loaded on server restart
- **âš¡ Background Auto-save**: Collections saved every 30 seconds automatically
- **ğŸ”„ Seamless Restart**: All collections restored exactly as they were
- **ğŸ” Semantic Search**: Advanced vector similarity search with multiple distance metrics
- **ğŸ“š Document Indexing**: Intelligent chunking and processing of various file types
- **ğŸ§  Multiple Embeddings**: Support for TF-IDF, BM25, BERT, MiniLM, and custom models
- **âš¡ High Performance**: Sub-3ms search times with optimized HNSW indexing
- **ğŸ—ï¸ Unified Architecture**: Single server with REST API and MCP integration
- **ğŸ”§ MCP Integration**: Model Context Protocol for AI IDE integration (Cursor, VS Code)
- **ğŸŒ REST API**: Complete HTTP API with authentication and security
- **ğŸš€ Advanced Embedding Models**: BM25, TF-IDF, and custom embedding providers
- **ğŸ¯ Simplified Configuration**: Minimal setup with intelligent defaults
- **ğŸ’¾ Automatic Persistence**: Collections automatically saved and loaded
- **ğŸ‘€ File Watcher**: Real-time file monitoring and indexing
- **ğŸ§  Intelligent Search**: Advanced semantic search with multi-query generation (v0.3.1)
- **ğŸ”¬ Semantic Reranking**: High-precision search with similarity thresholds
- **ğŸŒ Multi-Collection Search**: Cross-collection search with intelligent reranking
- **ğŸ¯ Contextual Search**: Context-aware search with metadata filtering

## ğŸ¯ **Simple Configuration**

Vectorizer uses intelligent defaults with minimal configuration required:

### **Features**
- âœ… **Minimal Setup**: Just run `vectorizer` and it works
- âœ… **Intelligent Defaults**: Automatic configuration with sensible defaults
- âœ… **Background Loading**: Collections load automatically without blocking server
- âœ… **Auto-Persistence**: Data is automatically saved and restored
- âœ… **File Watcher**: Real-time file monitoring with intelligent patterns
- âœ… **Dynamic Collections**: Create collections via REST API with automatic persistence

## ğŸš€ **Quick Start**

Get Vectorizer running in minutes:

### **1. Build and Run**
```bash
# Clone and build
git clone https://github.com/hivellm/vectorizer.git
cd vectorizer
cargo build --release

# Start the server
./target/release/vectorizer
```

### **2. Access Services**
- **REST API**: http://localhost:15002
- **MCP Server**: http://localhost:15002/mcp/sse  
- **Dashboard**: http://localhost:15002/dashboard
- **Health Check**: http://localhost:15002/health

## ğŸ’¾ **Persistence & File Watcher**

### **Dynamic Collections**
Create collections via REST API that persist automatically:

```bash
# Create a new collection
curl -X POST http://localhost:15002/collections \
  -H "Content-Type: application/json" \
  -d '{"name": "my-docs", "dimension": 512, "metric": "cosine"}'

# Insert documents
curl -X POST http://localhost:15002/insert \
  -H "Content-Type: application/json" \
  -d '{"collection": "my-docs", "text": "Your document content", "metadata": {"source": "file.txt"}}'
```

### **File Watcher**
Monitor file changes in real-time:
- **Supported formats**: `.md`, `.txt`, `.rs`, `.py`, `.js`, `.ts`, `.json`, `.yaml`, `.yml`
- **Auto-exclusion**: `target/`, `node_modules/`, `.git/`, etc.
- **Debounce**: 1000ms delay to handle rapid changes
- **Collection**: `watched_files` (configurable)

### **Persistence Features**
- **Auto-save**: Collections saved every 30 seconds
- **Restart recovery**: All collections restored on server restart
- **Format compatibility**: Versioned persistence format for future compatibility
- **Reliable writes**: File flush/sync ensures data integrity

### **3. Basic Usage**
```bash
# Check server status
curl http://localhost:15002/health

# List collections
curl http://localhost:15002/collections

# Search vectors (after adding some data)
curl -X POST http://localhost:15002/collections/my-collection/search \
  -H "Content-Type: application/json" \
  -d '{"query": "example text", "limit": 10}'
```

## ğŸ§  **Intelligent Search Features (v0.3.1)**

Vectorizer now includes advanced intelligent search capabilities that provide 3-4x better coverage than traditional search methods:

### **ğŸ” intelligent_search**
- **Multi-query generation**: Automatically generates 4-8 related queries
- **Domain expansion**: Expands queries with technical terms and synonyms
- **MMR diversification**: Ensures diverse, high-quality results
- **Technical focus**: Boosts scores for technical content
- **Collection bonuses**: Prioritizes relevant collections

### **ğŸ”¬ semantic_search**
- **Semantic reranking**: Advanced relevance scoring
- **Similarity thresholds**: Configurable quality filters (0.1-0.5)
- **Cross-encoder support**: Maximum precision matching

### **ğŸŒ multi_collection_search**
- **Cross-collection search**: Simultaneous search across multiple collections
- **Intelligent reranking**: Balanced results from different sources
- **Deduplication**: Removes duplicate content across collections

### **ğŸ¯ contextual_search**
- **Metadata filtering**: Filter by file type, chunk index, etc.
- **Context reranking**: Reorder based on contextual relevance
- **Configurable weights**: Balance between relevance and context

### **Usage Examples**
```bash
# Intelligent search with domain expansion
curl -X POST http://localhost:15002/intelligent_search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "CMMV framework architecture",
    "collections": ["cmmv-core-docs"],
    "max_results": 10,
    "domain_expansion": true,
    "technical_focus": true,
    "mmr_enabled": true
  }'

# Semantic search with high precision
curl -X POST http://localhost:15002/semantic_search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "authentication system",
    "collection": "cmmv-core-docs",
    "similarity_threshold": 0.15,
    "semantic_reranking": true
  }'
```

## ğŸ”— **Framework Integrations**

Complete integrations with popular AI frameworks:

### **LangChain**
```python
from integrations.langchain.vectorizer_store import VectorizerStore

store = VectorizerStore(host="localhost", port=15001, collection_name="docs")
store.add_documents([{"page_content": "LangChain framework", "metadata": {"source": "intro.txt"}}])
results = store.similarity_search("language models", k=3)
```

### **PyTorch & TensorFlow**
```python
from integrations.pytorch.pytorch_embedder import create_transformer_embedder

embedder = create_transformer_embedder(model_path="sentence-transformers/all-MiniLM-L6-v2")
client = PyTorchVectorizerClient()
client.set_embedder(embedder)
```

## ğŸš€ **Advanced Embedding Models**

Production-ready embedding models:

### **Available Models**
- **MiniLM Multilingual** (384D): Fast, efficient multilingual embeddings
- **E5 Small/Base** (384D/768D): Optimized for retrieval tasks
- **MPNet Multilingual** (768D): Superior semantic understanding
- **GTE Multilingual** (768D): Alibaba's high-quality model
- **DistilUSE** (512D): Google's efficient universal embeddings

### **Features**
- **Batch Processing**: Optimized batch inference for high throughput
- **Multilingual**: Support for 100+ languages

## ğŸ“š **Configuration**

```yaml
vectorizer:
  host: "localhost"
  port: 15002
  default_dimension: 512
  default_metric: "cosine"
  
  # Summarization
  summarization:
    enabled: true
    default_method: "extractive"
```

## ğŸ’¾ Data Management

Vectorizer automatically manages data persistence in the `data/` directory:
- **Collections are automatically saved and loaded** (v0.3.0)
- **Background loading** ensures server availability during startup
- **Auto-save every 30 seconds** for dynamic collections
- **File watcher** monitors changes and updates indexes
- **Quantization** is applied automatically for memory optimization
- **Versioned persistence format** for future compatibility

## ğŸ“Š **Performance Metrics**

### **Intelligent Search Performance (v0.3.1)**
Based on comprehensive testing with 107 collections:

| Metric | Traditional Search | Intelligent Search | Improvement |
|--------|-------------------|-------------------|-------------|
| **Coverage** | 4 results | 18 results (5 final) | 3-4x more |
| **Query Generation** | 1 query | 4-8 queries | Automatic |
| **Deduplication** | None | 18â†’9â†’5 results | Smart filtering |
| **Relevance** | â­â­â­â­ | â­â­â­â­â­ | Superior |
| **Diversity** | â­â­ | â­â­â­â­â­ | Much better |

### **System Performance**
- **ğŸš€ Server Startup**: Non-blocking with background collection loading
- **âš¡ Search Speed**: Sub-3ms search times with optimized HNSW indexing
- **ğŸ’¾ Memory Usage**: Automatic quantization for memory optimization
- **ğŸ“ˆ Scalability**: Tested with 107+ collections
- **ğŸ”„ Real-time**: Live file watching and indexing

## ğŸ¯ Use Cases

- **RAG Systems**: Large knowledge bases with semantic search
- **AI Applications**: Real-time context sharing and retrieval
- **Document Search**: Intelligent document indexing and search
- **Production Workflows**: Enterprise-grade vector operations

## ğŸ” Embedding Methods

**Sparse Embeddings**: TF-IDF, BM25 with SVD dimensionality reduction  
**Dense Embeddings**: BERT, MiniLM with contextual understanding  
**Hybrid Search**: Sparse retrieval + dense re-ranking for optimal results

## ğŸ“š **Documentation**

- **[API Documentation](./docs/api/)** - Complete API reference
- **[Intelligent Search Guide](./docs/specs/INTELLIGENT_SEARCH_TOOLS.md)** - Complete guide to intelligent search tools
- **[Quality Report](./docs/specs/INTELLIGENT_SEARCH_QUALITY_REPORT.md)** - Performance analysis and recommendations
- **[MCP Integration](./docs/specs/MCP_INTEGRATION.md)** - Model Context Protocol guide
- **[Performance Guide](./docs/specs/PERFORMANCE_GUIDE.md)** - Optimization and tuning
- **[Technical Documentation](./docs/specs/TECHNICAL_DOCUMENTATION_INDEX.md)** - Complete technical reference
- **[Roadmap](./docs/specs/ROADMAP.md)** - Development roadmap and milestones

## ğŸ”§ MCP Integration

IDE integration via Model Context Protocol:

```json
{
  "mcpServers": {
    "vectorizer": {
      "url": "http://localhost:15002/sse",
      "type": "sse",
      "protocol": "http"
    }
  }
}
```

**Available Tools:** 
- **Traditional**: search_vectors, list_collections, embed_text, create_collection, insert_texts, delete_vectors
- **Intelligent Search**: intelligent_search, semantic_search, multi_collection_search, contextual_search
- **Batch Operations**: batch_insert_texts, batch_search_vectors, batch_update_vectors, batch_delete_vectors