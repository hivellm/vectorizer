<!-- RULEBOOK:START -->
# Project Rules

Generated by @hivellm/rulebook
Generated at: 2025-12-07T23:41:18.457Z

## ‚ö†Ô∏è CRITICAL: Task Management Rules (HIGHEST PRECEDENCE)

**MANDATORY**: All task creation MUST follow Rulebook task management system.

**üìã ALWAYS reference `/rulebook/RULEBOOK.md` FIRST before creating any tasks or when "openspec" is mentioned.**

**Rules from RULEBOOK.md take precedence over all other rules in this file.**

**Key Requirements:**
- ‚úÖ Context7 MCP is REQUIRED for task creation
- ‚úÖ All tasks MUST follow OpenSpec-compatible format
- ‚úÖ Use `rulebook task create` instead of OpenSpec commands
- ‚úÖ Always validate task format before committing
- ‚ùå NEVER create tasks without checking RULEBOOK.md format requirements
- ‚ùå NEVER use OpenSpec commands - use Rulebook task system instead

### ‚ö†Ô∏è CRITICAL: Task File Structure Rules

**MANDATORY**: When creating or updating tasks, you MUST follow the correct file structure:

**‚úÖ CORRECT File Structure:**
- `proposal.md` - **Why** and **What Changes** (detailed explanations go here)
- `tasks.md` - **ONLY checklist items** (simple `- [ ]` or `- [x]` format)
- `specs/<module>/spec.md` - **Technical specifications** (SHALL/MUST requirements)
- `design.md` - **Technical design decisions** (optional, for complex features)

**‚ùå FORBIDDEN Practices:**
- ‚ùå **NEVER** add long explanations or specifications in `tasks.md`
- ‚ùå **NEVER** put technical details in `tasks.md` (use `specs/` instead)
- ‚ùå **NEVER** create `README.md` or `README` files in task directories
- ‚ùå **NEVER** create `PROCESS.md` or `PROCESS` files in task directories
- ‚ùå **NEVER** create any file not listed in the correct structure above

**What Goes Where:**

1. **`proposal.md`** - Use for:
   - Detailed "Why" explanations (minimum 20 characters)
   - "What Changes" descriptions
   - Impact analysis
   - Business/technical rationale

2. **`tasks.md`** - Use ONLY for:
   - Simple checklist items: `- [ ] Task description`
   - Status updates: `- [x] Completed task`
   - Brief comments: `<!-- tested, coverage: 95% -->`
   - **DO NOT** add long explanations, specifications, or technical details here

3. **`specs/<module>/spec.md`** - Use for:
   - Technical specifications with SHALL/MUST requirements
   - Scenario definitions (Given/When/Then)
   - Delta operations (ADDED/MODIFIED/REMOVED)
   - All detailed technical requirements

4. **`design.md`** - Use for (optional):
   - Architecture decisions
   - Technical design rationale
   - Complex implementation details

**Example of WRONG usage:**
```markdown
# tasks.md (WRONG - too much detail)

## Implementation
- [ ] Create authentication system
  The system SHALL implement JWT-based authentication...
  Users MUST be able to login with email and password...
  The system MUST validate tokens...
```

**Example of CORRECT usage:**
```markdown
# tasks.md (CORRECT - simple checklist)

## 1. Implementation Phase
- [ ] 1.1 Create authentication module
- [ ] 1.2 Add JWT token generation
- [ ] 1.3 Implement password validation

# specs/auth/spec.md (CORRECT - specifications here)

## ADDED Requirements

### Requirement: Authentication System
The system SHALL implement JWT-based authentication.

#### Scenario: User Login
Given a user with valid credentials
When the user submits login form
Then the system MUST return a JWT token
```

**Remember:**
- ‚úÖ `tasks.md` = Simple checklist only
- ‚úÖ `proposal.md` = Why and what changes
- ‚úÖ `specs/` = Technical specifications
- ‚ùå No README, PROCESS, or other files

**For complete task management guidelines, see: `/rulebook/RULEBOOK.md`**

---

## Core Rules

This project uses @hivellm/rulebook standards.

**CRITICAL RULES:**
1. **ALWAYS check `RULEBOOK.md` first** when creating tasks or if "openspec" is mentioned
2. Write tests first (95%+ coverage required)
3. Run quality checks before committing:
   - Type check / Compiler check
   - Linter (no warnings allowed)
   - All tests (100% pass rate)
   - Coverage check
4. Update docs/ when implementing features
5. Follow strict documentation structure
6. **NEVER run destructive deletions (`rm -rf`) in this repository; when adding submodules always use `git submodule add`.**
7. **Temporary files and scripts**:
   - ‚úÖ ALL scripts MUST be created in `/scripts` directory
   - ‚úÖ ALL temporary files (test, log, debug) MUST be in `/scripts`
   - ‚úÖ ALL temporary files MUST be removed immediately after use (MANDATORY)
   - ‚ùå NEVER create temporary files in project root or outside `/scripts`
   - ‚ùå NEVER leave temporary files after use - clean up before committing

## Detailed Rules

For comprehensive rules, see the corresponding files in `/rulebook/`:

- `/rulebook/RULEBOOK.md` - **Task management rules (HIGHEST PRECEDENCE)**
- `/rulebook/QUALITY_ENFORCEMENT.md` - Quality enforcement rules
- `/rulebook/GIT.md` - Git workflow rules

Language-specific rules are in `/rulebook/`.
Module-specific patterns are in `/rulebook/`.

When in doubt, ask to review @AGENTS.md first.

<!-- RULEBOOK:END -->

## Language-Specific Rules

The following languages are configured for this project. For detailed rules, see the corresponding files in `/rulebook/`:

### Rust Development Rules

For comprehensive Rust-specific guidelines, see `/rulebook/RUST.md`

Quick reference:
- Type safety and strict mode
- Code quality standards
- Testing requirements (95%+ coverage)
- Package management
- Error handling patterns

### Ruby Development Rules

For comprehensive Ruby-specific guidelines, see `/rulebook/RUBY.md`

Quick reference:
- Type safety and strict mode
- Code quality standards
- Testing requirements (95%+ coverage)
- Package management
- Error handling patterns

**Usage**: When working with language-specific code, reference the corresponding `/rulebook/[LANGUAGE].md` file for detailed guidelines.

## Module-Specific Instructions

The following modules are configured for this project. For detailed instructions, see the corresponding files in `/rulebook/`:

### Agent automation Instructions

For comprehensive Agent automation-specific instructions, see `/rulebook/AGENT_AUTOMATION.md`

Quick reference:
- Module-specific instructions
- Usage guidelines
- Integration patterns

**Usage**: When working with module-specific features, reference the corresponding `/rulebook/[MODULE].md` file for detailed instructions.

## Project Capabilities

This project has the following AI-assisted capabilities enabled:

- **Core**: Rulebook Task Management, Agent Automation, Dag, Documentation Rules, Quality Enforcement, Rulebook
- **Languages**: Ruby, Rust

Use `rulebook skill list` to see all available skills.
Use `rulebook skill add <skill-id>` to enable additional skills.

<!-- RULEBOOK:SKILLS_INDEX:START -->
## Installed Skills

| Category | Skill | Description |
|----------|-------|-------------|
| Core | Rulebook Task Management | Spec-driven task management for features and breaking changes with OpenSpec-compatible format |
| Languages | Ruby | **CRITICAL**: Execute these commands after EVERY implementation (see AGENT_AUTOMATION module for full workflow). |
| Languages | Rust | **CRITICAL**: Execute these commands after EVERY implementation (see AGENT_AUTOMATION module for full workflow). |
| Core | Agent Automation | **CRITICAL**: Mandatory workflow that AI agents MUST execute after EVERY implementation. |
| Core | Dag | **CRITICAL**: Maintain a clean dependency graph (DAG) to prevent circular dependencies and ensure maintainable architecture. |
| Core | Documentation Rules | **CRITICAL**: All documentation in English. Root README concise, detailed docs in `/docs`. |
| Core | Quality Enforcement | **CRITICAL**: These rules are NON-NEGOTIABLE and MUST be followed without exception. |
| Core | Rulebook | **CRITICAL**: Use Rulebook's built-in task management system for spec-driven development of new features and breaking changes. |

<!-- RULEBOOK:SKILLS_INDEX:END -->

<!-- RULEBOOK:SKILL:core/rulebook-task-management:START -->
# Rulebook Task Management

**CRITICAL**: Use Rulebook's built-in task management system for spec-driven development of new features and breaking changes.

## When to Use

Create tasks for:
- New features/capabilities
- Breaking changes
- Architecture changes
- Performance/security work

Skip for:
- Bug fixes (restore intended behavior)
- Typos, formatting, comments
- Dependency updates (non-breaking)

## Task Creation is MANDATORY Before Implementation

**ABSOLUTE RULE**: You MUST create a task BEFORE implementing ANY feature.

### MANDATORY Workflow

**NEVER start implementation without creating a task first:**

```bash
# WRONG: Starting implementation directly
# ... writing code without task ...

# CORRECT: Create task first
rulebook task create <task-id>
# Write proposal.md
# Write tasks.md
# Write spec deltas
rulebook task validate <task-id>
# NOW you can start implementation
```

### Task Creation Steps

**When a feature is requested:**

1. **STOP** - Do not start coding
2. **Create task** - `rulebook task create <task-id>`
3. **Plan** - Write proposal.md and tasks.md
4. **Spec** - Write spec deltas
5. **Validate** - `rulebook task validate <task-id>`
6. **THEN** - Start implementation

## Task Directory Structure

```
rulebook/tasks/<task-id>/
‚îú‚îÄ‚îÄ proposal.md         # Why and what changes
‚îú‚îÄ‚îÄ tasks.md            # Implementation checklist
‚îú‚îÄ‚îÄ design.md           # Technical design (optional)
‚îî‚îÄ‚îÄ specs/
    ‚îî‚îÄ‚îÄ <module>/
        ‚îî‚îÄ‚îÄ spec.md     # Technical specifications
```

## Task Commands

```bash
# Create new task
rulebook task create <task-id>

# List all tasks
rulebook task list

# Show task details
rulebook task show <task-id>

# Validate task structure
rulebook task validate <task-id>

# Archive completed task
rulebook task archive <task-id>
```

## Proposal Format (proposal.md)

```markdown
# Proposal: <Task Title>

## Why
<Explain the problem or opportunity>

## What Changes
<List of changes with ADDED/MODIFIED/REMOVED markers>

## Impact
- Affected specs: <list spec files>
- Affected code: <list source files>
- Breaking change: YES/NO
- User benefit: <describe benefit>
```

## Tasks Format (tasks.md)

**CRITICAL**: Only simple checklist items. Technical details go in specs.

```markdown
## 1. <Phase Name>
- [ ] 1.1 <Simple task description>
- [ ] 1.2 <Simple task description>

## 2. <Phase Name>
- [ ] 2.1 <Simple task description>
```

## Spec Delta Format (specs/<module>/spec.md)

```markdown
# <Module> Specification

## ADDED Requirements

### Requirement: <Name>
<Description>

#### Scenario: <Name>
Given <context>
When <action>
Then <expected result>

## MODIFIED Requirements

### Requirement: <Original Name>
<Description of modification>

## REMOVED Requirements

### Requirement: <Name to Remove>
<Reason for removal>
```

## MCP Integration

If MCP server is enabled, use programmatic task management:

```typescript
// Create task
await mcp.rulebook_task_create({ taskId: "my-task" });

// List tasks
await mcp.rulebook_task_list({});

// Show task
await mcp.rulebook_task_show({ taskId: "my-task" });

// Validate task
await mcp.rulebook_task_validate({ taskId: "my-task" });

// Archive task
await mcp.rulebook_task_archive({ taskId: "my-task" });
```

## Best Practices

1. **Always create task first** - Never implement without documentation
2. **Keep tasks.md simple** - Only checklist items, no explanations
3. **Put details in specs** - Technical requirements go in spec files
4. **Validate before implementing** - Run `rulebook task validate`
5. **Archive when done** - Move completed tasks to archive

<!-- RULEBOOK:SKILL:core/rulebook-task-management:END -->

<!-- RULEBOOK:SKILL:languages/ruby:START -->
<!-- RUBY:START -->
# Ruby Project Rules

## Agent Automation Commands

**CRITICAL**: Execute these commands after EVERY implementation (see AGENT_AUTOMATION module for full workflow).

```bash
# Complete quality check sequence:
bundle exec rubocop       # Linting and formatting
bundle exec rspec         # All tests (100% pass)
bundle exec rspec --format documentation  # Test coverage

# Security audit:
bundle audit              # Vulnerability scan
bundle outdated           # Check outdated deps
```

## Ruby Configuration

**CRITICAL**: Use Ruby 3.2+ with RuboCop and modern tooling.

- **Version**: Ruby 3.2+
- **Recommended**: Ruby 3.3+
- **Style Guide**: Ruby Style Guide (RuboCop)
- **Testing**: RSpec (recommended) or Minitest
- **Type Checking**: RBS + Steep (optional but recommended)

### Gemfile Requirements

```ruby
source 'https://rubygems.org'

ruby '>= 3.2.0'

# Production dependencies
gem 'rake', '~> 13.0'

# Development dependencies
group :development do
  gem 'rubocop', '~> 1.60', require: false
  gem 'rubocop-performance', require: false
  gem 'rubocop-rspec', require: false
end

# Test dependencies
group :test do
  gem 'rspec', '~> 3.12'
  gem 'simplecov', require: false
  gem 'simplecov-lcov', require: false
end

# Both development and test
group :development, :test do
  gem 'pry'
  gem 'pry-byebug'
end
```

### Gemspec Requirements (for gems)

```ruby
Gem::Specification.new do |spec|
  spec.name = 'your_gem'
  spec.version = '0.1.0'
  spec.authors = ['Your Name']
  spec.email = ['you@example.com']

  spec.summary = 'Brief summary'
  spec.description = 'Longer description'
  spec.homepage = 'https://github.com/you/your_gem'
  spec.license = 'MIT'
  spec.required_ruby_version = '>= 3.2.0'

  spec.files = Dir.glob('{lib,bin}/**/*') + %w[README.md LICENSE.txt]
  spec.bindir = 'exe'
  spec.executables = spec.files.grep(%r{^exe/}) { |f| File.basename(f) }
  spec.require_paths = ['lib']

  spec.add_dependency 'rake', '~> 13.0'
  
  spec.add_development_dependency 'rspec', '~> 3.12'
  spec.add_development_dependency 'rubocop', '~> 1.60'
end
```

## Code Quality Standards

### Mandatory Quality Checks

**CRITICAL**: After implementing ANY feature, you MUST run these commands in order.

**IMPORTANT**: These commands MUST match your GitHub Actions workflows to prevent CI/CD failures!

```bash
# Pre-Commit Checklist (MUST match .github/workflows/*.yml)

# 1. Lint (MUST pass with no warnings - matches workflow)
bundle exec rubocop

# 2. Run all tests (MUST pass 100% - matches workflow)
bundle exec rspec
# or: bundle exec rake test (for Minitest)

# 3. Check coverage (MUST meet threshold - matches workflow)
COVERAGE=true bundle exec rspec

# 4. Security audit (matches workflow)
bundle exec bundler-audit check --update

# 5. Build gem (if gem project - matches workflow)
gem build *.gemspec

# If ANY fails: ‚ùå DO NOT COMMIT - Fix first!
```

**If ANY of these fail, you MUST fix the issues before committing.**

**Why This Matters:**
- Running different commands locally than in CI causes "works on my machine" failures
- CI/CD workflows will fail if commands don't match
- Example: Using `rubocop -a` (auto-correct) locally but `rubocop` in CI = failure
- Example: Missing security audit locally = CI catches vulnerabilities in dependencies

### Linting with RuboCop

- Configuration in `.rubocop.yml`
- Must pass with no offenses
- Auto-correct safe offenses only

Example `.rubocop.yml`:
```yaml
require:
  - rubocop-performance
  - rubocop-rspec

AllCops:
  TargetRubyVersion: 3.2
  NewCops: enable
  Exclude:
    - 'vendor/**/*'
    - 'tmp/**/*'
    - 'bin/**/*'

Style/StringLiterals:
  EnforcedStyle: single_quotes

Metrics/MethodLength:
  Max: 15
  Exclude:
    - 'spec/**/*'

Metrics/BlockLength:
  Exclude:
    - 'spec/**/*'
    - '*.gemspec'
```

### Testing

- **Framework**: RSpec (recommended) or Minitest
- **Location**: `/spec` (RSpec) or `/test` (Minitest)
- **Coverage**: SimpleCov (80%+ threshold)
- **Focus**: Write descriptive specs

Example RSpec test:
```ruby
# spec/my_class_spec.rb

RSpec.describe MyClass do
  let(:instance) { described_class.new(value: 'test') }
  
  describe '#process' do
    context 'with valid input' do
      it 'returns processed value' do
        result = instance.process('input')
        expect(result).to eq('PROCESSED: input')
      end
      
      it 'handles empty strings' do
        expect(instance.process('')).to be_nil
      end
    end
    
    context 'with invalid input' do
      it 'raises ArgumentError' do
        expect { instance.process(nil) }.to raise_error(ArgumentError)
      end
    end
  end
  
  describe '#validate' do
    it 'returns true for valid data' do
      expect(instance.validate('valid')).to be true
    end
    
    it 'returns false for invalid data' do
      expect(instance.validate('')).to be false
    end
  end
end
```

Example Minitest:
```ruby
# test/my_class_test.rb

require 'test_helper'

class MyClassTest < Minitest::Test
  def setup
    @instance = MyClass.new(value: 'test')
  end
  
  def test_process_returns_expected_value
    result = @instance.process('input')
    assert_equal 'PROCESSED: input', result
  end
  
  def test_process_handles_empty_strings
    assert_nil @instance.process('')
  end
  
  def test_process_raises_on_nil
    assert_raises(ArgumentError) { @instance.process(nil) }
  end
end
```

### Coverage Configuration

Create `spec/spec_helper.rb`:
```ruby
if ENV['COVERAGE']
  require 'simplecov'
  require 'simplecov-lcov'
  
  SimpleCov::Formatter::LcovFormatter.config.report_with_single_file = true
  SimpleCov.formatter = SimpleCov::Formatter::MultiFormatter.new([
    SimpleCov::Formatter::HTMLFormatter,
    SimpleCov::Formatter::LcovFormatter
  ])
  
  SimpleCov.start do
    add_filter '/spec/'
    add_filter '/test/'
    
    minimum_coverage 80
    minimum_coverage_by_file 70
  end
end

require 'your_gem'

RSpec.configure do |config|
  config.expect_with :rspec do |expectations|
    expectations.include_chain_clauses_in_custom_matcher_descriptions = true
  end

  config.mock_with :rspec do |mocks|
    mocks.verify_partial_doubles = true
  end

  config.shared_context_metadata_behavior = :apply_to_host_groups
  config.filter_run_when_matching :focus
  config.example_status_persistence_file_path = 'spec/examples.txt'
  config.disable_monkey_patching!
  config.warnings = true
  
  config.default_formatter = 'doc' if config.files_to_run.one?
  config.profile_examples = 10
  config.order = :random
  Kernel.srand config.seed
end
```

## Dependency Management

### Using Bundler

```bash
# Install dependencies
bundle install

# Update dependencies
bundle update

# Check for outdated gems
bundle outdated

# Security audit
bundle exec bundler-audit check --update
```

### Gemfile.lock

- **MUST** commit Gemfile.lock for applications
- For gems: Add to `.gitignore`
- Ensures reproducible builds

## Best Practices

### DO's ‚úÖ

- **USE** meaningful variable and method names
- **FOLLOW** Ruby naming conventions (snake_case)
- **WRITE** descriptive tests with context blocks
- **HANDLE** exceptions explicitly
- **VALIDATE** inputs
- **DOCUMENT** public APIs
- **USE** symbols for hash keys when possible
- **FREEZE** string literals in Ruby 3+

### DON'Ts ‚ùå

- **NEVER** use global variables
- **NEVER** monkey-patch core classes without extreme caution
- **NEVER** skip tests
- **NEVER** commit `.byebug_history` or debug files
- **NEVER** use `eval` unless absolutely necessary
- **NEVER** ignore RuboCop offenses without justification
- **NEVER** commit with failing tests

Example code style:
```ruby
# ‚úÖ GOOD: Clean Ruby code
class DataProcessor
  def initialize(options = {})
    @threshold = options.fetch(:threshold, 0.5)
    @verbose = options.fetch(:verbose, false)
  end
  
  def process(data)
    validate_input!(data)
    
    log('Processing data...') if @verbose
    
    data.select { |item| item[:value] > @threshold }
  end
  
  private
  
  def validate_input!(data)
    raise ArgumentError, 'Data must be an array' unless data.is_a?(Array)
    raise ArgumentError, 'Data cannot be empty' if data.empty?
  end
  
  def log(message)
    puts "[#{Time.now.iso8601}] #{message}"
  end
end

# ‚ùå BAD: Poor practices
class DataProcessor
  def process(data)
    $threshold = 0.5  # DON'T use globals!
    
    if data == nil  # Use nil? method
      return false
    end
    
    result = []
    for item in data  # Use .each or .map
      if item[:value] > $threshold
        result.push(item)
      end
    end
    
    puts result  # DON'T print in library code
    result
  end
end
```

## CI/CD Requirements

Must include GitHub Actions workflows:

1. **Testing** (`ruby-test.yml`):
   - Test on ubuntu-latest, windows-latest, macos-latest
   - Ruby versions: 3.2, 3.3
   - Upload coverage to Codecov

2. **Linting** (`ruby-lint.yml`):
   - RuboCop checks
   - Bundler audit for security

3. **Build** (`ruby-build.yml`):
   - Build gem
   - Verify gem structure

## Publishing to RubyGems

### Prerequisites

1. Create account at https://rubygems.org
2. Get API key: `gem signin`
3. Add `RUBYGEMS_API_KEY` to GitHub secrets

### Publishing Workflow

```bash
# 1. Update version in gemspec or version.rb
# 2. Update CHANGELOG.md
# 3. Run all quality checks
bundle exec rubocop
bundle exec rspec
gem build *.gemspec

# 4. Create git tag
git tag -a v1.0.0 -m "Release version 1.0.0"

# 5. Push (manual if SSH password)
# git push origin main
# git push origin v1.0.0

# 6. Publish to RubyGems (or use GitHub Actions)
gem push your_gem-1.0.0.gem
```

<!-- RUBY:END -->

<!-- RULEBOOK:SKILL:languages/ruby:END -->

<!-- RULEBOOK:SKILL:languages/rust:START -->
<!-- RUST:START -->
# Rust Project Rules

## Agent Automation Commands

**CRITICAL**: Execute these commands after EVERY implementation (see AGENT_AUTOMATION module for full workflow).

```bash
# Complete quality check sequence:
cargo fmt --all -- --check           # Format check
cargo clippy --workspace --all-targets --all-features -- -D warnings  # Lint
cargo test --workspace --all-features  # All tests (100% pass)
cargo build --release                # Build verification
cargo llvm-cov --all                 # Coverage (95%+ required)

# Security audit:
cargo audit                          # Vulnerability scan
cargo outdated                       # Check outdated deps
```

## Rust Edition and Toolchain

**CRITICAL**: Always use Rust Edition 2024 with nightly toolchain.

- **Edition**: 2024
- **Toolchain**: nightly 1.85+
- **Update**: Run `rustup update nightly` regularly

### Formatting

- Use `rustfmt` with nightly toolchain
- Configuration in `rustfmt.toml` or `.rustfmt.toml`
- Always format before committing: `cargo +nightly fmt --all`
- CI must check formatting: `cargo +nightly fmt --all -- --check`

### Linting

- Use `clippy` with `-D warnings` (warnings as errors)
- Fix all clippy warnings before committing
- Acceptable exceptions must be documented with `#[allow(clippy::...)]` and justification
- CI must enforce clippy: `cargo clippy --workspace -- -D warnings`

### Testing

- **Location**: Tests in `/tests` directory for integration tests
- **Unit Tests**: In same file as implementation with `#[cfg(test)]`
- **Coverage**: Must meet project threshold (default 95%)
- **Tools**: Use `cargo-nextest` for faster test execution
- **Async**: Use `tokio::test` for async tests with Tokio runtime

Example test structure:
```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_feature() {
        // Test implementation
    }

    #[tokio::test]
    async fn test_async_feature() {
        // Async test implementation
    }
}
```

### Test Categories: S2S and Slow Tests

**CRITICAL**: Tests must be categorized based on execution time and dependencies.

#### Test Time Limits

- **Fast Tests**: Must complete in ‚â§ 10-20 seconds
- **Slow Tests**: Any test taking > 10-20 seconds must be marked as slow
- **S2S Tests**: Tests requiring active server/database must be isolated and run on-demand

#### S2S (Server-to-Server) Tests

**Tests that require active servers, databases, or external services must be isolated using Cargo features.**

**Implementation**:

1. **Create `s2s` feature in `Cargo.toml`**:
```toml
[features]
default = []
s2s = []  # Enable server-to-server tests
```

2. **Mark S2S tests with feature flag**:
```rust
#[cfg(test)]
mod tests {
    use super::*;

    // Regular fast test (always runs)
    #[test]
    fn test_local_computation() {
        // Fast test, no external dependencies
    }

    // S2S test (only runs with --features s2s)
    #[cfg(feature = "s2s")]
    #[tokio::test]
    async fn test_database_connection() {
        // Requires active database server
        let db = connect_to_database().await?;
        // ... test implementation
    }

    #[cfg(feature = "s2s")]
    #[tokio::test]
    async fn test_api_integration() {
        // Requires active API server
        let client = create_api_client().await?;
        // ... test implementation
    }
}
```

3. **Run tests**:
```bash
# Regular tests (excludes S2S)
cargo test

# Include S2S tests (requires active servers)
cargo test --features s2s

# CI/CD: Run S2S tests only when servers are available
cargo test --features s2s --test-args '--test-threads=1'
```

#### Slow Tests

**Tests that take > 10-20 seconds must be marked and run separately.**

**Implementation**:

1. **Create `slow` feature in `Cargo.toml`**:
```toml
[features]
default = []
slow = []  # Enable slow tests
```

2. **Mark slow tests**:
```rust
#[cfg(test)]
mod tests {
    use super::*;

    // Fast test (always runs)
    #[test]
    fn test_quick_operation() {
        // Completes in < 1 second
    }

    // Slow test (only runs with --features slow)
    #[cfg(feature = "slow")]
    #[test]
    fn test_heavy_computation() {
        // Takes 30+ seconds
        // Heavy processing, large dataset, etc.
    }

    #[cfg(feature = "slow")]
    #[tokio::test]
    async fn test_large_file_processing() {
        // Processes large files, takes > 20 seconds
    }
}
```

3. **Run tests**:
```bash
# Regular tests (excludes slow)
cargo test

# Include slow tests
cargo test --features slow

# Run both S2S and slow tests
cargo test --features s2s,slow
```

#### Best Practices

- ‚úÖ **Always run fast tests** in CI/CD by default
- ‚úÖ **Isolate S2S tests** - never run them in standard test suite
- ‚úÖ **Mark slow tests** - prevent CI/CD timeouts
- ‚úÖ **Document requirements** - specify which servers/services are needed for S2S tests
- ‚úÖ **Use timeouts** - Set appropriate timeouts for S2S tests: `tokio::time::timeout(Duration::from_secs(30), test_fn).await?`
- ‚ùå **Never mix** fast and slow/S2S tests in same test run
- ‚ùå **Never require** external services for standard test suite
- ‚ùå **Never exceed** 10-20 seconds for regular tests

## Async Programming

**CRITICAL**: Follow Tokio best practices for async code.

- **Runtime**: Use Tokio for async runtime
- **Blocking**: Never block in async context - use `spawn_blocking` for CPU-intensive tasks
- **Channels**: Use `tokio::sync::mpsc` or `tokio::sync::broadcast` for async communication
- **Timeouts**: Always set timeouts for network operations: `tokio::time::timeout`

Example:
```rust
use tokio::time::{timeout, Duration};

async fn fetch_data() -> Result<Data, Error> {
    timeout(Duration::from_secs(30), async {
        // Network operation
    }).await?
}
```

## Dependency Management

**CRITICAL**: Always verify latest versions before adding dependencies.

### Before Adding Any Dependency

1. **Check Context7 for latest version**:
   - Use MCP Context7 tool if available
   - Search for the crate documentation
   - Verify the latest stable version
   - Review breaking changes and migration guides

2. **Example Workflow**:
   ```
   Adding tokio ‚Üí Check crates.io and docs.rs
   Adding serde ‚Üí Verify latest version with security updates
   Adding axum ‚Üí Check for breaking changes in latest version
   ```

3. **Document Version Choice**:
   - Note why specific version chosen in `Cargo.toml` comments
   - Document any compatibility constraints
   - Update CHANGELOG.md with new dependencies

### Dependency Guidelines

- ‚úÖ Use latest stable versions
- ‚úÖ Check for security advisories: `cargo audit`
- ‚úÖ Prefer well-maintained crates (active development, good documentation)
- ‚úÖ Minimize dependency count
- ‚úÖ Use workspace dependencies for monorepos
- ‚ùå Don't use outdated versions without justification
- ‚ùå Don't add dependencies without checking latest version

## Codespell Configuration

**CRITICAL**: Use codespell to catch typos in code and documentation.

Install: `pip install 'codespell[toml]'`

Configuration in `pyproject.toml`:
```toml
[tool.codespell]
skip = "*.lock,*.json,target,node_modules,.git"
ignore-words-list = "crate,ser,deser"
```

Or run with flags:
```bash
codespell \
  --skip="*.lock,*.json,target,node_modules,.git" \
  --ignore-words-list="crate,ser,deser"
```

## Error Handling

- Use `Result<T, E>` for recoverable errors
- Use `thiserror` for custom error types
- Use `anyhow` for application-level error handling
- Document error conditions in function docs
- Never use `unwrap()` or `expect()` in production code without justification

Example:
```rust
use thiserror::Error;

#[derive(Error, Debug)]
pub enum MyError {
    #[error("IO error: {0}")]
    Io(#[from] std::io::Error),
    
    #[error("Invalid input: {0}")]
    InvalidInput(String),
}

pub fn process_data(input: &str) -> Result<Data, MyError> {
    // Implementation
}
```

## Documentation

- **Public APIs**: Must have doc comments (`///`)
- **Examples**: Include examples in doc comments
- **Modules**: Document module purpose with `//!`
- **Unsafe**: Always document safety requirements for `unsafe` code
- **Run doctests**: `cargo test --doc`

Example:
```rust
/// Processes the input data and returns a result.
///
/// # Arguments
///
/// * `input` - The input string to process
///
/// # Examples
///
/// ```
/// use mylib::process;
/// let result = process("hello");
/// assert_eq!(result, "HELLO");
/// ```
///
/// # Errors
///
/// Returns `MyError::InvalidInput` if input is empty.
pub fn process(input: &str) -> Result<String, MyError> {
    // Implementation
}
```

## Project Structure

```
project/
‚îú‚îÄ‚îÄ Cargo.toml          # Package manifest
‚îú‚îÄ‚îÄ Cargo.lock          # Dependency lock file (commit this)
‚îú‚îÄ‚îÄ README.md           # Project overview (allowed in root)
‚îú‚îÄ‚îÄ CHANGELOG.md        # Version history (allowed in root)
‚îú‚îÄ‚îÄ AGENTS.md          # AI assistant rules (allowed in root)
‚îú‚îÄ‚îÄ LICENSE            # Project license (allowed in root)
‚îú‚îÄ‚îÄ CONTRIBUTING.md    # Contribution guidelines (allowed in root)
‚îú‚îÄ‚îÄ CODE_OF_CONDUCT.md # Code of conduct (allowed in root)
‚îú‚îÄ‚îÄ SECURITY.md        # Security policy (allowed in root)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ lib.rs          # Library root (for libraries)
‚îÇ   ‚îú‚îÄ‚îÄ main.rs         # Binary root (for applications)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ tests/              # Integration tests
‚îú‚îÄ‚îÄ examples/           # Example code
‚îú‚îÄ‚îÄ benches/            # Benchmarks
‚îî‚îÄ‚îÄ docs/               # Project documentation
```

## CI/CD Requirements

Must include GitHub Actions workflows for:

1. **Testing** (`rust-test.yml`):
   - Test on ubuntu-latest, windows-latest, macos-latest
   - Use `cargo-nextest` for fast test execution
   - Upload test results

2. **Linting** (`rust-lint.yml`):
   - Format check: `cargo +nightly fmt --all -- --check`
   - Clippy: `cargo clippy --workspace -- -D warnings`
   - All targets: `cargo clippy --workspace --all-targets -- -D warnings`

3. **Codespell** (`codespell.yml`):
   - Check for typos in code and documentation
   - Fail on errors

## Crate Publication

### Publishing to crates.io

**Prerequisites:**
1. Create account at https://crates.io
2. Generate API token: `cargo login`
3. Add `CARGO_TOKEN` to GitHub repository secrets

**Cargo.toml Configuration:**

```toml
[package]
name = "your-crate-name"
version = "1.0.0"
edition = "2024"
authors = ["Your Name <your.email@example.com>"]
license = "MIT OR Apache-2.0"
description = "A short description of your crate"
documentation = "https://docs.rs/your-crate-name"
homepage = "https://github.com/your-org/your-crate-name"
repository = "https://github.com/your-org/your-crate-name"
readme = "README.md"
keywords = ["your", "keywords", "here"]
categories = ["category"]
exclude = [
    ".github/",
    "tests/",
    "benches/",
    "examples/",
    "*.sh",
]

[package.metadata.docs.rs]
all-features = true
rustdoc-args = ["--cfg", "docsrs"]
```

**Publishing Workflow:**

1. Update version in Cargo.toml
2. Update CHANGELOG.md
3. Run quality checks:
   ```bash
   cargo fmt --all
   cargo clippy --workspace --all-targets -- -D warnings
   cargo test --all-features
   cargo doc --no-deps --all-features
   ```
4. Create git tag: `git tag v1.0.0 && git push --tags`
5. GitHub Actions automatically publishes to crates.io
6. Or manual publish: `cargo publish`

**Publishing Checklist:**

- ‚úÖ All tests passing (`cargo test --all-features`)
- ‚úÖ No clippy warnings (`cargo clippy -- -D warnings`)
- ‚úÖ Code formatted (`cargo fmt --all -- --check`)
- ‚úÖ Documentation builds (`cargo doc --no-deps`)
- ‚úÖ Version updated in Cargo.toml
- ‚úÖ CHANGELOG.md updated
- ‚úÖ README.md up to date
- ‚úÖ LICENSE file present
- ‚úÖ Package size < 10MB (check with `cargo package --list`)
- ‚úÖ Verify with `cargo publish --dry-run`

**Semantic Versioning:**

Follow [SemVer](https://semver.org/) strictly:
- **MAJOR**: Breaking API changes
- **MINOR**: New features (backwards compatible)
- **PATCH**: Bug fixes (backwards compatible)

**Documentation:**

- Use `///` for public API documentation
- Include examples in doc comments
- Use `#![deny(missing_docs)]` for libraries
- Test documentation examples with `cargo test --doc`

```rust
/// Processes the input data and returns a result.
///
/// # Arguments
///
/// * `input` - The input string to process
///
/// # Examples
///
/// ```
/// use your_crate::process;
///
/// let result = process("hello");
/// assert_eq!(result, "HELLO");
/// ```
///
/// # Errors
///
/// Returns an error if the input is empty.
pub fn process(input: &str) -> Result<String, Error> {
    // Implementation
}
```

<!-- RUST:END -->


<!-- RULEBOOK:SKILL:languages/rust:END -->

<!-- RULEBOOK:SKILL:core/agent-automation:START -->
<!-- AGENT_AUTOMATION:START -->
# Agent Automation Rules

**CRITICAL**: Mandatory workflow that AI agents MUST execute after EVERY implementation.

## Workflow Overview

After completing ANY feature, bug fix, or code change, execute this workflow in order:

### Step 1: Quality Checks (MANDATORY)

Run these checks in order - ALL must pass:

```bash
1. Type check (if applicable)
2. Lint (MUST pass with ZERO warnings)
3. Format code
4. Run ALL tests (MUST pass 100%)
5. Verify coverage meets threshold (default 95%)
```

**Language-specific commands**: See your language template (TYPESCRIPT, RUST, PYTHON, etc.) for exact commands.

**IF ANY CHECK FAILS:**
- ‚ùå STOP immediately
- ‚ùå DO NOT proceed
- ‚ùå DO NOT commit
- ‚úÖ Fix the issue first
- ‚úÖ Re-run ALL checks

### Step 2: Security & Dependency Audits

```bash
# Check for vulnerabilities (language-specific)
# Check for outdated dependencies (informational)
# Find unused dependencies (optional)
```

**Language-specific commands**: See your language template for audit commands.

**IF VULNERABILITIES FOUND:**
- ‚úÖ Attempt automatic fix
- ‚úÖ Document if auto-fix fails
- ‚úÖ Include in Step 5 report
- ‚ùå Never ignore critical/high vulnerabilities without user approval

### Step 3: Update OpenSpec Tasks

If `openspec/` directory exists:

```bash
# Mark completed tasks as [DONE]
# Update in-progress tasks
# Add new tasks if discovered
# Update progress percentages
# Document deviations or blockers
```

### Step 4: Update Documentation

```bash
# Update ROADMAP.md (if feature is milestone)
# Update CHANGELOG.md (conventional commits format)
# Update feature specs (if implementation differs)
# Update README.md (if public API changed)
```

### Step 5: Git Commit

**ONLY after ALL above steps pass:**

**‚ö†Ô∏è CRITICAL: All commit messages MUST be in English**

```bash
git add .
git commit -m "<type>(<scope>): <description>

- Detailed change 1
- Detailed change 2
- Tests: [describe coverage]
- Coverage: X% (threshold: 95%)

Closes #<issue> (if applicable)"
```

**Commit Types**: `feat`, `fix`, `docs`, `refactor`, `perf`, `test`, `build`, `ci`, `chore`

**Language Requirement**: Commit messages must be written in English. Never use Portuguese, Spanish, or any other language.

### Step 6: Report to User

```
‚úÖ Implementation Complete

üìù Changes:
- [List main changes]

üß™ Quality Checks:
- ‚úÖ Type check: Passed
- ‚úÖ Linting: Passed (0 warnings)
- ‚úÖ Formatting: Applied
- ‚úÖ Tests: X/X passed (100%)
- ‚úÖ Coverage: X% (threshold: 95%)

üîí Security:
- ‚úÖ No vulnerabilities

üìä OpenSpec:
- ‚úÖ Tasks updated
- ‚úÖ Progress: X% ‚Üí Y%

üìö Documentation:
- ‚úÖ CHANGELOG.md updated
- ‚úÖ [other docs updated]

üíæ Git:
- ‚úÖ Committed: <commit message>
- ‚úÖ Hash: <commit hash>

üìã Next Steps:
- [ ] Review changes
- [ ] Push to remote (if ready)
```

## Automation Exceptions

Skip steps ONLY when:

1. **Exploratory Code**: User says "experimental", "draft", "try"
   - Still run quality checks
   - Don't commit

2. **User Explicitly Requests**: User says "skip tests", "no commit"
   - Only skip requested step
   - Warn about skipped steps

3. **Emergency Hotfix**: Critical production bug
   - Run minimal checks
   - Document technical debt

**In ALL other cases: Execute complete workflow**

## Error Recovery

If workflow fails 3+ times:

```bash
1. Create backup branch
2. Reset to last stable commit
3. Report to user with error details
4. Request guidance or try alternative approach
```

## Best Practices

### DO's ‚úÖ
- ALWAYS run complete workflow
- ALWAYS update OpenSpec and documentation
- ALWAYS use conventional commits
- ALWAYS report summary to user
- ASK before skipping steps

### DON'Ts ‚ùå
- NEVER skip quality checks without permission
- NEVER commit failing tests
- NEVER commit linting errors
- NEVER skip documentation updates
- NEVER assume user wants to skip automation
- NEVER commit debug code or secrets

## Summary

**Complete workflow after EVERY implementation:**

1. ‚úÖ Quality checks (type, lint, format, test, coverage)
2. ‚úÖ Security audit
3. ‚úÖ Update OpenSpec tasks
4. ‚úÖ Update documentation
5. ‚úÖ Git commit (conventional format)
6. ‚úÖ Report summary to user

**Only skip with explicit user permission and document why.**

<!-- AGENT_AUTOMATION:END -->

<!-- RULEBOOK:SKILL:core/agent-automation:END -->

<!-- RULEBOOK:SKILL:core/dag:START -->
<!-- DAG:START -->
# Dependency Architecture Guidelines (DAG)

**CRITICAL**: Maintain a clean dependency graph (DAG) to prevent circular dependencies and ensure maintainable architecture.

## Core Principles

### No Circular Dependencies
- **NEVER** create circular dependencies between components
- **ALWAYS** ensure dependencies form a Directed Acyclic Graph (DAG)
- **ALWAYS** validate dependency structure before committing

### Layer Separation
- **ALWAYS** maintain clear layer boundaries
- **ALWAYS** ensure higher layers depend only on lower layers
- **NEVER** allow lower layers to depend on higher layers

### Interface Boundaries
- **ALWAYS** use interfaces for cross-component communication
- **ALWAYS** define clear contracts between components
- **NEVER** create tight coupling between components

## Dependency Rules

### Layer Architecture

**Layer 1: Foundation**
- Utils, helpers, utilities
- Type definitions
- Configuration management
- Base constants and enums

**Layer 2: Core**
- Core business logic
- Data models and schemas
- Base services and repositories
- Domain entities

**Layer 3: Features**
- Feature implementations
- Business logic
- API endpoints
- Service orchestration

**Layer 4: Presentation**
- UI components
- CLI interfaces
- API controllers
- View models

### Dependency Flow

```
Foundation ‚Üí Core ‚Üí Features ‚Üí Presentation
```

**Rules:**
- ‚úÖ Foundation can depend on nothing (or external libraries only)
- ‚úÖ Core can depend on Foundation
- ‚úÖ Features can depend on Core and Foundation
- ‚úÖ Presentation can depend on Features, Core, and Foundation
- ‚ùå Foundation CANNOT depend on Core, Features, or Presentation
- ‚ùå Core CANNOT depend on Features or Presentation
- ‚ùå Features CANNOT depend on Presentation

## Component Graph Structure

### Example Valid DAG

```
Core
  ‚îú‚îÄ‚îÄ Utils
  ‚îú‚îÄ‚îÄ Types
  ‚îî‚îÄ‚îÄ Config

Features
  ‚îú‚îÄ‚îÄ Feature A
  ‚îÇ   ‚îî‚îÄ‚îÄ Core
  ‚îî‚îÄ‚îÄ Feature B
      ‚îú‚îÄ‚îÄ Core
      ‚îî‚îÄ‚îÄ Feature A

Presentation
  ‚îú‚îÄ‚îÄ CLI
  ‚îÇ   ‚îî‚îÄ‚îÄ Features
  ‚îî‚îÄ‚îÄ API
      ‚îî‚îÄ‚îÄ Features
```

### Invalid Patterns (Circular Dependencies)

```
‚ùå Feature A ‚Üí Feature B ‚Üí Feature A
‚ùå Core ‚Üí Feature ‚Üí Core
‚ùå Utils ‚Üí Core ‚Üí Utils
```

## Verification

### Before Committing

**MANDATORY**: Verify dependency structure:

```bash
# Check for circular dependencies
# Add your dependency check command here
# Examples:
# - TypeScript: tsc --noEmit (catches import cycles)
# - Rust: cargo check (catches circular dependencies)
# - Python: pylint --disable=all --enable=import-error
# - Go: go vet ./...
```

### Dependency Analysis Tools

**TypeScript/JavaScript:**
```bash
# Use madge to detect circular dependencies
npx madge --circular src/

# Use dependency-cruiser
npx dependency-cruiser --validate src/
```

**Rust:**
```bash
# Cargo automatically detects circular dependencies
cargo check
```

**Python:**
```bash
# Use vulture or pylint
pylint --disable=all --enable=import-error src/
```

**Go:**
```bash
# Use go vet
go vet ./...
```

## Best Practices

### DO's ‚úÖ

- **ALWAYS** maintain clear layer boundaries
- **ALWAYS** validate dependencies before committing
- **ALWAYS** use interfaces for cross-layer communication
- **ALWAYS** document component dependencies
- **ALWAYS** refactor when circular dependencies are detected
- **ALWAYS** keep dependency graph shallow (avoid deep nesting)

### DON'Ts ‚ùå

- **NEVER** create circular dependencies
- **NEVER** allow lower layers to depend on higher layers
- **NEVER** create tight coupling between components
- **NEVER** skip dependency validation
- **NEVER** mix concerns across layers
- **NEVER** create bidirectional dependencies

## Dependency Documentation

### Documenting Dependencies

**In code:**
```typescript
// Component: UserService
// Dependencies:
//   - UserRepository (Core layer)
//   - Logger (Foundation layer)
//   - Config (Foundation layer)
// Does NOT depend on:
//   - UserController (Presentation layer)
//   - UserAPI (Presentation layer)
```

**In documentation:**
- Maintain `docs/DAG.md` with component dependency graph
- Update when adding new components
- Include dependency direction and purpose

## Refactoring Circular Dependencies

### When Circular Dependency is Detected

1. **Identify the cycle**: Map the dependency chain
2. **Find common dependency**: Extract shared functionality
3. **Introduce interface**: Use dependency inversion
4. **Restructure layers**: Move components to appropriate layer
5. **Validate fix**: Run dependency check again

### Example Refactoring

**Before (Circular):**
```
Feature A ‚Üí Feature B ‚Üí Feature A
```

**After (Fixed):**
```
Core
  ‚îî‚îÄ‚îÄ SharedService

Feature A ‚Üí Core
Feature B ‚Üí Core
```

## Integration with AGENT_AUTOMATION

**CRITICAL**: Include dependency validation in AGENT_AUTOMATION workflow:

```bash
# Step 1.5: Dependency Validation (before implementation)
# Check for circular dependencies
npm run check-deps  # or equivalent for your language

# If circular dependencies detected:
# ‚ùå STOP - Fix architecture first
# ‚úÖ Refactor to remove cycles
# ‚úÖ Re-validate before proceeding
```

## Language-Specific Guidelines

### TypeScript/JavaScript
- Use `madge` or `dependency-cruiser` for validation
- Configure ESLint rules for import ordering
- Use path aliases to enforce layer structure

### Rust
- Cargo automatically detects circular dependencies
- Use `cargo tree` to visualize dependencies
- Organize modules to reflect layer structure

### Python
- Use `pylint` or `vulture` for import analysis
- Organize packages to reflect layer structure
- Use `__init__.py` to control exports

### Go
- Use `go vet` for dependency validation
- Organize packages in directories reflecting layers
- Use interfaces to decouple components

## Examples

### Good Architecture ‚úÖ

```
src/
‚îú‚îÄ‚îÄ foundation/
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ types/
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ repositories/
‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îú‚îÄ‚îÄ auth/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ (depends on core, foundation)
‚îÇ   ‚îî‚îÄ‚îÄ payments/
‚îÇ       ‚îî‚îÄ‚îÄ (depends on core, foundation)
‚îî‚îÄ‚îÄ presentation/
    ‚îú‚îÄ‚îÄ cli/
    ‚îÇ   ‚îî‚îÄ‚îÄ (depends on features, core, foundation)
    ‚îî‚îÄ‚îÄ api/
        ‚îî‚îÄ‚îÄ (depends on features, core, foundation)
```

### Bad Architecture ‚ùå

```
src/
‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îî‚îÄ‚îÄ auth/
‚îÇ       ‚îî‚îÄ‚îÄ (depends on presentation)  # ‚ùå Wrong direction
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îî‚îÄ‚îÄ (depends on features)  # ‚ùå Wrong direction
‚îî‚îÄ‚îÄ presentation/
    ‚îî‚îÄ‚îÄ (depends on foundation only)  # ‚ùå Missing dependencies
```

## Maintenance

### Regular Checks

- **Before every commit**: Run dependency validation
- **Weekly**: Review dependency graph for optimization
- **Before major refactoring**: Document current dependencies
- **After adding new components**: Update DAG documentation

### Tools Integration

Add dependency checks to:
- Pre-commit hooks
- CI/CD pipelines
- AGENT_AUTOMATION workflow
- Quality gates

<!-- DAG:END -->


<!-- RULEBOOK:SKILL:core/dag:END -->

<!-- RULEBOOK:SKILL:core/documentation-rules:START -->
# Documentation Standards

**CRITICAL**: All documentation in English. Root README concise, detailed docs in `/docs`.

## Structure

**Root-Level (ONLY):**
- `README.md` - Overview + quick start
- `CHANGELOG.md` - Version history
- `AGENTS.md` - AI instructions
- `LICENSE`, `CONTRIBUTING.md`, `SECURITY.md`

**All Other Docs in `/docs`:**
- `ARCHITECTURE.md`, `DEVELOPMENT.md`, `ROADMAP.md`
- `specs/`, `guides/`, `diagrams/`, `benchmarks/`

## Update Requirements by Commit Type

| Type | Update |
|------|--------|
| `feat` | README features, API docs, CHANGELOG "Added" |
| `fix` | Troubleshooting, CHANGELOG "Fixed" |
| `breaking` | CHANGELOG + migration guide, version docs |
| `perf` | Benchmarks, CHANGELOG "Performance" |
| `security` | SECURITY.md, CHANGELOG "Security" |
| `docs` | Verify spelling/links only |
| `refactor` | Update if behavior changed |

## Quality Checks (CI/CD)

```bash
markdownlint **/*.md         # Lint markdown
markdown-link-check **/*.md  # Check links
codespell **/*.md            # Spell check
```

**MUST pass before commit** (see AGENT_AUTOMATION).
<!-- RULEBOOK:SKILL:core/documentation-rules:END -->

<!-- RULEBOOK:SKILL:core/quality-enforcement:START -->
<!-- QUALITY_ENFORCEMENT:START -->
# Quality Enforcement Rules

**CRITICAL**: These rules are NON-NEGOTIABLE and MUST be followed without exception.

## Absolute Prohibitions

### Test Bypassing - STRICTLY FORBIDDEN
- NEVER use .skip(), .only(), or .todo() to bypass failing tests
- NEVER comment out failing tests
- NEVER use @ts-ignore, @ts-expect-error, or similar to hide test errors
- NEVER mock/stub functionality just to make tests pass without fixing root cause
- FIX the actual problem causing test failures

### Git Hook Bypassing - STRICTLY FORBIDDEN  
- NEVER use --no-verify flag on git commit
- NEVER use --no-verify flag on git push
- NEVER disable or skip pre-commit hooks
- NEVER disable or skip pre-push hooks
- FIX the issues that hooks are detecting

### Test Implementation - STRICTLY FORBIDDEN
- NEVER create boilerplate tests that don't actually test behavior
- NEVER write tests that always pass regardless of implementation
- NEVER write tests without assertions
- NEVER mock everything to avoid testing real behavior
- WRITE meaningful tests that verify actual functionality

### Problem Solving Approach - REQUIRED
- DO NOT seek the simplest bypass or workaround
- DO NOT be creative with shortcuts that compromise quality
- DO solve problems properly following best practices
- DO use proven, established solutions from decades of experience
- DO fix root causes, not symptoms

### Temporary Files and Scripts - STRICTLY FORBIDDEN
- **NEVER** create temporary files in project root or any directory outside `/scripts`
- **NEVER** create test files, log files, or debug files outside `/scripts`
- **NEVER** leave temporary files after use - they MUST be deleted immediately
- **ALWAYS** create all scripts inside `/scripts` directory
- **ALWAYS** remove temporary files immediately after use (MANDATORY)
- **ALWAYS** clean up test artifacts, log files, and debug files before committing
- **ALWAYS** use `/scripts` directory for any temporary scripts or test files

**Why This Matters:**
LLM assistants often create temporary files for testing but forget to remove them, accumulating dozens of junk files that pollute the repository. All temporary work MUST be done in `/scripts` and cleaned up immediately.

**Examples:**
- ‚ùå Creating `test.js`, `debug.log`, `temp.json` in project root
- ‚ùå Leaving test files after debugging
- ‚ùå Creating scripts outside `/scripts` directory
- ‚úÖ Creating `/scripts/test-feature.js` and removing it after use
- ‚úÖ Using `/scripts` for all temporary work
- ‚úÖ Cleaning up all temporary files before committing

## Enforcement

These rules apply to ALL implementations:
- Bug fixes
- New features  
- Refactoring
- Documentation changes
- Any code modifications

**Violation = Implementation Rejected**

<!-- QUALITY_ENFORCEMENT:END -->


<!-- RULEBOOK:SKILL:core/quality-enforcement:END -->

<!-- RULEBOOK:SKILL:core/rulebook:START -->
<!-- RULEBOOK:START -->
# Rulebook Task Management

**CRITICAL**: Use Rulebook's built-in task management system for spec-driven development of new features and breaking changes.

## When to Use

Create tasks for:
- ‚úÖ New features/capabilities
- ‚úÖ Breaking changes
- ‚úÖ Architecture changes  
- ‚úÖ Performance/security work

Skip for:
- ‚ùå Bug fixes (restore intended behavior)
- ‚ùå Typos, formatting, comments
- ‚ùå Dependency updates (non-breaking)

## ‚ö†Ô∏è CRITICAL: Task Creation is MANDATORY Before Implementation

**ABSOLUTE RULE**: You MUST create a task BEFORE implementing ANY feature.

### Why This Matters

**Without task registration:**
- ‚ùå Tasks can be lost in context
- ‚ùå No tracking of implementation progress
- ‚ùå No record of what was done and why
- ‚ùå Difficult to resume work after context loss
- ‚ùå No validation of completion criteria

**With task registration:**
- ‚úÖ All features are tracked and documented
- ‚úÖ Progress is visible and measurable
- ‚úÖ Implementation history is preserved
- ‚úÖ Easy to resume work from any point
- ‚úÖ Clear completion criteria

### MANDATORY Workflow

**NEVER start implementation without creating a task first:**

```bash
# ‚ùå WRONG: Starting implementation directly
# ... writing code without task ...

# ‚úÖ CORRECT: Create task first
rulebook task create <task-id>
# Write proposal.md
# Write tasks.md
# Write spec deltas
rulebook task validate <task-id>
# NOW you can start implementation
```

### Task Creation Before Any Feature Request

**When a feature is requested:**

1. **STOP** - Do not start coding
2. **Create task** - `rulebook task create <task-id>`
3. **Plan** - Write proposal.md and tasks.md
4. **Spec** - Write spec deltas
5. **Validate** - `rulebook task validate <task-id>`
6. **THEN** - Start implementation

**Example:**
```
User: "Add user authentication feature"

‚ùå WRONG: Start coding immediately
‚úÖ CORRECT:
  1. rulebook task create add-user-authentication
  2. Write proposal.md explaining why and what
  3. Write tasks.md with implementation checklist
  4. Write specs/core/spec.md with requirements
  5. rulebook task validate add-user-authentication
  6. NOW start implementing
```

## CRITICAL: Task Creation Workflow

**MANDATORY STEPS** - Follow in this exact order:

### Step 1: Check Context7 MCP (MANDATORY)

**BEFORE creating ANY task, you MUST:**

1. **Query Context7 for OpenSpec documentation** (Rulebook uses OpenSpec-compatible format):
   ```
   @Context7 /fission-ai/openspec task creation format spec structure
   ```

2. **Review official format requirements**:
   - Spec delta file format
   - Requirement structure
   - Scenario formatting
   - Delta headers (ADDED/MODIFIED/REMOVED/RENAMED)

3. **Verify format requirements**:
   - Scenario MUST use `#### Scenario:` (4 hashtags, NOT 3, NOT bullets)
   - Requirements MUST use `### Requirement: [Name]`
   - MUST include SHALL/MUST statement after requirement name
   - MUST include at least one scenario per requirement
   - Purpose section MUST have minimum 20 characters

**Why This Matters:**
Most AI assistants create tasks with incorrect formats (wrong scenario headers, missing SHALL statements, incomplete deltas). Context7 provides the official format documentation that prevents validation failures.

### Step 2: Explore Current State

```bash
# List existing tasks
rulebook task list

# List active changes
rulebook task list --active

# View task details
rulebook task show <task-id>
```

### Step 3: Choose Task ID

- Use **verb-led** kebab-case: `add-auth`, `update-api`, `remove-feature`, `refactor-module`
- Must be unique (check existing tasks)
- Descriptive and focused (one capability per task)

### Step 4: Create Task Structure

```bash
# Create new task
rulebook task create <task-id>

# This creates:
# /rulebook/tasks/<task-id>/
#   ‚îú‚îÄ‚îÄ proposal.md       # Why and what changes
#   ‚îú‚îÄ‚îÄ tasks.md          # Implementation checklist
#   ‚îú‚îÄ‚îÄ design.md         # Technical decisions (optional)
#   ‚îî‚îÄ‚îÄ specs/
#       ‚îî‚îÄ‚îÄ <module>/
#           ‚îî‚îÄ‚îÄ spec.md   # Delta showing additions/modifications
```

### Step 5: Write Proposal

**File**: `/rulebook/tasks/<task-id>/proposal.md`

```markdown
# Proposal: Task Name

## Why
Minimum 20 characters explaining why this change is needed.
Provide context, motivation, and business/technical rationale.

## What Changes
Detailed description of what will change:
- Specific components affected
- New features or capabilities
- Breaking changes (if any)
- Migration path (if applicable)

## Impact
- Affected specs: list spec names
- Affected code: list files/modules
- Breaking change: YES/NO
- User benefit: describe benefits
```

### Step 6: Write Tasks Checklist

**File**: `/rulebook/tasks/<task-id>/tasks.md`

```markdown
## 1. Implementation Phase
- [ ] 1.1 First task item
- [ ] 1.2 Second task item

## 2. Testing Phase
- [ ] 2.1 Write unit tests
- [ ] 2.2 Write integration tests

## 3. Documentation Phase
- [ ] 3.1 Update README
- [ ] 3.2 Update CHANGELOG
```

### Step 7: Write Spec Delta

**File**: `/rulebook/tasks/<task-id>/specs/<module>/spec.md`

**CRITICAL FORMAT REQUIREMENTS:**

```markdown
# Specification Name

## ADDED Requirements

### Requirement: Feature Name
The system SHALL/MUST do something specific and testable.
Every requirement needs SHALL or MUST keyword.

#### Scenario: Scenario Name
Given some precondition
When an action occurs
Then an expected outcome happens

## MODIFIED Requirements

### Requirement: Existing Feature
The system SHALL/MUST do something modified.

#### Scenario: Modified scenario
Given updated precondition
When action occurs
Then new expected outcome

## REMOVED Requirements

### Requirement: Deprecated Feature
[Description of what is being removed]

## RENAMED Requirements
- FROM: `### Requirement: Old Name`
- TO: `### Requirement: New Name`
```

**Format Rules:**
- ‚úÖ Purpose section: Minimum 20 characters
- ‚úÖ Requirements: Must contain SHALL or MUST
- ‚úÖ Scenarios: Use `#### Scenario:` (4 hashtags)
- ‚úÖ Scenarios: Use Given/When/Then structure
- ‚úÖ Deltas: Use ADDED/MODIFIED/REMOVED/RENAMED headers
- ‚ùå NEVER use 3 hashtags for scenarios
- ‚ùå NEVER use bullet points for scenarios
- ‚ùå NEVER omit SHALL/MUST from requirements

### Step 8: Validate Task

```bash
# Validate task format
rulebook task validate <task-id>

# Validate with strict mode (recommended)
rulebook task validate <task-id> --strict

# Validate all tasks
rulebook task validate --all
```

**Validation checks:**
- Purpose section length (‚â•20 chars)
- Requirement keywords (SHALL/MUST)
- Scenario format (4 hashtags)
- Given/When/Then structure
- Delta headers format

### Step 9: Update Task Status

```bash
# Mark task as in progress
rulebook task update <task-id> --status in-progress

# Update task progress
rulebook task update <task-id> --progress 50

# Mark task as completed
rulebook task update <task-id> --status completed
```

### Step 10: Archive Completed Task

```bash
# Archive completed task
rulebook task archive <task-id>

# Archive without prompts
rulebook task archive <task-id> --yes
```

**Archive process:**
1. Validates task format
2. Checks task completion status
3. Applies spec deltas to main specifications
4. Moves task to `/rulebook/tasks/archive/YYYY-MM-DD-<task-id>/`
5. Updates related specifications

## Task Format Examples

### Correct Format ‚úÖ

```markdown
# Auth Specification

## ADDED Requirements

### Requirement: Two-Factor Authentication
The system MUST require a second factor during login for enhanced security.

#### Scenario: OTP required
Given a user submits valid credentials
When authentication starts
Then an OTP challenge is required

#### Scenario: OTP verification
Given a user receives an OTP code
When they submit the correct OTP
Then they are authenticated successfully
```

### Incorrect Format ‚ùå

```markdown
# Auth Specification

## Requirements

### Requirement: Two-Factor Authentication
The system requires a second factor.  # ‚ùå Missing SHALL/MUST

#### Scenario: OTP required  # ‚ùå Only 3 hashtags
- WHEN user submits credentials  # ‚ùå Using bullets instead of Given/When/Then
- THEN OTP challenge is required
```

## Common Pitfalls & How to Avoid Them

### Top 5 Mistakes AI Assistants Make

1. **Wrong Scenario Headers**
   - ‚ùå `### Scenario:` (3 hashtags)
   - ‚úÖ `#### Scenario:` (4 hashtags)

2. **Missing SHALL/MUST Keywords**
   - ‚ùå "The system provides authentication"
   - ‚úÖ "The system SHALL provide authentication"

3. **Using Bullets for Scenarios**
   - ‚ùå `- WHEN user does X THEN Y happens`
   - ‚úÖ `Given X\nWhen Y\nThen Z`

4. **Incomplete Purpose Section**
   - ‚ùå "Auth system" (too short)
   - ‚úÖ "Authentication system for secure user access with JWT tokens and session management" (‚â•20 chars)

5. **Wrong Delta Headers**
   - ‚ùå `## New Requirements` or `## Changes`
   - ‚úÖ `## ADDED Requirements`, `## MODIFIED Requirements`, etc.

## Integration with AGENT_AUTOMATION

**CRITICAL**: After implementing a task, follow AGENT_AUTOMATION workflow:

1. Run quality checks (lint, test, type-check, build)
2. Update task status in `tasks.md`
3. Update documentation (ROADMAP, CHANGELOG, specs)
4. Commit with conventional commit format
5. Archive task when complete

## ‚ö†Ô∏è CRITICAL: Git Hooks Will Block Commits with Problems

**ABSOLUTE RULE**: Pre-commit and pre-push hooks will **BLOCK** any commit attempt if there are:
- ‚ùå Lint errors or warnings
- ‚ùå Test failures
- ‚ùå Type check errors
- ‚ùå Formatting issues
- ‚ùå Coverage below thresholds

### Why This Matters

**DO NOT attempt to commit code with problems:**
- ‚ùå `git commit` will **FAIL** if lint has errors
- ‚ùå `git commit` will **FAIL** if tests are failing
- ‚ùå `git push` will **FAIL** if pre-push checks fail
- ‚ùå You will waste time trying to commit broken code
- ‚ùå The hooks will reject your commit automatically

**ALWAYS fix problems BEFORE attempting to commit:**
- ‚úÖ Run `npm run lint` and fix ALL errors/warnings first
- ‚úÖ Run `npm test` and ensure ALL tests pass
- ‚úÖ Run `npm run type-check` and fix ALL type errors
- ‚úÖ Run `npm run format` if formatting is required
- ‚úÖ Run `npm test -- --coverage` and ensure coverage thresholds are met
- ‚úÖ **ONLY THEN** attempt `git commit`

### Mandatory Pre-Commit Workflow

**BEFORE every commit, you MUST:**

```bash
# 1. Fix lint errors FIRST (highest priority)
npm run lint
# Fix ALL errors and warnings
# If lint fails, commit will be blocked

# 2. Fix test failures SECOND
npm test
# Fix ALL failing tests
# If tests fail, commit will be blocked

# 3. Fix type errors THIRD
npm run type-check
# Fix ALL type errors
# If type check fails, commit will be blocked

# 4. Fix formatting (if required)
npm run format
# Apply formatting fixes

# 5. Verify coverage (if required by hooks)
npm test -- --coverage
# Ensure coverage thresholds are met

# 6. ONLY AFTER all checks pass, attempt commit
git add .
git commit -m "feat: your commit message"
# This will now succeed because all checks passed
```

### What Happens If You Try to Commit with Problems

**Example of blocked commit:**

```bash
$ git commit -m "feat: add new feature"

üîç Running TypeScript/JavaScript pre-commit checks...
  ‚Üí Type checking...
  ‚Üí Linting...

/mnt/f/project/src/feature.ts
   42:19  error  Unexpected any. Specify a different type  @typescript-eslint/no-explicit-any

‚úñ 1 problem (1 error, 0 warnings)

‚ùå Commit blocked: Lint errors found
```

**You MUST fix the error before committing:**

```bash
# Fix the lint error
# ... edit code to fix the issue ...

# Run lint again to verify
npm run lint
# ‚úÖ All checks pass

# NOW commit will succeed
git commit -m "feat: add new feature"
# ‚úÖ Commit successful
```

### ‚ö†Ô∏è CRITICAL: NEVER Use --no-verify to Bypass Hooks

**ABSOLUTE PROHIBITION**: You MUST NEVER use `--no-verify` or `--no-gpg-sign` flags to bypass git hooks.

**FORBIDDEN COMMANDS:**
- ‚ùå `git commit --no-verify` - **NEVER USE THIS**
- ‚ùå `git commit -n` - **NEVER USE THIS** (short form of --no-verify)
- ‚ùå `git push --no-verify` - **NEVER USE THIS**
- ‚ùå Any flag that skips pre-commit or pre-push hooks

### Why This Is Prohibited

**Using `--no-verify` defeats the entire purpose of quality gates:**
- ‚ùå Allows broken code to be committed
- ‚ùå Bypasses all quality checks (lint, test, type-check)
- ‚ùå Introduces technical debt and bugs
- ‚ùå Violates project quality standards
- ‚ùå Can break the build for other developers
- ‚ùå Makes code review harder (reviewers see broken code)

**The hooks exist for a reason:**
- ‚úÖ They protect code quality
- ‚úÖ They prevent bugs from entering the codebase
- ‚úÖ They ensure consistency across the project
- ‚úÖ They catch errors before they reach production

### What to Do Instead

**If you're tempted to use `--no-verify`, it means:**
1. **You have problems that need fixing** - Fix them first
2. **You're trying to commit too early** - Complete the work properly
3. **You're rushing** - Slow down and do it right

**Correct approach:**

```bash
# ‚ùå WRONG: Trying to bypass hooks
git commit --no-verify -m "feat: add feature"
# This is FORBIDDEN - never do this

# ‚úÖ CORRECT: Fix problems first, then commit
npm run lint
# Fix all errors...

npm test
# Fix all failing tests...

npm run type-check
# Fix all type errors...

# NOW commit (hooks will pass)
git commit -m "feat: add feature"
# ‚úÖ Commit successful - all checks passed
```

### Summary

**CRITICAL RULES:**
- ‚ö†Ô∏è **NEVER** attempt to commit code with lint errors - hooks will block it
- ‚ö†Ô∏è **NEVER** attempt to commit code with test failures - hooks will block it
- ‚ö†Ô∏è **NEVER** attempt to commit code with type errors - hooks will block it
- ‚ö†Ô∏è **NEVER** use `--no-verify` or any flag to bypass hooks - **ABSOLUTELY FORBIDDEN**
- ‚ö†Ô∏è **ALWAYS** fix ALL problems BEFORE attempting to commit
- ‚ö†Ô∏è **ALWAYS** run quality checks manually before `git commit`
- ‚ö†Ô∏è **ALWAYS** ensure all checks pass before committing

**The hooks are there to protect code quality - they will NOT let broken code through. Always resolve problems first, then commit. Bypassing hooks is strictly prohibited and defeats the purpose of quality gates.**

## MANDATORY: Task List Updates During Implementation

**CRITICAL RULE**: You MUST update the task list (`tasks.md`) immediately after completing and testing each implementation step.

### When to Update Task List

**ALWAYS update `tasks.md` when:**
- ‚úÖ You complete a task item (mark as `[x]`)
- ‚úÖ You finish implementing a feature and it's tested
- ‚úÖ You complete a test suite
- ‚úÖ You finish documentation updates
- ‚úÖ You verify the implementation works correctly

**NEVER commit without updating `tasks.md` if you've made progress on a task.**

### How to Update Task List

1. **After Implementation**:
   ```markdown
   ## 1. Implementation Phase
   - [x] 1.1 Create task manager module  # ‚úÖ Mark as done
   - [x] 1.2 Add validation logic        # ‚úÖ Mark as done
   - [ ] 1.3 Add archive functionality   # Still pending
   ```

2. **After Testing**:
   ```markdown
   ## 2. Testing Phase
   - [x] 2.1 Write unit tests            # ‚úÖ Tests written and passing
   - [x] 2.2 Write integration tests     # ‚úÖ Tests written and passing
   - [ ] 2.3 Add E2E tests                # Still pending
   ```

3. **After Documentation**:
   ```markdown
   ## 3. Documentation Phase
   - [x] 3.1 Update README                # ‚úÖ Updated
   - [x] 3.2 Update CHANGELOG             # ‚úÖ Updated
   - [ ] 3.3 Update API docs              # Still pending
   ```

### Workflow: Implement ‚Üí Test ‚Üí Verify Coverage ‚Üí Update Tasks ‚Üí Commit ‚Üí Next Task

**MANDATORY SEQUENCE** for every implementation:

```bash
# 1. Implement the feature
# ... write code ...

# 2. Test the implementation
npm test
npm run lint
npm run type-check

# 3. Verify test coverage (CRITICAL)
npm test -- --coverage
# Check coverage thresholds are met
# Fix any coverage gaps before proceeding

# 4. Update tasks.md IMMEDIATELY after successful tests and coverage check
# Mark completed items as [x] in tasks.md
# Update task status if needed

# 5. Verify task status is updated before moving to next task
rulebook task show <task-id>
# Confirm status reflects current progress

# 6. Commit locally (BACKUP - do this frequently)
git add .
git commit -m "feat: implement task manager validation

- Complete task 1.2: Add validation logic
- All tests passing
- Coverage verified: 95%
- Updated tasks.md"

# 7. Keep remote repository updated (if configured)
# Check if remote is configured
git remote -v

# If remote exists, push regularly
git push origin <branch-name>

# If no remote configured, see setup instructions below

# 8. Only then proceed to next task
# Follow priority order (most critical first)
```

## ‚ö†Ô∏è CRITICAL: Frequent Local Commits for Backup

**ABSOLUTE RULE**: Commit locally frequently, even if just for backup purposes.

### Why Frequent Commits Matter

**Without frequent commits:**
- ‚ùå Risk of losing work if system crashes
- ‚ùå No recovery point if something goes wrong
- ‚ùå Difficult to revert to previous working state
- ‚ùå Lost context if session is interrupted

**With frequent commits:**
- ‚úÖ Work is backed up locally
- ‚úÖ Easy to recover from mistakes
- ‚úÖ Can revert to any previous state
- ‚úÖ Progress is preserved

### When to Commit Locally

**Commit locally whenever you:**
- ‚úÖ Complete a task item (even if not fully tested)
- ‚úÖ Finish implementing a feature (before full testing)
- ‚úÖ Fix a bug or issue
- ‚úÖ Update documentation
- ‚úÖ Make significant progress
- ‚úÖ Feel the need for a backup point
- ‚úÖ Are about to try something risky
- ‚úÖ Are switching to a different task

**Commit frequency:**
- **Minimum**: After completing each task item
- **Recommended**: Every 15-30 minutes of active work
- **Maximum**: As often as you feel necessary for safety

### Local Commit Workflow

```bash
# Quick local commit (backup)
git add .
git commit -m "wip: progress on task 1.2

- Implemented validation logic
- Still testing
- Backup commit"

# Or more descriptive
git add .
git commit -m "feat: add validation logic (WIP)

- Task 1.2 in progress
- Core validation implemented
- Tests pending
- Backup before continuing"
```

### Commit Message Format for Backup Commits

**For work-in-progress commits:**
```bash
git commit -m "wip: <brief description>

- What was done
- Current status
- Next steps"
```

**For completed task items:**
```bash
git commit -m "feat: <feature description>

- Complete task X.Y: <task name>
- All tests passing
- Coverage verified
- Updated tasks.md"
```

## ‚ö†Ô∏è CRITICAL: Keep Remote Repository Updated

**MANDATORY**: Keep your remote repository synchronized with local work.

### Check Remote Configuration

**First, check if remote is configured:**
```bash
git remote -v
```

**If you see output like:**
```
origin  https://github.com/user/repo.git (fetch)
origin  https://github.com/user/repo.git (push)
```
‚úÖ Remote is configured - proceed to push regularly

**If you see no output or error:**
‚ùå No remote configured - see setup instructions below

### Push to Remote Regularly

**After local commits, push to remote:**
```bash
# Push current branch
git push origin <branch-name>

# Or push current branch (if tracking is set)
git push

# Push with tags
git push --tags
```

**Recommended push frequency:**
- **Minimum**: After completing a task
- **Recommended**: After every 2-3 local commits
- **Maximum**: After every local commit (if working solo)

### Remote Repository Setup

**If no remote repository is configured:**

#### Option 1: GitHub (Recommended)

1. **Create repository on GitHub:**
   - Go to https://github.com/new
   - Create a new repository
   - **DO NOT** initialize with README, .gitignore, or license (if you already have local repo)

2. **Add remote and push:**
   ```bash
   # Add remote (replace with your repository URL)
   git remote add origin https://github.com/username/repo-name.git
   
   # Or using SSH
   git remote add origin git@github.com:username/repo-name.git
   
   # Push to remote
   git push -u origin main
   # Or 'master' if that's your default branch
   ```

3. **Verify:**
   ```bash
   git remote -v
   git push
   ```

**GitHub Setup Guide:**
- **Official Guide**: https://docs.github.com/en/get-started/quickstart/create-a-repo
- **Adding Remote**: https://docs.github.com/en/get-started/getting-started-with-git/managing-remote-repositories

#### Option 2: GitLab

1. **Create repository on GitLab:**
   - Go to https://gitlab.com/projects/new
   - Create a new project
   - **DO NOT** initialize with README (if you already have local repo)

2. **Add remote and push:**
   ```bash
   git remote add origin https://gitlab.com/username/repo-name.git
   git push -u origin main
   ```

**GitLab Setup Guide:**
- **Official Guide**: https://docs.gitlab.com/ee/gitlab-basics/create-project.html

#### Option 3: Bitbucket

1. **Create repository on Bitbucket:**
   - Go to https://bitbucket.org/repo/create
   - Create a new repository

2. **Add remote and push:**
   ```bash
   git remote add origin https://bitbucket.org/username/repo-name.git
   git push -u origin main
   ```

**Bitbucket Setup Guide:**
- **Official Guide**: https://support.atlassian.com/bitbucket-cloud/docs/create-a-git-repository/

#### Option 4: Self-Hosted Git Server

**If using self-hosted Git server:**
```bash
# Add remote
git remote add origin <your-git-server-url>

# Push
git push -u origin main
```

### Verify Remote is Working

**After setting up remote:**
```bash
# Check remote configuration
git remote -v

# Test push
git push origin main

# If successful, you'll see:
# "Enumerating objects: X, done."
# "Writing objects: 100% (X/X), done."
```

### Troubleshooting Remote Issues

**Error: "remote origin already exists"**
```bash
# Remove existing remote
git remote remove origin

# Add new remote
git remote add origin <new-url>
```

**Error: "authentication failed"**
- Check your credentials
- Use SSH keys for better security
- See: https://docs.github.com/en/authentication/connecting-to-github-with-ssh

**Error: "repository not found"**
- Verify repository URL is correct
- Check you have access to the repository
- Ensure repository exists on remote server

### Best Practices for Remote Sync

**DO's ‚úÖ:**
- ‚úÖ Push to remote after completing tasks
- ‚úÖ Push before switching branches
- ‚úÖ Push before trying risky changes
- ‚úÖ Push at end of work session
- ‚úÖ Use descriptive commit messages
- ‚úÖ Keep commits atomic (one logical change per commit)

**DON'Ts ‚ùå:**
- ‚ùå Don't push broken code (test first)
- ‚ùå Don't push sensitive information (API keys, passwords)
- ‚ùå Don't force push to shared branches
- ‚ùå Don't skip pushing for extended periods
- ‚ùå Don't commit without meaningful messages

### Automated Backup Reminder

**Set up reminders to push regularly:**
```bash
# Add to your shell profile (.bashrc, .zshrc, etc.)
alias git-backup='git add . && git commit -m "backup: $(date +%Y-%m-%d\ %H:%M:%S)" && git push'

# Use: git-backup (quick backup and push)
```

### Summary: Backup and Remote Sync Workflow

**Complete workflow:**
1. **Work locally** - Make changes
2. **Test changes** - Ensure they work
3. **Commit locally** - `git commit` (backup)
4. **Update tasks.md** - Mark progress
5. **Push to remote** - `git push` (if remote configured)
6. **Continue work** - Next task

**If no remote:**
1. **Set up remote** - Follow instructions above
2. **Push initial code** - `git push -u origin main`
3. **Continue regular pushes** - After each commit or task

### Priority Order: Most Critical First

**ALWAYS follow this priority order when continuing implementation:**

1. **Tests** (HIGHEST PRIORITY)
   - Write tests for the feature
   - Ensure all tests pass
   - Verify test coverage meets thresholds

2. **Coverage Verification** (CRITICAL)
   - Run coverage check: `npm test -- --coverage`
   - Fix any coverage gaps
   - Ensure coverage thresholds are met

3. **Update Task Status** (MANDATORY)
   - Mark completed items as `[x]` in `tasks.md`
   - Update task status if needed
   - Document what was completed

4. **Next Task** (Only after above steps)
   - Move to next most critical task
   - Follow same sequence

**Example Priority Order:**

```markdown
## Priority Order (Most Critical First)

### 1. Testing (CRITICAL - Do First)
- [ ] 1.1 Write unit tests for core functionality
- [ ] 1.2 Write integration tests
- [ ] 1.3 Verify test coverage ‚â• 95%

### 2. Coverage Verification (CRITICAL - Do Second)
- [ ] 2.1 Run coverage check
- [ ] 2.2 Fix coverage gaps
- [ ] 2.3 Verify thresholds met

### 3. Task Status Update (MANDATORY - Do Third)
- [ ] 3.1 Update tasks.md with completed items
- [ ] 3.2 Update task status
- [ ] 3.3 Document completion

### 4. Next Implementation (Only After Above)
- [ ] 4.1 Move to next critical task
- [ ] 4.2 Follow same sequence
```

### Never Skip Steps

**CRITICAL RULES:**
- ‚ùå NEVER proceed to next task without updating current task status
- ‚ùå NEVER skip test coverage verification
- ‚ùå NEVER mark tasks complete without tests passing
- ‚ùå NEVER implement without creating task first
- ‚úÖ ALWAYS update task status before moving to next task
- ‚úÖ ALWAYS verify coverage before marking task complete
- ‚úÖ ALWAYS follow priority order (most critical first)

### Task Status Tracking

**Track progress in `tasks.md`:**

```markdown
## Progress Summary
- Total tasks: 15
- Completed: 8
- In progress: 2
- Pending: 5
- Blocked: 0

## Current Status
- ‚úÖ Implementation Phase: 80% complete (4/5 tasks)
- ‚è≥ Testing Phase: 50% complete (2/4 tasks)
- ‚è∏Ô∏è Documentation Phase: 0% complete (0/3 tasks)
```

### Validation Before Committing

**BEFORE every commit, verify:**
- [ ] All completed tasks are marked as `[x]` in `tasks.md`
- [ ] Task status reflects current progress
- [ ] No tasks are marked complete without implementation
- [ ] All tests pass for completed tasks
- [ ] Test coverage meets thresholds (run `npm test -- --coverage`)
- [ ] Task status updated before moving to next task
- [ ] Documentation is updated for completed features

### Task Status Update Before Next Task

**CRITICAL RULE**: You MUST update task status in `tasks.md` BEFORE moving to the next task.

**Why:**
- Prevents loss of progress tracking
- Ensures context is preserved
- Makes it easy to resume work
- Provides clear progress visibility

**Workflow:**
```bash
# 1. Complete current task item
# ... implementation ...

# 2. Test and verify coverage
npm test
npm test -- --coverage

# 3. Update tasks.md IMMEDIATELY
# Mark as [x] and add status comment

# 4. Verify update
rulebook task show <task-id>
# Confirm status is updated

# 5. ONLY THEN proceed to next task
# Follow priority order (most critical first)
```

**Example:**
```markdown
## 1. Implementation Phase
- [x] 1.1 Create task manager module <!-- tested, coverage: 95% -->
- [x] 1.2 Add validation logic <!-- tested, coverage: 92%, status: complete -->
- [ ] 1.3 Add archive functionality <!-- next: will start after status update -->
```

## Task Archiving Workflow

**CRITICAL**: Archive tasks ONLY after full completion and validation.

### When to Archive

**Archive a task when:**
- ‚úÖ All items in `tasks.md` are marked as `[x]`
- ‚úÖ All tests pass (unit, integration, E2E)
- ‚úÖ Code review is complete (if applicable)
- ‚úÖ Documentation is updated (README, CHANGELOG, specs)
- ‚úÖ Task format is validated (`rulebook task validate <task-id>`)
- ‚úÖ Spec deltas have been applied to main specifications

**NEVER archive a task that is:**
- ‚ùå Partially complete
- ‚ùå Missing tests
- ‚ùå Failing validation
- ‚ùå Missing documentation

### Archive Process

**Step-by-step archive workflow:**

```bash
# 1. Verify all tasks are complete
rulebook task show <task-id>
# Check that all items in tasks.md are [x]

# 2. Run all quality checks
npm test
npm run lint
npm run type-check
npm run build

# 3. Validate task format
rulebook task validate <task-id>

# 4. Update final documentation
# - Update CHANGELOG.md
# - Update README.md if needed
# - Update any affected documentation

# 5. Archive the task
rulebook task archive <task-id>

# 6. Verify archive
rulebook task list --archived
# Task should appear in archived list
```

### Post-Archive Actions

**After archiving, ensure:**
- ‚úÖ Spec deltas are applied to main specifications
- ‚úÖ CHANGELOG.md is updated with the change
- ‚úÖ Any breaking changes are documented
- ‚úÖ Migration guides are created (if needed)
- ‚úÖ Related tasks are unblocked (if any)

### Archive Location

**Archived tasks are moved to:**
```
/rulebook/tasks/archive/YYYY-MM-DD-<task-id>/
```

**Structure:**
```
/rulebook/tasks/archive/2025-11-13-add-auth/
‚îú‚îÄ‚îÄ proposal.md
‚îú‚îÄ‚îÄ tasks.md          # All items marked [x]
‚îú‚îÄ‚îÄ design.md
‚îî‚îÄ‚îÄ specs/
    ‚îî‚îÄ‚îÄ core/
        ‚îî‚îÄ‚îÄ spec.md
```

## Task Creation Best Practices

### Task ID Naming

**Use verb-led kebab-case:**
- ‚úÖ `add-user-authentication`
- ‚úÖ `refactor-task-manager`
- ‚úÖ `update-api-validation`
- ‚úÖ `remove-legacy-code`
- ‚ùå `user-auth` (not descriptive)
- ‚ùå `task_manager` (use kebab-case)
- ‚ùå `new-feature` (too generic)

### Task Scope

**One capability per task:**
- ‚úÖ Good: `add-email-notifications`
- ‚ùå Bad: `add-email-notifications-and-sms-and-push` (too broad)

**Break large tasks into smaller ones:**
- ‚úÖ `add-email-notifications`
- ‚úÖ `add-sms-notifications`
- ‚úÖ `add-push-notifications`

### Task Checklist Structure

**Organize tasks by phase:**

```markdown
## 1. Planning & Design
- [ ] 1.1 Research existing solutions
- [ ] 1.2 Design architecture
- [ ] 1.3 Create technical spec

## 2. Implementation
- [ ] 2.1 Create core module
- [ ] 2.2 Add validation logic
- [ ] 2.3 Integrate with existing system

## 3. Testing
- [ ] 3.1 Write unit tests
- [ ] 3.2 Write integration tests
- [ ] 3.3 Test edge cases

## 4. Documentation
- [ ] 4.1 Update README
- [ ] 4.2 Update CHANGELOG
- [ ] 4.3 Add code comments

## 5. Cleanup
- [ ] 5.1 Remove debug code
- [ ] 5.2 Remove unused imports
- [ ] 5.3 Final code review
```

## Continuous Task Updates

**CRITICAL**: Update `tasks.md` continuously, not just at the end.

### Real-Time Updates

**Update as you work:**
1. **Start task**: Mark as `[ ]` (if not already)
2. **Begin implementation**: Add comment `<!-- in progress -->`
3. **Complete implementation**: Mark as `[x]`
4. **Test passes**: Add comment `<!-- tested -->`
5. **Ready for review**: Add comment `<!-- ready for review -->`

**Example:**
```markdown
## 1. Implementation
- [x] 1.1 Create task manager module <!-- tested -->
- [x] 1.2 Add validation logic <!-- tested, ready for review -->
- [ ] 1.3 Add archive functionality <!-- in progress -->
```

### Progress Tracking

**Add progress indicators:**
```markdown
## Progress: 60% (9/15 tasks complete)

## 1. Implementation Phase: 100% ‚úÖ
- [x] 1.1 Task 1
- [x] 1.2 Task 2
- [x] 1.3 Task 3

## 2. Testing Phase: 50% ‚è≥
- [x] 2.1 Unit tests
- [x] 2.2 Integration tests
- [ ] 2.3 E2E tests

## 3. Documentation Phase: 0% ‚è∏Ô∏è
- [ ] 3.1 README
- [ ] 3.2 CHANGELOG
- [ ] 3.3 API docs
```

## Task Validation Before Archive

**MANDATORY checks before archiving:**

```bash
# 1. Format validation
rulebook task validate <task-id>
# Must pass all format checks

# 2. Completion check
# All items in tasks.md must be [x]

# 3. Test coverage
npm test -- --coverage
# Must meet coverage thresholds

# 4. Code quality
npm run lint
npm run type-check
# Must pass all checks

# 5. Build verification
npm run build
# Must build successfully
```

## Summary: Task Lifecycle

**Complete task lifecycle:**

1. **Create** (MANDATORY FIRST STEP): `rulebook task create <task-id>`
   - ‚ö†Ô∏è NEVER start implementation without creating task first
   - ‚ö†Ô∏è Tasks without registration can be lost in context

2. **Plan**: Write proposal.md and tasks.md
   - Define why, what, and how
   - Create implementation checklist

3. **Design**: Write design.md (if needed)
   - Technical decisions
   - Architecture choices

4. **Spec**: Write spec deltas in specs/
   - OpenSpec-compatible format
   - Requirements with SHALL/MUST

5. **Validate**: `rulebook task validate <task-id>`
   - Format validation
   - Structure verification

6. **Implement**: Write code, following priority order
   - Most critical tasks first
   - Update tasks.md as you go

7. **Test** (HIGHEST PRIORITY): Write tests, verify coverage
   - All tests must pass
   - Coverage must meet thresholds
   - Mark tested items in tasks.md

8. **Update Status** (MANDATORY): Update task status before next task
   - Mark completed items as `[x]`
   - Update status in tasks.md
   - Verify status update

9. **Document**: Update docs, mark in tasks.md
   - README, CHANGELOG, specs

10. **Validate**: Final validation before archive
    - All checks pass
    - Coverage verified

11. **Archive**: `rulebook task archive <task-id>`
    - Move to archive
    - Apply spec deltas

**CRITICAL REMINDERS:**
- ‚ö†Ô∏è **ALWAYS create task BEFORE implementation** - without registration, tasks can be lost
- ‚ö†Ô∏è **ALWAYS follow priority order** - most critical first (tests, coverage, status update)
- ‚ö†Ô∏è **ALWAYS update task status before next task** - prevents context loss
- ‚ö†Ô∏è **ALWAYS verify coverage** - run `npm test -- --coverage` before marking complete
- ‚ö†Ô∏è **ALWAYS commit locally frequently** - even for backup, prevents work loss
- ‚ö†Ô∏è **ALWAYS keep remote repository updated** - push regularly if remote is configured
- ‚ö†Ô∏è **ALWAYS update `tasks.md` at EVERY step**, not just at the end!

## Best Practices

### DO's ‚úÖ

- **ALWAYS** create task BEFORE implementing any feature
- **ALWAYS** check Context7 MCP before creating tasks
- **ALWAYS** validate task format before committing
- **ALWAYS** use SHALL/MUST in requirements
- **ALWAYS** use 4 hashtags for scenarios
- **ALWAYS** use Given/When/Then structure
- **ALWAYS** follow priority order (most critical first)
- **ALWAYS** write tests first (highest priority)
- **ALWAYS** verify test coverage before marking complete
- **ALWAYS** commit locally frequently (even for backup)
- **ALWAYS** keep remote repository updated (push regularly)
- **ALWAYS** update task status before moving to next task
- **ALWAYS** update task status during implementation
- **ALWAYS** archive completed tasks
- **ALWAYS** document breaking changes in proposal

### DON'Ts ‚ùå

- **NEVER** start implementation without creating task first
- **NEVER** skip task registration (tasks can be lost in context)
- **NEVER** proceed to next task without updating current task status
- **NEVER** skip test coverage verification
- **NEVER** mark tasks complete without tests passing
- **NEVER** skip local commits (commit frequently for backup)
- **NEVER** let remote repository get out of sync (push regularly)
- **NEVER** commit sensitive information (API keys, passwords)
- **NEVER** force push to shared branches
- **NEVER** create tasks without checking Context7 format
- **NEVER** use 3 hashtags for scenarios
- **NEVER** omit SHALL/MUST from requirements
- **NEVER** use bullet points for scenarios
- **NEVER** skip validation
- **NEVER** leave tasks unarchived after completion
- **NEVER** mix formats (stick to OpenSpec-compatible format)
- **NEVER** ignore priority order (always do most critical first)

## CLI Commands Reference

### Task Management Commands

#### `rulebook task create <task-id>`

Create a new Rulebook task with OpenSpec-compatible format.

**Usage:**
```bash
rulebook task create add-user-authentication
```

**What it does:**
- Creates `/rulebook/tasks/<task-id>/` directory
- Generates `proposal.md` template
- Generates `tasks.md` template
- Creates `specs/` directory for spec deltas

**Requirements:**
- Task ID must be unique (verb-led kebab-case)
- Context7 MCP must be available (for format validation)

**Example:**
```bash
$ rulebook task create add-email-notifications
‚úÖ Task add-email-notifications created successfully
Location: rulebook/tasks/add-email-notifications/

‚ö†Ô∏è  Remember to:
  1. Check Context7 MCP for OpenSpec format requirements
  2. Fill in proposal.md (minimum 20 characters in "Why" section)
  3. Add tasks to tasks.md
  4. Create spec deltas in specs/*/spec.md
  5. Validate with: rulebook task validate add-email-notifications
```

**Error Handling:**
- `Task <task-id> already exists`: Choose a different task ID or archive existing task

---

#### `rulebook task list [--archived]`

List all Rulebook tasks (active and optionally archived).

**Usage:**
```bash
# List active tasks only
rulebook task list

# List including archived tasks
rulebook task list --archived
```

**Output:**
- Active tasks with status (pending, in-progress, completed, blocked)
- Archived tasks with archive date (if --archived flag is used)

**Example:**
```bash
$ rulebook task list

üìã Rulebook Tasks

Active Tasks:
  pending      add-user-authentication - Add user authentication feature
  in-progress  refactor-api-validation - Refactor API validation logic
  completed    update-documentation - Update project documentation

$ rulebook task list --archived

üìã Rulebook Tasks

Active Tasks:
  pending      add-user-authentication - Add user authentication feature

Archived Tasks:
  archived     2025-01-15-add-email-notifications - Add email notifications (2025-01-15)
```

**Task Status Values:**
- `pending`: Task not started
- `in-progress`: Task being worked on
- `completed`: Task finished (ready for archive)
- `blocked`: Task blocked by dependency

---

#### `rulebook task show <task-id>`

Show detailed information about a specific task.

**Usage:**
```bash
rulebook task show add-user-authentication
```

**Output:**
- Task ID and title
- Status (pending, in-progress, completed, blocked)
- Created and updated dates
- Archive date (if archived)
- Proposal summary (first 500 characters)
- Spec files list

**Example:**
```bash
$ rulebook task show add-user-authentication

üìã Task: add-user-authentication

Title: add-user-authentication
Status: pending
Created: 2025-01-15T10:30:00.000Z
Updated: 2025-01-15T10:30:00.000Z

Proposal:
# Proposal: Add User Authentication

## Why
We need to implement secure user authentication to protect user accounts and enable personalized features. This will include JWT token-based authentication with refresh tokens and password hashing using bcrypt...

Specs:
  core/spec.md (1234 chars)
```

**Error Handling:**
- `Task <task-id> not found`: Verify task ID exists with `rulebook task list`

---

#### `rulebook task validate <task-id>`

Validate task format against OpenSpec-compatible requirements.

**Usage:**
```bash
rulebook task validate add-user-authentication
```

**Validation Checks:**
- Purpose section length (‚â•20 characters)
- Requirement keywords (SHALL/MUST)
- Scenario format (4 hashtags, not 3)
- Given/When/Then structure
- Delta headers format (ADDED/MODIFIED/REMOVED/RENAMED)

**Example:**
```bash
$ rulebook task validate add-user-authentication
‚úÖ Task add-user-authentication is valid

‚ö†Ô∏è  Warnings:
  - Scenario in core/spec.md should use Given/When/Then structure
```

**Error Example:**
```bash
$ rulebook task validate invalid-task
‚ùå Task invalid-task validation failed

Errors:
  - Scenarios in core/spec.md must use 4 hashtags (####), not 3 (###)
  - Requirement in core/spec.md missing SHALL or MUST keyword: ### Requirement: Auth
  - Purpose section (## Why) must have at least 20 characters
```

**Error Handling:**
- Fix all errors before proceeding
- Warnings are informational but don't block archiving

---

#### `rulebook task archive <task-id> [--skip-validation]`

Archive a completed task and apply spec deltas to main specifications.

**Usage:**
```bash
# Archive with validation (recommended)
rulebook task archive add-user-authentication

# Archive without validation (use with caution)
rulebook task archive add-user-authentication --skip-validation
```

**Archive Process:**
1. Validates task format (unless `--skip-validation` is used)
2. Checks task completion status
3. Applies spec deltas to main specifications
4. Moves task to `/rulebook/tasks/archive/YYYY-MM-DD-<task-id>/`
5. Updates related specifications

**Example:**
```bash
$ rulebook task archive add-user-authentication
‚úÖ Task add-user-authentication archived successfully
```

**Error Handling:**
- `Task validation failed`: Fix validation errors before archiving
- `Task <task-id> not found`: Verify task ID exists
- `Archive <archive-name> already exists`: Archive with that date already exists

**Important:**
- Only archive tasks that are fully completed
- All items in `tasks.md` should be marked as `[x]`
- All tests should pass
- Documentation should be updated

---

### Core Rulebook Commands

#### `rulebook init [--minimal] [--light] [--yes]`

Initialize Rulebook for current project.

**Usage:**
```bash
# Interactive mode
rulebook init

# Minimal setup (essentials only)
rulebook init --minimal

# Light mode (no quality enforcement)
rulebook init --light

# Skip prompts, use defaults
rulebook init --yes
```

**What it does:**
- Detects languages, frameworks, and MCP modules
- Generates AGENTS.md with AI assistant rules
- Creates `/rulebook/` directory with templates
- Creates/updates `.gitignore` automatically
- Optionally installs Git hooks
- Generates Cursor commands (if Cursor is selected IDE)

---

#### `rulebook update [--yes] [--minimal] [--light]`

Update AGENTS.md and .rulebook to latest version.

**Usage:**
```bash
# Interactive mode
rulebook update

# Skip confirmation
rulebook update --yes

# Minimal mode
rulebook update --minimal

# Light mode
rulebook update --light
```

**What it does:**
- Migrates OpenSpec tasks to Rulebook format (if OpenSpec exists)
- Migrates OpenSpec archives to Rulebook format
- Removes OpenSpec commands from `.cursor/commands/`
- Updates AGENTS.md with latest templates
- Merges templates while preserving customizations
- Updates Cursor commands (if Cursor is selected IDE)

---

#### `rulebook validate`

Validate project structure against Rulebook standards.

**Usage:**
```bash
rulebook validate
```

**Validation Checks:**
- AGENTS.md presence and format
- Rulebook directory structure
- Documentation structure
- Tests directory
- Score calculation (0-100)

---

#### `rulebook health`

Check project health score.

**Usage:**
```bash
rulebook health
```

**Categories Scored:**
- Quality (linting, formatting, code quality)
- Testing (test coverage, test quality)
- Security (vulnerabilities, secrets)
- Documentation (README, docs/, comments)

**Score Range:** 0-100

---

#### `rulebook workflows`

Generate GitHub Actions workflows for detected languages.

**Usage:**
```bash
rulebook workflows
```

**What it does:**
- Creates `.github/workflows/` directory
- Generates language-specific workflows (test, lint, publish)
- Adds codespell workflow for spelling checks

---

#### `rulebook check-deps`

Check for outdated and vulnerable dependencies.

**Usage:**
```bash
rulebook check-deps
```

**Supported Package Managers:**
- npm (package.json)
- Cargo (Cargo.toml)
- pip (requirements.txt, pyproject.toml)
- Go modules (go.mod)

---

#### `rulebook check-coverage [-t <threshold>]`

Check test coverage against threshold.

**Usage:**
```bash
# Default threshold (95%)
rulebook check-coverage

# Custom threshold
rulebook check-coverage -t 80
```

---

#### `rulebook generate-docs [--yes]`

Generate documentation structure and standard files.

**Usage:**
```bash
# Interactive mode
rulebook generate-docs

# Skip prompts
rulebook generate-docs --yes
```

---

#### `rulebook version <major|minor|patch>`

Bump project version (semantic versioning).

**Usage:**
```bash
rulebook version major  # 1.0.0 -> 2.0.0
rulebook version minor  # 1.0.0 -> 1.1.0
rulebook version patch  # 1.0.0 -> 1.0.1
```

---

#### `rulebook changelog [-v <version>]`

Generate changelog from git commits.

**Usage:**
```bash
# Auto-detect version
rulebook changelog

# Specify version
rulebook changelog -v 1.0.0
```

---

#### `rulebook fix`

Auto-fix common project issues.

**Usage:**
```bash
rulebook fix
```

---

### Advanced Commands (Beta)

#### `rulebook watcher`

Start modern full-screen console watcher for task progress.

**Usage:**
```bash
rulebook watcher
```

**Features:**
- Live task progress tracking
- Activity log with timestamps
- System status monitoring
- Auto-refresh every 2 seconds

---

#### `rulebook agent [--dry-run] [--tool <name>] [--iterations <n>] [--watch]`

Start autonomous agent for managing AI CLI workflows.

**Usage:**
```bash
# Dry run (simulate without changes)
rulebook agent --dry-run

# Specify CLI tool
rulebook agent --tool cursor-agent

# Set max iterations
rulebook agent --iterations 10

# Enable watcher mode
rulebook agent --watch
```

---

#### `rulebook config [--show] [--set <key=value>] [--feature <name> --enable|--disable]`

Manage Rulebook configuration.

**Usage:**
```bash
# Show current config
rulebook config --show

# Set config value
rulebook config --set rulebookDir=custom-rulebook

# Enable feature
rulebook config --feature watcher --enable

# Disable feature
rulebook config --feature agent --disable
```

## Migration from OpenSpec

If your project previously used OpenSpec:

1. **Automatic Migration**: Run `rulebook update` to automatically migrate OpenSpec tasks to Rulebook format
2. **Manual Migration**: Tasks in `/openspec/changes/` will be moved to `/rulebook/tasks/`
3. **Format Compatibility**: Rulebook uses OpenSpec-compatible format, so existing tasks remain valid

## Context7 MCP Requirement

**CRITICAL**: Context7 MCP is REQUIRED for task creation.

**Why**: 
- Ensures correct format by fetching official OpenSpec documentation
- Prevents common format errors made by AI assistants
- Provides up-to-date format requirements

**If Context7 MCP is not available:**
- Task creation will fail with clear error message
- You must configure Context7 MCP before creating tasks
- See `/rulebook/CONTEXT7.md` for setup instructions

## Troubleshooting

### Validation Errors

**Error**: "Requirement must contain SHALL or MUST keyword"
- **Fix**: Add SHALL or MUST to requirement text
- **Example**: Change "The system provides authentication" to "The system SHALL provide authentication"

**Error**: "Scenario must use 4 hashtags"
- **Fix**: Change `### Scenario:` to `#### Scenario:` (at start of line)
- **Note**: Validation only checks headers at start of line, not in text content

**Error**: "Purpose section too short"
- **Fix**: Expand "Why" section in proposal.md to at least 20 characters
- **Example**: "Auth system" ‚Üí "Authentication system for secure user access with JWT tokens and session management"

**Error**: "Scenario must use Given/When/Then structure"
- **Fix**: Replace bullet points with Given/When/Then format
- **Example**: 
  ```markdown
  #### Scenario: User login
  Given a user has valid credentials
  When they submit the login form
  Then they are authenticated successfully
  ```

### Task Creation Errors

**Error**: "Context7 MCP not available"
- **Fix**: Configure Context7 MCP in your MCP configuration file
- **See**: `/rulebook/CONTEXT7.md` for setup instructions

**Error**: "Task ID already exists"
- **Fix**: Choose a different task ID or archive existing task
- **Check**: Use `rulebook task list` to see existing tasks

### Task Archive Errors

**Error**: "Task validation failed"
- **Fix**: Run `rulebook task validate <task-id>` to see all errors
- **Fix**: Address all validation errors before archiving
- **Option**: Use `--skip-validation` flag only if you're certain the task is valid

**Error**: "Archive <archive-name> already exists"
- **Fix**: Archive with that date already exists
- **Check**: Use `rulebook task list --archived` to see archived tasks

### Command Errors

**Error**: "Task <task-id> not found"
- **Fix**: Verify task ID exists with `rulebook task list`
- **Check**: Ensure you're in the correct project directory

**Error**: "No tasks found"
- **Fix**: Create a task first with `rulebook task create <task-id>`
- **Check**: Verify `/rulebook/tasks/` directory exists

### Migration Errors

**Error**: "Failed to migrate task"
- **Fix**: Check error message for specific issue
- **Check**: Verify OpenSpec task structure is correct
- **Fix**: Manually migrate if automatic migration fails

**Error**: "Failed to read OpenSpec changes directory"
- **Fix**: Verify `/openspec/changes/` directory exists
- **Check**: Ensure you have read permissions

## Examples

See `/rulebook/tasks/` directory for examples of correctly formatted tasks.

<!-- RULEBOOK:END -->


<!-- RULEBOOK:SKILL:core/rulebook:END -->
