<!-- RULEBOOK:START -->
# Project Rules

Generated by @hivellm/rulebook
Generated at: 2025-11-01T02:07:36.655Z

<!-- QUALITY_ENFORCEMENT:START -->
# Quality Enforcement Rules

**CRITICAL**: These rules are NON-NEGOTIABLE and MUST be followed without exception.

## Absolute Prohibitions

### Test Bypassing - STRICTLY FORBIDDEN
- NEVER use .skip(), .only(), or .todo() to bypass failing tests
- NEVER comment out failing tests
- NEVER use @ts-ignore, @ts-expect-error, or similar to hide test errors
- NEVER mock/stub functionality just to make tests pass without fixing root cause
- FIX the actual problem causing test failures

### Git Hook Bypassing - STRICTLY FORBIDDEN  
- NEVER use --no-verify flag on git commit
- NEVER use --no-verify flag on git push
- NEVER disable or skip pre-commit hooks
- NEVER disable or skip pre-push hooks
- FIX the issues that hooks are detecting

### Test Implementation - STRICTLY FORBIDDEN
- NEVER create boilerplate tests that don't actually test behavior
- NEVER write tests that always pass regardless of implementation
- NEVER write tests without assertions
- NEVER mock everything to avoid testing real behavior
- WRITE meaningful tests that verify actual functionality

### Problem Solving Approach - REQUIRED
- DO NOT seek the simplest bypass or workaround
- DO NOT be creative with shortcuts that compromise quality
- DO solve problems properly following best practices
- DO use proven, established solutions from decades of experience
- DO fix root causes, not symptoms

## Enforcement

These rules apply to ALL implementations:
- Bug fixes
- New features  
- Refactoring
- Documentation changes
- Any code modifications

**Violation = Implementation Rejected**

<!-- QUALITY_ENFORCEMENT:END -->


## Documentation Standards

**CRITICAL**: Minimize Markdown files. Keep documentation organized.

### Allowed Root-Level Documentation
Only these files are allowed in the project root:
- ✅ `README.md` - Project overview and quick start
- ✅ `CHANGELOG.md` - Version history and release notes
- ✅ `AGENTS.md` - This file (AI assistant instructions)
- ✅ `LICENSE` - Project license
- ✅ `CONTRIBUTING.md` - Contribution guidelines
- ✅ `CODE_OF_CONDUCT.md` - Code of conduct
- ✅ `SECURITY.md` - Security policy

### All Other Documentation
**ALL other documentation MUST go in `/docs` directory**:
- `/docs/ARCHITECTURE.md` - System architecture
- `/docs/DEVELOPMENT.md` - Development guide
- `/docs/ROADMAP.md` - Project roadmap
- `/docs/DAG.md` - Component dependencies (DAG)
- `/docs/specs/` - Feature specifications
- `/docs/sdks/` - SDK documentation
- `/docs/protocols/` - Protocol specifications
- `/docs/guides/` - Developer guides
- `/docs/diagrams/` - Architecture diagrams
- `/docs/benchmarks/` - Performance benchmarks
- `/docs/versions/` - Version release reports

## Testing Requirements

**CRITICAL**: All features must have comprehensive tests.

- **Minimum Coverage**: 95%
- **Test Location**: `/tests` directory in project root
- **Test Execution**: 100% of tests MUST pass before moving to next task
- **Test First**: Write tests based on specifications before implementation

## Feature Development Workflow

**CRITICAL**: Follow this workflow for all feature development.

1. **Check Specifications First**:
   - Read `/docs/specs/` for feature specifications
   - Review `/docs/ARCHITECTURE.md` for system design
   - Check `/docs/ROADMAP.md` for implementation timeline
   - Review `/docs/DAG.md` for component dependencies

2. **Implement with Tests**:
   - Write tests in `/tests` directory first
   - Implement feature following specifications
   - Ensure tests pass and meet coverage threshold

3. **Quality Checks**:
   - Run code formatter
   - Run linter (must pass with no warnings)
   - Run all tests (must be 100% passing)
   - Verify coverage meets threshold

4. **Update Documentation**:
   - Update `/docs/ROADMAP.md` progress
   - Update feature specs if implementation differs
   - Document any deviations with justification

## Rules Configuration

Rules can be selectively disabled using `.rulesignore` file in project root.

Example `.rulesignore`:
```
# Ignore coverage requirement
coverage-threshold
# Ignore specific language rules
rust/edition-2024
# Ignore all TypeScript rules
typescript/*
```

<!-- RULEBOOK:END -->





<!-- RUST:START -->
# Rust Project Rules

## Agent Automation Commands

**CRITICAL**: Execute these commands after EVERY implementation (see AGENT_AUTOMATION module for full workflow).

```bash
# Complete quality check sequence:
cargo fmt --all -- --check           # Format check
cargo clippy --workspace --all-targets --all-features -- -D warnings  # Lint
cargo test --workspace --all-features  # All tests (100% pass)
cargo build --release                # Build verification
cargo llvm-cov --all                 # Coverage (95%+ required)

# Security audit:
cargo audit                          # Vulnerability scan
cargo outdated                       # Check outdated deps
```

## Rust Edition and Toolchain

**CRITICAL**: Always use Rust Edition 2024 with nightly toolchain.

- **Edition**: 2024
- **Toolchain**: nightly 1.85+
- **Update**: Run `rustup update nightly` regularly

### Formatting

- Use `rustfmt` with nightly toolchain
- Configuration in `rustfmt.toml` or `.rustfmt.toml`
- Always format before committing: `cargo +nightly fmt --all`
- CI must check formatting: `cargo +nightly fmt --all -- --check`

### Linting

- Use `clippy` with `-D warnings` (warnings as errors)
- Fix all clippy warnings before committing
- Acceptable exceptions must be documented with `#[allow(clippy::...)]` and justification
- CI must enforce clippy: `cargo clippy --workspace -- -D warnings`

### Testing

- **Location**: Tests in `/tests` directory for integration tests
- **Unit Tests**: In same file as implementation with `#[cfg(test)]`
- **Coverage**: Must meet project threshold (default 95%)
- **Tools**: Use `cargo-nextest` for faster test execution
- **Async**: Use `tokio::test` for async tests with Tokio runtime

Example test structure:
```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_feature() {
        // Test implementation
    }

    #[tokio::test]
    async fn test_async_feature() {
        // Async test implementation
    }
}
```

## Async Programming

**CRITICAL**: Follow Tokio best practices for async code.

- **Runtime**: Use Tokio for async runtime
- **Blocking**: Never block in async context - use `spawn_blocking` for CPU-intensive tasks
- **Channels**: Use `tokio::sync::mpsc` or `tokio::sync::broadcast` for async communication
- **Timeouts**: Always set timeouts for network operations: `tokio::time::timeout`

Example:
```rust
use tokio::time::{timeout, Duration};

async fn fetch_data() -> Result<Data, Error> {
    timeout(Duration::from_secs(30), async {
        // Network operation
    }).await?
}
```

## Dependency Management

**CRITICAL**: Always verify latest versions before adding dependencies.

### Before Adding Any Dependency

1. **Check Context7 for latest version**:
   - Use MCP Context7 tool if available
   - Search for the crate documentation
   - Verify the latest stable version
   - Review breaking changes and migration guides

2. **Example Workflow**:
   ```
   Adding tokio → Check crates.io and docs.rs
   Adding serde → Verify latest version with security updates
   Adding axum → Check for breaking changes in latest version
   ```

3. **Document Version Choice**:
   - Note why specific version chosen in `Cargo.toml` comments
   - Document any compatibility constraints
   - Update CHANGELOG.md with new dependencies

### Dependency Guidelines

- ✅ Use latest stable versions
- ✅ Check for security advisories: `cargo audit`
- ✅ Prefer well-maintained crates (active development, good documentation)
- ✅ Minimize dependency count
- ✅ Use workspace dependencies for monorepos
- ❌ Don't use outdated versions without justification
- ❌ Don't add dependencies without checking latest version

## Codespell Configuration

**CRITICAL**: Use codespell to catch typos in code and documentation.

Install: `pip install 'codespell[toml]'`

Configuration in `pyproject.toml`:
```toml
[tool.codespell]
skip = "*.lock,*.json,target,node_modules,.git"
ignore-words-list = "crate,ser,deser"
```

Or run with flags:
```bash
codespell \
  --skip="*.lock,*.json,target,node_modules,.git" \
  --ignore-words-list="crate,ser,deser"
```

## Error Handling

- Use `Result<T, E>` for recoverable errors
- Use `thiserror` for custom error types
- Use `anyhow` for application-level error handling
- Document error conditions in function docs
- Never use `unwrap()` or `expect()` in production code without justification

Example:
```rust
use thiserror::Error;

#[derive(Error, Debug)]
pub enum MyError {
    #[error("IO error: {0}")]
    Io(#[from] std::io::Error),
    
    #[error("Invalid input: {0}")]
    InvalidInput(String),
}

pub fn process_data(input: &str) -> Result<Data, MyError> {
    // Implementation
}
```

## Documentation

- **Public APIs**: Must have doc comments (`///`)
- **Examples**: Include examples in doc comments
- **Modules**: Document module purpose with `//!`
- **Unsafe**: Always document safety requirements for `unsafe` code
- **Run doctests**: `cargo test --doc`

Example:
```rust
/// Processes the input data and returns a result.
///
/// # Arguments
///
/// * `input` - The input string to process
///
/// # Examples
///
/// ```
/// use mylib::process;
/// let result = process("hello");
/// assert_eq!(result, "HELLO");
/// ```
///
/// # Errors
///
/// Returns `MyError::InvalidInput` if input is empty.
pub fn process(input: &str) -> Result<String, MyError> {
    // Implementation
}
```

## Project Structure

```
project/
├── Cargo.toml          # Package manifest
├── Cargo.lock          # Dependency lock file (commit this)
├── README.md           # Project overview (allowed in root)
├── CHANGELOG.md        # Version history (allowed in root)
├── AGENTS.md          # AI assistant rules (allowed in root)
├── LICENSE            # Project license (allowed in root)
├── CONTRIBUTING.md    # Contribution guidelines (allowed in root)
├── CODE_OF_CONDUCT.md # Code of conduct (allowed in root)
├── SECURITY.md        # Security policy (allowed in root)
├── src/
│   ├── lib.rs          # Library root (for libraries)
│   ├── main.rs         # Binary root (for applications)
│   └── ...
├── tests/              # Integration tests
├── examples/           # Example code
├── benches/            # Benchmarks
└── docs/               # Project documentation
```

## CI/CD Requirements

Must include GitHub Actions workflows for:

1. **Testing** (`rust-test.yml`):
   - Test on ubuntu-latest, windows-latest, macos-latest
   - Use `cargo-nextest` for fast test execution
   - Upload test results

2. **Linting** (`rust-lint.yml`):
   - Format check: `cargo +nightly fmt --all -- --check`
   - Clippy: `cargo clippy --workspace -- -D warnings`
   - All targets: `cargo clippy --workspace --all-targets -- -D warnings`

3. **Codespell** (`codespell.yml`):
   - Check for typos in code and documentation
   - Fail on errors

## Crate Publication

### Publishing to crates.io

**Prerequisites:**
1. Create account at https://crates.io
2. Generate API token: `cargo login`
3. Add `CARGO_TOKEN` to GitHub repository secrets

**Cargo.toml Configuration:**

```toml
[package]
name = "your-crate-name"
version = "1.0.0"
edition = "2024"
authors = ["Your Name <your.email@example.com>"]
license = "MIT OR Apache-2.0"
description = "A short description of your crate"
documentation = "https://docs.rs/your-crate-name"
homepage = "https://github.com/your-org/your-crate-name"
repository = "https://github.com/your-org/your-crate-name"
readme = "README.md"
keywords = ["your", "keywords", "here"]
categories = ["category"]
exclude = [
    ".github/",
    "tests/",
    "benches/",
    "examples/",
    "*.sh",
]

[package.metadata.docs.rs]
all-features = true
rustdoc-args = ["--cfg", "docsrs"]
```

**Publishing Workflow:**

1. Update version in Cargo.toml
2. Update CHANGELOG.md
3. Run quality checks:
   ```bash
   cargo fmt --all
   cargo clippy --workspace --all-targets -- -D warnings
   cargo test --all-features
   cargo doc --no-deps --all-features
   ```
4. Create git tag: `git tag v1.0.0 && git push --tags`
5. GitHub Actions automatically publishes to crates.io
6. Or manual publish: `cargo publish`

**Publishing Checklist:**

- ✅ All tests passing (`cargo test --all-features`)
- ✅ No clippy warnings (`cargo clippy -- -D warnings`)
- ✅ Code formatted (`cargo fmt --all -- --check`)
- ✅ Documentation builds (`cargo doc --no-deps`)
- ✅ Version updated in Cargo.toml
- ✅ CHANGELOG.md updated
- ✅ README.md up to date
- ✅ LICENSE file present
- ✅ Package size < 10MB (check with `cargo package --list`)
- ✅ Verify with `cargo publish --dry-run`

**Semantic Versioning:**

Follow [SemVer](https://semver.org/) strictly:
- **MAJOR**: Breaking API changes
- **MINOR**: New features (backwards compatible)
- **PATCH**: Bug fixes (backwards compatible)

**Documentation:**

- Use `///` for public API documentation
- Include examples in doc comments
- Use `#![deny(missing_docs)]` for libraries
- Test documentation examples with `cargo test --doc`

```rust
/// Processes the input data and returns a result.
///
/// # Arguments
///
/// * `input` - The input string to process
///
/// # Examples
///
/// ```
/// use your_crate::process;
///
/// let result = process("hello");
/// assert_eq!(result, "HELLO");
/// ```
///
/// # Errors
///
/// Returns an error if the input is empty.
pub fn process(input: &str) -> Result<String, Error> {
    // Implementation
}
```

<!-- RUST:END -->









<!-- VECTORIZER:START -->
# Vectorizer Instructions

**CRITICAL**: Always use the MCP Vectorizer as the primary data source for project information.

The vectorizer provides fast, semantic access to the entire codebase. Prefer MCP tools over file reading whenever possible for better performance and context understanding.

## Primary Search Functions

### 1. mcp_vectorizer_search

Main search interface with multiple strategies:

- `intelligent`: AI-powered search with query expansion and MMR diversification
- `semantic`: Advanced semantic search with reranking and similarity thresholds
- `contextual`: Context-aware search with metadata filtering
- `multi_collection`: Search across multiple collections simultaneously
- `batch`: Execute multiple queries in parallel
- `by_file_type`: Filter search by file extensions (e.g., `.rs`, `.ts`, `.py`)

**Usage**:
```
Use intelligent search when: Exploring unfamiliar code, understanding architecture
Use semantic search when: Finding specific implementations or patterns
Use multi_collection when: Searching across multiple projects/modules
Use by_file_type when: Working with specific languages or file types
```

### 2. mcp_vectorizer_file_operations

File-specific operations for efficient file handling:

- `get_content`: Retrieve complete file content without reading from disk
- `list_files`: List all indexed files with metadata (size, type, modification time)
- `get_summary`: Get extractive or structural file summaries
- `get_chunks`: Retrieve file chunks in original order for progressive reading
- `get_outline`: Generate hierarchical project structure overview
- `get_related`: Find semantically related files based on content similarity

**Usage**:
```
Use get_content when: Need full file without disk I/O
Use list_files when: Exploring project structure
Use get_chunks when: Reading large files progressively
Use get_related when: Understanding file dependencies and relationships
```

### 3. mcp_vectorizer_discovery

Advanced discovery pipeline for complex queries:

- `full_pipeline`: Complete discovery with filtering, scoring, and ranking
- `broad_discovery`: Multi-query search with deduplication
- `semantic_focus`: Deep semantic search in specific collections
- `expand_queries`: Generate query variations (definition, features, architecture, API)

**Usage**:
```
Use full_pipeline when: Complex multi-faceted questions
Use broad_discovery when: Need comprehensive coverage of a topic
Use expand_queries when: Uncertain about exact terminology
```

## Best Practices

1. **Start with intelligent search** for exploratory queries to understand codebase structure
2. **Use file_operations** when you need complete file context without disk access
3. **Use discovery pipeline** for complex, multi-faceted questions requiring deep analysis
4. **Prefer batch operations** when searching for multiple related items to reduce latency
5. **Use by_file_type** when working with specific languages (e.g., only Rust or TypeScript files)

## Performance Tips

- **Batch queries** instead of sequential searches for better performance
- **Use specific collections** when you know the target area to reduce search space
- **Set similarity thresholds** to filter out irrelevant results (typically 0.6-0.8)
- **Cache results** for repeated queries within the same session

## Common Patterns

### Pattern 1: Understanding a Feature
```
1. Use intelligent search to find feature implementation
2. Use get_related to find connected files
3. Use get_outline to understand feature structure
4. Use get_content to read specific implementations
```

### Pattern 2: Debugging an Issue
```
1. Use semantic search with error message or symptom
2. Use by_file_type to focus on relevant language files
3. Use get_chunks to progressively read large files
4. Use get_related to find potentially affected files
```

### Pattern 3: Adding a New Feature
```
1. Use expand_queries to find similar existing features
2. Use full_pipeline for comprehensive discovery
3. Use get_outline to understand where to add code
4. Use get_related to find integration points
```

<!-- VECTORIZER:END -->



<!-- SYNAP:START -->
# Synap Instructions

**CRITICAL**: Use MCP Synap for persistent task and data storage during development sessions.

Synap provides a distributed key-value store, pub/sub messaging, and streaming capabilities. Use it to maintain state, track tasks, and persist important data across context windows.

## Core Features

### 1. Key-Value Store

Store and retrieve data with TTL support:

- `synap_kv_get`: Retrieve a value by key
- `synap_kv_set`: Store a value with optional TTL (time-to-live)
- `synap_kv_delete`: Remove a key from storage
- `synap_kv_scan`: Scan keys by prefix pattern

**Usage**:
```
Use for: Task tracking, configuration storage, session state
TTL for: Temporary data that should expire
Scan for: Listing related items by prefix (e.g., "task:*")
```

### 2. Queue System

Persistent message queues for task management:

- `synap_queue_publish`: Add a message to a queue with priority
- `synap_queue_consume`: Retrieve and process messages from queue

**Usage**:
```
Use for: Task queues, work distribution, async job processing
Priorities: 0-9 (9 = highest priority)
Pattern: Producer-consumer model for parallel work
```

### 3. Pub/Sub Messaging

Event-driven communication:

- `synap_pubsub_publish`: Broadcast message to topic subscribers

**Usage**:
```
Use for: Event notifications, real-time updates, broadcast messages
Pattern: One-to-many messaging for loosely coupled components
```

### 4. Streaming

Real-time event streaming:

- `synap_stream_publish`: Publish events to a stream room

**Usage**:
```
Use for: Real-time data streams, live updates, event logs
Pattern: Continuous data flow for monitoring and analytics
```

## Best Practices for AI Development

### Task Tracking

Store implementation tasks and progress:

```
Pattern: "task:<feature-name>:<subtask-id>"

Example:
- synap_kv_set("task:auth:implement-login", JSON.stringify({
    status: "in_progress",
    started: "2024-01-01T10:00:00Z",
    tests: ["test_login_success", "test_login_failure"],
    coverage: 95.2
  }))
```

### Session State

Preserve state across context windows:

```
Pattern: "session:<session-id>:<data-type>"

Example:
- synap_kv_set("session:abc123:current-file", "/src/auth/login.ts")
- synap_kv_set("session:abc123:todo-list", JSON.stringify([...]))
```

### Configuration Storage

Store project configuration and settings:

```
Pattern: "config:<category>:<key>"

Example:
- synap_kv_set("config:project:coverage-threshold", "95")
- synap_kv_set("config:project:languages", JSON.stringify(["rust", "typescript"]))
```

### Test Results

Track test execution and coverage:

```
Pattern: "test:<suite>:<timestamp>"

Example:
- synap_kv_set("test:integration:latest", JSON.stringify({
    passed: 42,
    failed: 0,
    coverage: 96.5,
    duration: "3.2s"
  }), 86400) // TTL: 24 hours
```

## Common Patterns

### Pattern 1: Multi-Step Implementation Tracking

```
1. Store overall plan: synap_kv_set("plan:feature-x", plan_json)
2. Track each step: synap_kv_set("step:feature-x:1", step_status)
3. Update progress: synap_kv_set("progress:feature-x", percentage)
4. Mark complete: synap_kv_delete("plan:feature-x")
```

### Pattern 2: Code Generation History

```
1. Store generated code: synap_kv_set("generated:file-path", code)
2. Track modifications: synap_kv_set("history:file-path", changelog)
3. List all generated: synap_kv_scan("generated:*")
```

### Pattern 3: Error Tracking

```
1. Log errors: synap_kv_set("error:timestamp", error_details, 3600)
2. Track fixes: synap_kv_set("fix:error-id", fix_details)
3. Scan recent errors: synap_kv_scan("error:*")
```

## Retention and Cleanup

- Use TTL for temporary data (session state, cache, recent errors)
- No TTL for persistent data (configuration, important results)
- Regularly clean up old data with `synap_kv_delete`
- Use prefixes for easy bulk operations with `synap_kv_scan`

## Integration with Development Workflow

1. **Before Starting**: Check for existing state (`synap_kv_get("session:current-task")`)
2. **During Work**: Update progress regularly (`synap_kv_set("progress:*")`)
3. **After Completion**: Store results and clean up temporary data
4. **Context Switch**: Save complete state before summarization

<!-- SYNAP:END -->



<!-- OPENSPEC:START -->
# OpenSpec Instructions

**CRITICAL**: Use OpenSpec for spec-driven development of new features and breaking changes.

## When to Use

Create proposal for:
- ✅ New features/capabilities
- ✅ Breaking changes
- ✅ Architecture changes  
- ✅ Performance/security work

Skip for:
- ❌ Bug fixes (restore intended behavior)
- ❌ Typos, formatting, comments
- ❌ Dependency updates (non-breaking)

## Quick Start

```bash
# 1. Check existing
openspec list --specs
openspec list

# 2. Create change
CHANGE=add-your-feature
mkdir -p openspec/changes/$CHANGE/specs/capability-name

# 3. Create files
# - proposal.md (why, what, impact)
# - tasks.md (implementation checklist)
# - specs/capability-name/spec.md (deltas)

# 4. Validate
openspec validate $CHANGE --strict
```

## Spec Format

**CRITICAL**: Scenario format MUST be exact:

```markdown
## ADDED Requirements
### Requirement: Feature Name
The system SHALL provide...

#### Scenario: Success case
- **WHEN** user performs action
- **THEN** expected result occurs
```

❌ **WRONG:**
```markdown
- **Scenario: Login**      # NO - bullet
**Scenario**: Login        # NO - bold
### Scenario: Login        # NO - 3 hashtags
```

✅ **CORRECT:**
```markdown
#### Scenario: User login   # YES - 4 hashtags
```

## Three-Stage Workflow

### Stage 1: Create
1. Read `openspec/project.md`
2. Choose verb-led `change-id` (e.g., `add-auth`, `update-api`)
3. Create `proposal.md`, `tasks.md`, delta specs
4. Validate: `openspec validate [id] --strict`
5. Get approval

### Stage 2: Implement  
1. Read `proposal.md`, `tasks.md`
2. Implement tasks
3. Run AGENT_AUTOMATION workflow
4. Update tasks as complete
5. Document commit hash in tasks.md

### Stage 3: Archive
After deployment:
```bash
openspec archive [change] --yes
```

## Commands

```bash
openspec list                    # Active changes
openspec list --specs            # All capabilities
openspec show [item]             # View details
openspec validate [change] --strict  # Validate
openspec diff [change]           # Show changes
openspec archive [change] --yes  # Complete
```

## Best Practices

✅ **DO:**
- One requirement per concern
- At least one scenario per requirement
- Use SHALL/MUST for normative requirements
- Validate before committing
- Keep changes focused and small

❌ **DON'T:**
- Mix multiple features in one change
- Skip scenario definitions
- Use wrong scenario format
- Start implementation before approval

## Integration with AGENT_AUTOMATION

OpenSpec drives implementation. AGENT_AUTOMATION enforces quality:

```
1. Create spec → Validate → Approve
2. Implement → Run AGENT_AUTOMATION
3. Update tasks.md with commit hash
4. Archive when deployed
```

<!-- OPENSPEC:END -->



## Complete Example: Creating an OpenSpec Change

### Example: Adding Authentication Feature

**Directory Structure:**
```
openspec/changes/add-user-authentication/
├── proposal.md
├── tasks.md
├── design.md (optional)
└── specs/
    └── auth/
        └── spec.md
```

**File: `proposal.md`**
```markdown
# Proposal: Add User Authentication

## Why
Users need secure access control to protect their data and ensure only authorized users can access the system.

## What Changes
- **ADDED** JWT-based authentication system
- **ADDED** User login/logout endpoints
- **ADDED** Password hashing with bcrypt
- **ADDED** Session management

## Impact
- Affected specs: auth (new capability)
- Affected code: src/auth/, src/middleware/
- Breaking change: None (new feature)
- Dependencies: bcrypt, jsonwebtoken
```

**File: `tasks.md`**
```markdown
# Tasks: Add User Authentication

## Phase 1: Core Implementation
- [ ] 1.1 Install dependencies (bcrypt, jsonwebtoken)
- [ ] 1.2 Create User model with password field
- [ ] 1.3 Implement password hashing utility
- [ ] 1.4 Create JWT token generation/validation
- [ ] 1.5 Implement login endpoint
- [ ] 1.6 Implement logout endpoint

## Phase 2: Middleware
- [ ] 2.1 Create authentication middleware
- [ ] 2.2 Add route protection
- [ ] 2.3 Handle token expiration

## Phase 3: Testing
- [ ] 3.1 Unit tests for password hashing
- [ ] 3.2 Unit tests for JWT utilities
- [ ] 3.3 Integration tests for login/logout
- [ ] 3.4 Test authentication middleware

## Phase 4: Documentation
- [ ] 4.1 Update README with auth setup
- [ ] 4.2 Document API endpoints
- [ ] 4.3 Add security best practices guide
```

**File: `specs/auth/spec.md`**
```markdown
## ADDED Requirements

### Requirement: User Login
The system SHALL authenticate users with email and password credentials.

#### Scenario: Successful login
- **WHEN** user provides valid email and password
- **THEN** system returns JWT token
- **AND** token expires in 24 hours

#### Scenario: Invalid credentials
- **WHEN** user provides incorrect password
- **THEN** system returns 401 error
- **AND** error message does not reveal if email exists

### Requirement: Password Security
The system SHALL hash passwords using bcrypt with minimum 10 rounds.

#### Scenario: Password storage
- **WHEN** user creates account
- **THEN** password is hashed before storage
- **AND** plaintext password is never stored

### Requirement: Token Validation
The system SHALL validate JWT tokens on protected endpoints.

#### Scenario: Valid token
- **WHEN** authenticated request with valid token
- **THEN** request proceeds to handler
- **AND** user context is attached to request

#### Scenario: Expired token
- **WHEN** request with expired token
- **THEN** system returns 401 error
- **AND** client receives token refresh instruction
```

**Validate your work:**
```bash
openspec validate add-user-authentication --strict
```

## CLI Command Reference

```bash
# List all commands
openspec --help

# Initialize OpenSpec in project
openspec init

# List existing specs (capabilities)
openspec list --specs
openspec spec list --long

# List active changes (proposals)
openspec list
openspec change list --json

# Show specific spec or change
openspec show auth --type spec
openspec show add-user-authentication

# Show change deltas only
openspec show add-user-authentication --json --deltas-only

# Validate change
openspec validate add-user-authentication
openspec validate add-user-authentication --strict

# Show diff between change and current spec
openspec diff add-user-authentication

# Archive completed change
openspec archive add-user-authentication
openspec archive add-user-authentication --yes  # Non-interactive

# Update OpenSpec instructions
openspec update
```

## Integration with Context7

Use Context7 to find real-world examples and best practices:

```bash
# Find OpenSpec examples in dependencies
@Context7 /openspec/openspec examples of proposal.md
@Context7 /openspec/openspec task structure best practices
@Context7 /openspec/openspec scenario format examples

# Find similar implementations
@Context7 jwt authentication implementation examples
@Context7 password hashing with bcrypt examples
```

## Debugging Common Issues

### Issue: "Change must have at least one delta"

**Problem:** No spec files found or missing delta headers

**Solution:**
```bash
# Check directory structure
ls -la openspec/changes/your-change/specs/

# Ensure spec.md files exist in capability subdirectories
ls -la openspec/changes/your-change/specs/*/spec.md

# Verify delta headers exist
grep "## ADDED Requirements\|## MODIFIED Requirements" \
  openspec/changes/your-change/specs/*/spec.md
```

### Issue: "Requirement must have at least one scenario"

**Problem:** Scenario format is incorrect

**Solution:**
```bash
# Debug scenario parsing
openspec show your-change --json --deltas-only | jq '.deltas[].requirements'

# Check for correct format (4 hashtags)
grep "#### Scenario:" openspec/changes/your-change/specs/*/spec.md

# Common mistakes to fix:
# ❌ - **Scenario: Name**
# ❌ **Scenario**: Name
# ❌ ### Scenario: Name
# ✅ #### Scenario: Name
```

### Issue: "Silent scenario parsing failures"

**Problem:** Scenarios not appearing in validation output

**Solution:**
```bash
# Use JSON output to see what parser found
openspec show your-change --json | jq '.deltas[].requirements[].scenarios'

# Ensure exact format:
# - Line starts with: #### Scenario:
# - Followed by: scenario name
# - Then: - **WHEN** / - **THEN** / - **AND** conditions
```

## Best Practices Summary

1. ✅ **Always validate before committing:** `openspec validate --strict`
2. ✅ **Use Context7 for examples:** Search real implementations
3. ✅ **Follow exact scenario format:** 4 hashtags, WHEN/THEN/AND
4. ✅ **One capability per spec directory:** Don't mix concerns
5. ✅ **Complete MODIFIED requirements:** Include full original text
6. ✅ **Keep proposals focused:** Small, incremental changes
7. ✅ **Update documentation:** README, CHANGELOG, specs in sync



## Complete Example: Creating an OpenSpec Change

### Example: Adding Authentication Feature

**Directory Structure:**
```
openspec/changes/add-user-authentication/
├── proposal.md
├── tasks.md
├── design.md (optional)
└── specs/
    └── auth/
        └── spec.md
```

**File: `proposal.md`**
```markdown
# Proposal: Add User Authentication

## Why
Users need secure access control to protect their data and ensure only authorized users can access the system.

## What Changes
- **ADDED** JWT-based authentication system
- **ADDED** User login/logout endpoints
- **ADDED** Password hashing with bcrypt
- **ADDED** Session management

## Impact
- Affected specs: auth (new capability)
- Affected code: src/auth/, src/middleware/
- Breaking change: None (new feature)
- Dependencies: bcrypt, jsonwebtoken
```

**File: `tasks.md`**
```markdown
# Tasks: Add User Authentication

## Phase 1: Core Implementation
- [ ] 1.1 Install dependencies (bcrypt, jsonwebtoken)
- [ ] 1.2 Create User model with password field
- [ ] 1.3 Implement password hashing utility
- [ ] 1.4 Create JWT token generation/validation
- [ ] 1.5 Implement login endpoint
- [ ] 1.6 Implement logout endpoint

## Phase 2: Middleware
- [ ] 2.1 Create authentication middleware
- [ ] 2.2 Add route protection
- [ ] 2.3 Handle token expiration

## Phase 3: Testing
- [ ] 3.1 Unit tests for password hashing
- [ ] 3.2 Unit tests for JWT utilities
- [ ] 3.3 Integration tests for login/logout
- [ ] 3.4 Test authentication middleware

## Phase 4: Documentation
- [ ] 4.1 Update README with auth setup
- [ ] 4.2 Document API endpoints
- [ ] 4.3 Add security best practices guide
```

**File: `specs/auth/spec.md`**
```markdown
## ADDED Requirements

### Requirement: User Login
The system SHALL authenticate users with email and password credentials.

#### Scenario: Successful login
- **WHEN** user provides valid email and password
- **THEN** system returns JWT token
- **AND** token expires in 24 hours

#### Scenario: Invalid credentials
- **WHEN** user provides incorrect password
- **THEN** system returns 401 error
- **AND** error message does not reveal if email exists

### Requirement: Password Security
The system SHALL hash passwords using bcrypt with minimum 10 rounds.

#### Scenario: Password storage
- **WHEN** user creates account
- **THEN** password is hashed before storage
- **AND** plaintext password is never stored

### Requirement: Token Validation
The system SHALL validate JWT tokens on protected endpoints.

#### Scenario: Valid token
- **WHEN** authenticated request with valid token
- **THEN** request proceeds to handler
- **AND** user context is attached to request

#### Scenario: Expired token
- **WHEN** request with expired token
- **THEN** system returns 401 error
- **AND** client receives token refresh instruction
```

**Validate your work:**
```bash
openspec validate add-user-authentication --strict
```

## CLI Command Reference

```bash
# List all commands
openspec --help

# Initialize OpenSpec in project
openspec init

# List existing specs (capabilities)
openspec list --specs
openspec spec list --long

# List active changes (proposals)
openspec list
openspec change list --json

# Show specific spec or change
openspec show auth --type spec
openspec show add-user-authentication

# Show change deltas only
openspec show add-user-authentication --json --deltas-only

# Validate change
openspec validate add-user-authentication
openspec validate add-user-authentication --strict

# Show diff between change and current spec
openspec diff add-user-authentication

# Archive completed change
openspec archive add-user-authentication
openspec archive add-user-authentication --yes  # Non-interactive

# Update OpenSpec instructions
openspec update
```

## Integration with Context7

Use Context7 to find real-world examples and best practices:

```bash
# Find OpenSpec examples in dependencies
@Context7 /openspec/openspec examples of proposal.md
@Context7 /openspec/openspec task structure best practices
@Context7 /openspec/openspec scenario format examples

# Find similar implementations
@Context7 jwt authentication implementation examples
@Context7 password hashing with bcrypt examples
```

## Debugging Common Issues

### Issue: "Change must have at least one delta"

**Problem:** No spec files found or missing delta headers

**Solution:**
```bash
# Check directory structure
ls -la openspec/changes/your-change/specs/

# Ensure spec.md files exist in capability subdirectories
ls -la openspec/changes/your-change/specs/*/spec.md

# Verify delta headers exist
grep "## ADDED Requirements\|## MODIFIED Requirements" \
  openspec/changes/your-change/specs/*/spec.md
```

### Issue: "Requirement must have at least one scenario"

**Problem:** Scenario format is incorrect

**Solution:**
```bash
# Debug scenario parsing
openspec show your-change --json --deltas-only | jq '.deltas[].requirements'

# Check for correct format (4 hashtags)
grep "#### Scenario:" openspec/changes/your-change/specs/*/spec.md

# Common mistakes to fix:
# ❌ - **Scenario: Name**
# ❌ **Scenario**: Name
# ❌ ### Scenario: Name
# ✅ #### Scenario: Name
```

### Issue: "Silent scenario parsing failures"

**Problem:** Scenarios not appearing in validation output

**Solution:**
```bash
# Use JSON output to see what parser found
openspec show your-change --json | jq '.deltas[].requirements[].scenarios'

# Ensure exact format:
# - Line starts with: #### Scenario:
# - Followed by: scenario name
# - Then: - **WHEN** / - **THEN** / - **AND** conditions
```

## Best Practices Summary

1. ✅ **Always validate before committing:** `openspec validate --strict`
2. ✅ **Use Context7 for examples:** Search real implementations
3. ✅ **Follow exact scenario format:** 4 hashtags, WHEN/THEN/AND
4. ✅ **One capability per spec directory:** Don't mix concerns
5. ✅ **Complete MODIFIED requirements:** Include full original text
6. ✅ **Keep proposals focused:** Small, incremental changes
7. ✅ **Update documentation:** README, CHANGELOG, specs in sync





<!-- CONTEXT7:START -->
# Context7 Instructions

**CRITICAL**: Use MCP Context7 to access up-to-date library documentation before adding dependencies.

Context7 provides real-time access to documentation for thousands of libraries and frameworks. Always check Context7 before adding new dependencies to ensure you're using the latest stable versions and following best practices.

## Core Functions

### 1. resolve-library-id

Resolve a package name to a Context7-compatible library ID:

```
Input: Library name (e.g., "tokio", "react", "fastapi")
Output: Context7 library ID (e.g., "/tokio-rs/tokio", "/facebook/react")
```

**MUST** use this function before `get-library-docs` unless the user provides an explicit library ID.

### 2. get-library-docs

Fetch documentation for a library:

```
Input: Context7 library ID, optional topic, token limit
Output: Relevant documentation, examples, API reference
```

Options:
- `topic`: Focus on specific area (e.g., "routing", "hooks", "async")
- `tokens`: Control documentation size (default: 5000)

## Mandatory Usage

### Before Adding Dependencies

**CRITICAL**: Check Context7 for every new dependency.

#### Rust Example
```
Adding tokio:
1. resolve-library-id("tokio") → "/tokio-rs/tokio"
2. get-library-docs("/tokio-rs/tokio") → Latest version, features, examples
3. Check for breaking changes in latest version
4. Add to Cargo.toml with correct version and features
```

#### TypeScript Example
```
Adding express:
1. resolve-library-id("express") → "/expressjs/express"
2. get-library-docs("/expressjs/express") → Latest version, middleware patterns
3. Review TypeScript type definitions availability
4. Add to package.json with latest stable version
```

#### Python Example
```
Adding fastapi:
1. resolve-library-id("fastapi") → "/tiangolo/fastapi"
2. get-library-docs("/tiangolo/fastapi", topic="async") → Async patterns
3. Check Python version requirements
4. Add to pyproject.toml or requirements.txt
```

## Best Practices

### 1. Version Verification

Always verify the latest stable version:

```
1. Use resolve-library-id to find the library
2. Use get-library-docs to see current version
3. Check for security advisories
4. Review changelog for breaking changes
5. Document version choice in code/commits
```

### 2. Topic-Focused Queries

Use the topic parameter for specific information:

```
Examples:
- get-library-docs("/tokio-rs/tokio", topic="channels")
- get-library-docs("/facebook/react", topic="hooks")
- get-library-docs("/psf/requests", topic="authentication")
```

### 3. Migration Guides

When updating major versions:

```
1. Get docs for current version
2. Get docs for target version
3. Look for migration guide in documentation
4. Review breaking changes
5. Plan migration strategy
```

### 4. Best Practices Discovery

Learn idiomatic usage patterns:

```
1. Get library docs with relevant topic
2. Review code examples
3. Check for recommended patterns
4. Follow security best practices
5. Implement according to documentation
```

## Integration with Development Workflow

### Adding New Dependency

```
1. Identify need for library
2. Use resolve-library-id to find correct library
3. Use get-library-docs to review:
   - Latest stable version
   - Features and capabilities
   - Usage examples
   - Security considerations
4. Add dependency with correct version
5. Document why this library was chosen
6. Update CHANGELOG.md
```

### Updating Existing Dependency

```
1. Use get-library-docs for current version
2. Use get-library-docs for latest version
3. Review changelog between versions
4. Check for breaking changes
5. Update code if needed
6. Update dependency version
7. Test thoroughly
```

### Troubleshooting

```
1. Use get-library-docs with specific topic
2. Search for error message or issue
3. Review examples for correct usage
4. Check for known issues or workarounds
5. Verify you're following best practices
```

## Common Patterns

### Pattern 1: Dependency Selection

```
Problem: Need HTTP client library

1. resolve-library-id("requests") for Python
   OR resolve-library-id("reqwest") for Rust
   OR resolve-library-id("axios") for TypeScript

2. get-library-docs for each candidate

3. Compare features, performance, maintenance

4. Choose best fit for requirements

5. Document decision
```

### Pattern 2: Feature Discovery

```
Need: Async file operations in Rust

1. resolve-library-id("tokio") → "/tokio-rs/tokio"
2. get-library-docs("/tokio-rs/tokio", topic="file I/O")
3. Review async file operation examples
4. Implement using documented patterns
```

### Pattern 3: Security Verification

```
Before adding crypto library:

1. resolve-library-id("ring") for Rust
2. get-library-docs("/briansmith/ring")
3. Check security audit status
4. Review recommended algorithms
5. Verify actively maintained
6. Add with appropriate features
```

## Library ID Format

Context7 library IDs follow patterns:

- GitHub: `/org/repo` or `/org/repo/version`
- Examples:
  - `/tokio-rs/tokio`
  - `/vercel/next.js`
  - `/psf/requests`
  - `/vercel/next.js/v14.0.0` (specific version)

## Error Handling

If library not found:

1. Verify correct library name
2. Try alternative names or repos
3. Check if library is on supported platforms
4. Consider using official documentation as fallback

<!-- CONTEXT7:END -->



<!-- GIT:START -->

**AI Assistant Git Push Mode**: MANUAL

**CRITICAL**: Never execute `git push` commands automatically.
Always provide push commands for manual execution by the user.

Example:
```
✋ MANUAL ACTION REQUIRED:
Run these commands manually (SSH password may be required):
  git push origin main
  git push origin v1.0.0
```

# Git Workflow Rules

**CRITICAL**: Specific rules and patterns for Git version control workflow.

## Git Workflow Overview

This project follows a strict Git workflow to ensure code quality and proper version control.

**NEVER commit code without tests passing. NEVER create tags without full quality checks.**

## Initial Repository Setup

### New Project Initialization

**⚠️ CRITICAL**: Only run initialization commands if `.git` directory does NOT exist!

```bash
# Check if Git repository already exists
if [ -d .git ]; then
  echo "❌ Git repository already initialized. Skipping git init."
  echo "Current status:"
  git status
  git remote -v
  exit 0
fi

# If no .git directory exists, initialize:

# Initialize Git repository
git init

# Add all files
git add .

# Initial commit
git commit -m "chore: Initial project setup"

# Rename default branch to main (GitHub standard)
git branch -M main

# Add remote (if applicable)
git remote add origin <repository-url>
```

**AI Assistant Behavior:**

```
BEFORE running any Git initialization commands:

1. Check if .git directory exists
2. If exists:
   ✅ Repository already configured
   ❌ DO NOT run: git init
   ❌ DO NOT run: git branch -M main
   ✅ Check status: git status
   ✅ Show remotes: git remote -v
   
3. If not exists:
   ✅ Safe to initialize
   ✅ Run full initialization sequence
```

## AI Assistant Git Checks

**CRITICAL**: AI assistants MUST perform these checks before Git operations:

### Automatic Checks

```bash
# 1. Check if Git repository exists
if [ ! -d .git ]; then
  echo "No Git repository found."
  # Ask user if they want to initialize
fi

# 2. Check if there are unstaged changes
git status --short

# 3. Check current branch
CURRENT_BRANCH=$(git branch --show-current)
echo "On branch: $CURRENT_BRANCH"

# 4. Check if remote exists
git remote -v

# 5. Check for unpushed commits
git log origin/main..HEAD --oneline 2>/dev/null
```

### Before Git Commands

**NEVER execute if `.git` directory exists:**
- ❌ `git init` - Repository already initialized
- ❌ `git branch -M main` - Branch may already be configured
- ❌ `git remote add origin` - Remote may already exist (check first with `git remote -v`)
- ❌ `git config user.name/email` - User configuration is personal
- ❌ Reconfiguration commands - Repository is already set up

**ALWAYS safe to execute:**
- ✅ `git status` - Check repository state
- ✅ `git add` - Stage changes
- ✅ `git commit` - Create commits (after quality checks)
- ✅ `git log` - View history
- ✅ `git diff` - View changes
- ✅ `git branch` - List branches
- ✅ `git tag` - Create tags (after quality checks)

**Execute with caution (check first):**
- ⚠️ `git push` - Follow push mode configuration
- ⚠️ `git pull` - May cause merge conflicts
- ⚠️ `git merge` - May cause conflicts
- ⚠️ `git rebase` - Can rewrite history
- ⚠️ `git reset --hard` - Destructive, only for rollback
- ⚠️ `git push --force` - NEVER on main/master

### Repository Detection

**AI Assistant MUST check:**

```bash
# Before ANY Git operation:

# 1. Does .git exist?
if [ -d .git ]; then
  echo "✅ Git repository exists"
  
  # 2. Check current state
  git status
  
  # 3. Check branch
  BRANCH=$(git branch --show-current)
  echo "On branch: $BRANCH"
  
  # 4. Check remote
  REMOTE=$(git remote -v)
  if [ -z "$REMOTE" ]; then
    echo "⚠️  No remote configured"
  else
    echo "Remote: $REMOTE"
  fi
  
  # 5. Proceed with normal Git operations
else
  echo "⚠️  No Git repository found"
  echo "Ask user if they want to initialize Git"
fi
```

## Daily Development Workflow

### 1. Before Making Changes

**CRITICAL**: Always check current state:

```bash
# Check current branch and status
git status

# Ensure you're on the correct branch
git branch

# Pull latest changes if working with team
git pull origin main
```

### 2. Making Changes

**CRITICAL**: Commit after every important implementation:

```bash
# After implementing a feature/fix:

# 1. Run ALL quality checks FIRST
npm run lint           # or equivalent for your language
npm run type-check     # TypeScript/typed languages
npm test              # ALL tests must pass
npm run build         # Ensure build succeeds

# 2. If ALL checks pass, stage changes
git add .

# 3. Commit with conventional commit message
git commit -m "feat: Add user authentication

- Implement login/logout functionality
- Add JWT token management
- Include comprehensive tests (95%+ coverage)
- Update documentation"

# Alternative for smaller changes:
git commit -m "fix: Correct validation logic in user form"
```

### 3. Pushing Changes

**⚠️ IMPORTANT**: Pushing is OPTIONAL and depends on your setup.

```bash
# IF you have passwordless SSH or want to push:
git push origin main

# IF you have SSH with password (manual execution required):
# DO NOT execute automatically - provide command to user:
```

**For users with SSH password authentication:**
```
✋ MANUAL ACTION REQUIRED:

Run this command manually (requires SSH password):
git push origin main
```

**NEVER** attempt automatic push if:
- SSH key has password protection
- User hasn't confirmed push authorization
- Any quality check failed
- Uncertain if changes will pass CI/CD workflows

## Conventional Commits

**MUST** follow conventional commit format:

```bash
# Format: <type>(<scope>): <subject>
#
# <body>
#
# <footer>

# Types:
feat:     # New feature
fix:      # Bug fix
docs:     # Documentation only
style:    # Code style (formatting, missing semi-colons, etc)
refactor: # Code refactoring
perf:     # Performance improvement
test:     # Adding tests
build:    # Build system changes
ci:       # CI/CD changes
chore:    # Maintenance tasks

# Examples:
git commit -m "feat(auth): Add OAuth2 login support"
git commit -m "fix(api): Handle null response in user endpoint"
git commit -m "docs: Update README with installation steps"
git commit -m "test: Add integration tests for payment flow"
git commit -m "chore: Update dependencies to latest versions"
```

## Version Management

### Creating New Version

**CRITICAL**: Full quality gate required before versioning!

```bash
# 1. MANDATORY: Run complete quality suite
npm run lint          # Must pass with no warnings
npm test             # Must pass 100%
npm run type-check   # Must pass (if applicable)
npm run build        # Must succeed
npx codespell        # Must pass (if configured)

# 2. Update version in package.json/Cargo.toml/etc
# Use semantic versioning:
# - MAJOR: Breaking changes (1.0.0 -> 2.0.0)
# - MINOR: New features, backwards compatible (1.0.0 -> 1.1.0)
# - PATCH: Bug fixes (1.0.0 -> 1.0.1)

# 3. Update CHANGELOG.md
# Document all changes in this version:
## [1.2.0] - 2024-01-15
### Added
- New feature X
- New feature Y

### Fixed
- Bug in component Z

### Changed
- Refactored module A

# 4. Commit version changes
git add .
git commit -m "chore: Release version 1.2.0

- Updated version to 1.2.0
- Updated CHANGELOG.md with release notes"

# 5. Create annotated tag
git tag -a v1.2.0 -m "Release version 1.2.0

Major changes:
- Feature X
- Feature Y
- Bug fix Z

All tests passing ✅
Coverage: 95%+ ✅
Linting: Clean ✅
Build: Success ✅"

# 6. OPTIONAL: Push tag (manual if SSH password)
# Only if you're CERTAIN it will pass CI/CD workflows!
```

**For users requiring manual push:**
```
✋ MANUAL ACTIONS REQUIRED:

1. Verify all quality checks passed locally
2. Push commits:
   git push origin main

3. Push tag:
   git push origin v1.2.0

Note: Tag push will trigger CI/CD workflows and may create GitHub release.
Only push if you're confident all checks will pass.
```

## Quality Gate Enforcement

### Before ANY Commit

**MANDATORY CHECKS**:

```bash
# Checklist - ALL must pass:
☐ Code formatted
☐ Linter passes (no warnings)
☐ Type check passes
☐ ALL tests pass (100%)
☐ Coverage meets threshold (95%+)
☐ Build succeeds
☐ No console errors/warnings

# Run quality check script:
npm run quality-check  # or equivalent

# If ANY check fails:
# ❌ DO NOT COMMIT
# ❌ FIX THE ISSUES FIRST
```

### Before Tag Creation

**MANDATORY CHECKS** (even stricter):

```bash
# Extended checklist - ALL must pass:
☐ All pre-commit checks passed
☐ Codespell passes (no typos)
☐ Security audit clean
☐ Dependencies up to date
☐ Documentation updated
☐ CHANGELOG.md updated
☐ Version bumped correctly
☐ All workflows would pass

# Run comprehensive check:
npm run lint
npm test
npm run type-check
npm run build
npx codespell
npm audit

# Only create tag if everything is green!
```

## Error Recovery & Rollback

### When Implementation Is Failing

If the AI is making repeated mistakes and user is frustrated:

```bash
# 1. Identify last stable commit
git log --oneline -10

# 2. Create backup branch of current work
git branch backup-failed-attempt

# 3. Hard reset to last stable version
git reset --hard <last-stable-commit-hash>

# 4. Verify stability
npm test
npm run build

# 5. Reimplement from scratch using DIFFERENT approach
# ⚠️ DO NOT repeat the same techniques that failed before
# ⚠️ Review AGENTS.md for alternative patterns
# ⚠️ Consider different architecture/design

# 6. After successful reimplementation
git branch -D backup-failed-attempt  # Delete backup if no longer needed
```

### Undo Last Commit (Not Pushed)

```bash
# Keep changes, undo commit
git reset --soft HEAD~1

# Discard changes completely
git reset --hard HEAD~1
```

### Revert Pushed Commit

```bash
# Create revert commit
git revert <commit-hash>

# Then push (manual if SSH password)
```

## Branch Strategy

### Feature Branches

```bash
# Create feature branch
git checkout -b feature/user-authentication

# Work on feature...
# Commit regularly with quality checks

# When feature complete and tested:
git checkout main
git merge feature/user-authentication

# Delete feature branch
git branch -d feature/user-authentication
```

### Hotfix Workflow

```bash
# Critical bug in production
git checkout -b hotfix/critical-security-fix

# Fix the bug
# MUST include tests
# MUST pass all quality checks

git commit -m "fix: Critical security vulnerability in auth

- Patch authentication bypass
- Add regression tests
- Update security documentation"

# Merge to main
git checkout main
git merge hotfix/critical-security-fix

# Tag immediately if production fix
git tag -a v1.2.1 -m "Hotfix: Security patch"

# Manual push if required
```

## Critical AI Assistant Rules

### Repository Initialization

**BEFORE any `git init` or setup commands:**

```
1. Check for .git directory existence
2. If .git exists:
   - ❌ STOP - Repository already configured
   - ❌ DO NOT run git init
   - ❌ DO NOT run git config
   - ❌ DO NOT run git branch -M
   - ❌ DO NOT reconfigure anything
   - ✅ Use existing repository as-is
   
3. If .git does NOT exist:
   - ✅ Ask user if they want Git initialization
   - ✅ Run initialization sequence if approved
```

### Push Command Behavior

**Based on configured push mode:**

```
Manual Mode (DEFAULT):
  ❌ NEVER execute: git push
  ✅ ALWAYS provide: "Run manually: git push origin main"
  
Prompt Mode:
  ⚠️  ALWAYS ask first: "Ready to push. Proceed? [Y/n]"
  ✅ Execute only if user confirms
  
Auto Mode:
  ⚠️  Check quality first
  ⚠️  Only if 100% confident
  ✅ Execute if all checks passed
```

### Quality Gate Enforcement

**MANDATORY checks before commit:**

```bash
# Run in this exact order:
1. npm run lint          # or language equivalent
2. npm run type-check    # if applicable
3. npm test             # ALL tests must pass
4. npm run build        # must succeed

# If ANY fails:
❌ STOP - DO NOT commit
❌ Fix issues first
❌ Re-run all checks

# If ALL pass:
✅ Safe to commit
✅ Proceed with git add and commit
```

**MANDATORY checks before tag:**

```bash
# Extended checks for version tags:
1. All commit checks above +
2. npx codespell        # no typos
3. npm audit            # no vulnerabilities
4. CHANGELOG.md updated
5. Version bumped correctly
6. Documentation current

# If ANY fails:
❌ STOP - DO NOT create tag
❌ Fix issues
❌ Re-verify everything

# Only create tag if 100% green!
```

## Best Practices

### DO's ✅

- **ALWAYS** check if .git exists before init commands
- **ALWAYS** run tests before commit
- **ALWAYS** use conventional commit messages
- **ALWAYS** update CHANGELOG for versions
- **COMMIT** after each important implementation
- **TAG** releases with semantic versions
- **VERIFY** quality gates before tagging
- **DOCUMENT** breaking changes clearly
- **REVERT** when implementation is failing repeatedly
- **ASK** user before automatic push
- **PROVIDE** manual commands for SSH password users
- **CHECK** repository state before operations
- **RESPECT** existing Git configuration

### DON'Ts ❌

- **NEVER** run `git init` if .git exists
- **NEVER** run `git config` (user-specific)
- **NEVER** reconfigure existing repository
- **NEVER** commit without passing tests
- **NEVER** commit with linting errors
- **NEVER** commit with build failures
- **NEVER** create tag without quality checks
- **NEVER** push automatically with SSH password
- **NEVER** push if uncertain about CI/CD success
- **NEVER** commit console.log/debug code
- **NEVER** commit credentials or secrets
- **NEVER** force push to main/master
- **NEVER** rewrite published history
- **NEVER** skip hooks (--no-verify)
- **NEVER** assume repository configuration

## SSH Configuration

### For Users with SSH Password

If your SSH key has password protection:

**Configuration in AGENTS.md or project settings:**

```yaml
git_workflow:
  auto_push: false
  push_mode: "manual"
  reason: "SSH key has password protection"
```

**AI Assistant Behavior:**
- ✅ Provide push commands in chat
- ✅ Wait for user manual execution
- ❌ Never attempt automatic push
- ❌ Never execute git push commands

### For Users with Passwordless SSH

```yaml
git_workflow:
  auto_push: true  # or prompt each time
  push_mode: "auto"
```

## Git Hooks

### Pre-commit Hook

Create `.git/hooks/pre-commit`:

```bash
#!/bin/sh

echo "Running pre-commit checks..."

# Run linter
npm run lint
if [ $? -ne 0 ]; then
  echo "❌ Linting failed. Commit aborted."
  exit 1
fi

# Run tests
npm test
if [ $? -ne 0 ]; then
  echo "❌ Tests failed. Commit aborted."
  exit 1
fi

# Run type check (if applicable)
if command -v tsc &> /dev/null; then
  npm run type-check
  if [ $? -ne 0 ]; then
    echo "❌ Type check failed. Commit aborted."
    exit 1
  fi
fi

echo "✅ All pre-commit checks passed!"
exit 0
```

### Pre-push Hook

Create `.git/hooks/pre-push`:

```bash
#!/bin/sh

echo "Running pre-push checks..."

# Run full test suite
npm test
if [ $? -ne 0 ]; then
  echo "❌ Tests failed. Push aborted."
  exit 1
fi

# Run build
npm run build
if [ $? -ne 0 ]; then
  echo "❌ Build failed. Push aborted."
  exit 1
fi

echo "✅ All pre-push checks passed!"
exit 0
```

Make hooks executable:
```bash
chmod +x .git/hooks/pre-commit
chmod +x .git/hooks/pre-push
```

## CI/CD Integration

### Before Providing Push Commands

**CRITICAL**: Only suggest push if confident about CI/CD success:

```
✅ Provide push command if:
- All local tests passed
- All linting passed
- Build succeeded
- Coverage meets threshold
- No warnings or errors
- Code follows AGENTS.md standards
- Similar changes passed CI/CD before

❌ DO NOT provide push command if:
- ANY quality check failed
- Uncertain about CI/CD requirements
- Making experimental changes
- First time working with this codebase
- User seems uncertain

Instead say:
"I recommend running the full CI/CD pipeline locally first to ensure 
the changes will pass. Once confirmed, you can push manually."
```

## GitHub MCP Server Integration

**If GitHub MCP Server is available**, use it for automated workflow monitoring.

### Workflow Validation After Push

```
After every git push (manual or auto):

1. Wait 5-10 seconds for workflows to trigger

2. Check workflow status via GitHub MCP:
   - List workflow runs for latest commit
   - Check status of each workflow

3. If workflows are RUNNING:
   ⏳ Report: "CI/CD workflows in progress..."
   ✅ Continue with other tasks
   ✅ Check again in next user interaction
   
4. If workflows COMPLETED:
   - All passed: ✅ Report success
   - Some failed: ❌ Fetch errors and fix

5. If workflows FAILED:
   a. Fetch complete error logs via GitHub MCP
   b. Display errors to user
   c. Analyze against AGENTS.md standards
   d. Propose specific fixes
   e. Implement fixes
   f. Run local quality checks
   g. Commit fixes
   h. Provide push command for retry
```

### Next Interaction Check

```
On every user message after a push:

if (github_mcp_available && last_push_timestamp) {
  // Check workflow status
  const status = await checkWorkflows();
  
  if (status.running) {
    console.log('⏳ CI/CD still running, will check later');
  } else if (status.failed) {
    console.log('❌ CI/CD failures detected!');
    await analyzeAndFixErrors(status.errors);
  } else {
    console.log('✅ All CI/CD workflows passed!');
  }
}
```

### Error Analysis Flow

```
When workflow fails:

1. Fetch error via GitHub MCP:
   - Workflow name
   - Job name  
   - Failed step
   - Error output
   - Full logs

2. Categorize error:
   - Test failure → Fix test or implementation
   - Lint error → Format/fix code style
   - Build error → Fix compilation issues
   - Type error → Fix type definitions
   - Coverage error → Add more tests

3. Fix following AGENTS.md:
   - Apply correct pattern from AGENTS.md
   - Add tests if needed
   - Verify locally before committing

4. Commit fix:
   git commit -m "fix: Resolve CI/CD failure - [specific issue]"

5. Provide push command:
   "Ready to retry. Run: git push origin main"

6. After next push:
   - Monitor again
   - Verify fix worked
```

### CI/CD Confidence Check

**Before suggesting push:**

```
Assess confidence in CI/CD success:

HIGH confidence (safe to push):
✅ All local checks passed
✅ Similar changes passed CI before
✅ No experimental changes
✅ Follows AGENTS.md exactly
✅ Comprehensive tests
✅ No unusual patterns

MEDIUM confidence (verify first):
⚠️ First time with this pattern
⚠️ Modified build configuration
⚠️ Changed dependencies
⚠️ Cross-platform concerns
→ Suggest: "Let's verify locally first"

LOW confidence (don't push yet):
❌ Experimental implementation
❌ Skipped some tests
❌ Uncertain about compatibility
❌ Modified CI/CD files
→ Say: "Let's run additional checks first"
```

## Troubleshooting

### Merge Conflicts

```bash
# View conflicts
git status

# Edit conflicted files (marked with <<<<<<<, =======, >>>>>>>)

# After resolving:
git add <resolved-files>
git commit -m "fix: Resolve merge conflicts"
```

### Accidental Commit

```bash
# Undo last commit, keep changes
git reset --soft HEAD~1

# Make corrections
# Re-commit properly
```

### Lost Commits

```bash
# View all actions
git reflog

# Recover lost commit
git checkout <commit-hash>
git checkout -b recovery-branch
```

<!-- GIT:END -->
