# Vectorizer Server Configuration File
# Updated for v0.28.1 - REST API architecture with MCP support
# Simplified deployment without complex dependencies

# =============================================================================
# FILE WATCHER CONFIGURATION - DISABLED FOR CLUSTER MODE
# =============================================================================
file_watcher:
  enabled: false
  debounce_delay_ms: 1000
  min_file_size_bytes: 1
  max_file_size_bytes: 10485760 # 10MB
  hash_validation_enabled: true
  collection_name: "workspace-files"

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
server:
  # Basic server settings
  host: "127.0.0.1" # Server bind address (localhost for testing)
  port: 15002 # Server port
  mcp_port: 15002 # MCP server port

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
logging:
  # Log levels
  level: "info" # Global log level: error/warn/info/debug/trace
  format: "json" # Log format: json/text

  # Request/Response logging
  log_requests: true # Log all requests
  log_responses: false # Log responses (can be verbose)
  log_errors: true # Log errors

  # Correlation ID tracking
  correlation_id_enabled: true # Add correlation IDs to all requests

# =============================================================================
# GPU CONFIGURATION (Metal GPU - macOS only)
# =============================================================================
gpu:
  # Enable GPU acceleration (default: true on macOS, false on other platforms)
  enabled: true

  # Batch size for GPU batch operations (default: 1000)
  # Higher values = better GPU utilization, more memory usage
  batch_size: 1000

  # Fallback to CPU if GPU initialization fails (default: true)
  fallback_to_cpu: true

  # Preferred backend: auto (detect best), metal (force Metal on macOS), cpu (disable GPU)
  # Options: auto | metal | cpu
  preferred_backend: "auto"

# =============================================================================
# MONITORING & TELEMETRY CONFIGURATION
# =============================================================================
monitoring:
  # Prometheus metrics
  prometheus:
    enabled: true # Enable Prometheus metrics export
    endpoint: "/prometheus/metrics" # Metrics endpoint path

  # System metrics collector
  system_metrics:
    enabled: true # Enable periodic system metrics collection
    interval_secs: 15 # Collection interval in seconds

  # OpenTelemetry distributed tracing
  telemetry:
    enabled: false # Enable OpenTelemetry tracing (requires OTLP collector)
    otlp_endpoint: "http://localhost:4317" # OTLP gRPC endpoint
    service_name: "vectorizer" # Service name in traces
    sampler: "always_on" # Sampling strategy: always_on/always_off/parent_based

  # Metrics to track
  metrics:
    # Search metrics
    search_enabled: true # Track search requests, latency, results

    # Indexing metrics
    indexing_enabled: true # Track insert operations, vector/collection counts

    # Replication metrics
    replication_enabled: true # Track replication lag, bytes sent/received

    # System metrics
    system_enabled: true # Track memory usage, cache hits, API errors

# =============================================================================
# CLUSTER CONFIGURATION (Distributed Sharding)
# =============================================================================
# Cluster mode enables distributed sharding across multiple Vectorizer servers
# for horizontal scalability and high availability.
#
# When enabled, collections with sharding enabled will automatically distribute
# shards across cluster nodes using consistent hashing.
#
# Example: 3-node cluster setup
# -----------------------------
# Node 1 (this server):
#   cluster:
#     enabled: true
#     node_id: "node-1"
#     servers:
#       - id: "node-1"
#         address: "192.168.1.10"
#         grpc_port: 15003
#       - id: "node-2"
#         address: "192.168.1.11"
#         grpc_port: 15003
#       - id: "node-3"
#         address: "192.168.1.12"
#         grpc_port: 15003
#
# Node 2 and Node 3 should have the same servers list but different node_id.
#
# For more information, see:
# - docs/users/configuration/CLUSTER.md
# - docs/users/collections/SHARDING.md
# - docs/deployment/CLUSTER.md

cluster:
  # Enable cluster mode for distributed sharding across multiple servers
  # When false, sharding works only within a single server
  enabled: true
  
  # This server's unique node ID
  # Auto-generated UUID if not specified (recommended: use descriptive names)
  # Examples: "node-1", "node-dc1-1", "vectorizer-primary"
  node_id: "node-1"  # Cluster node identifier
  
  # Discovery method for finding cluster nodes
  # Options:
  #   - "static": Manually configure all nodes in servers list (recommended)
  #   - "dns": DNS-based discovery (future feature)
  #   - "service_registry": Service registry discovery (future feature)
  discovery: "static"
  
  # gRPC request timeout in milliseconds
  # Operations to remote nodes will fail after this timeout
  # Increase for slow networks or high-latency connections
  timeout_ms: 5000
  
  # Number of retries for failed operations
  # Failed operations (insert, update, delete, search) will be retried this many times
  # before returning an error
  retry_count: 3
  
  # Static server list (required when discovery: "static")
  # All nodes in the cluster must be listed here
  # Each node should have the same list (with different node_id)
  servers:
    - id: "node-1"
      address: "127.0.0.1"      # Local node for testing
      grpc_port: 15003
    # Add more nodes as needed:
    # - id: "node-2"
    #   address: "192.168.1.11"
    #   grpc_port: 15003
    # - id: "node-3"
    #   address: "192.168.1.12"
    #   grpc_port: 15003

# =============================================================================
# DEFAULT COLLECTION CONFIGURATION
# =============================================================================
collections:
  defaults:
    # Vector settings
    dimension: 512 # Default vector dimension
    metric: "cosine" # Default distance metric: cosine/euclidean/dot_product

    # Quantization (memory optimization)
    quantization:
      type: "sq" # Quantization type: sq (scalar quantization)
      sq:
        bits: 8 # SQ bits per dimension

    # Embedding settings
    embedding:
      model: "bm25" # Default embedding: bm25
      bow:
        vocab_size: 50000 # BOW vocabulary size
        max_sequence_length: 512 # Maximum sequence length
      hash:
        hash_size: 1000000 # Feature hash size
      ngram:
        ngram_range: [1, 3] # N-gram range [min, max]
        vocab_size: 100000 # N-gram vocabulary size
      bm25:
        k1: 1.5 # BM25 k1 parameter
        b: 0.75 # BM25 b parameter

    # Index settings (HNSW)
    index:
      type: "hnsw" # Index type: hnsw/optimized_hnsw
      hnsw:
        m: 16 # HNSW connections per layer
        ef_construction: 200 # Construction search width
        ef_search: 64 # Query search width
      optimized_hnsw:
        batch_size: 1000 # Batch insertion size
        parallel: true # Enable parallel construction
        initial_capacity: 100000 # Pre-allocation size
        max_connections: 16 # Maximum connections per layer
        max_connections_0: 32 # Connections for layer 0

# =============================================================================
# TRANSMUTATION DOCUMENT CONVERSION (v0.8.0)
# =============================================================================
transmutation:
  # Enable/disable transmutation document conversion
  enabled: true

  # Maximum file size for conversion (in MB)
  # Files larger than this will be skipped
  max_file_size_mb: 50

  # Conversion timeout (in seconds)
  # Conversions taking longer than this will be aborted
  conversion_timeout_secs: 300

  # Preserve images during conversion
  # Note: Requires additional dependencies (LibreOffice for DOCX images)
  preserve_images: false

# Supported formats when transmutation feature is enabled:
# - PDF (with page metadata) - 98x faster than Docling
# - DOCX (with page metadata) - Pure Rust
# - XLSX (as Markdown tables) - 148 pages/sec
# - PPTX (slides as pages) - 1639 pages/sec
# - HTML/HTM (clean Markdown) - 2110 pages/sec
# - XML (structured Markdown) - 2353 pages/sec
# - Images (JPG, JPEG, PNG, TIFF, TIF, BMP, GIF, WEBP) - Requires Tesseract OCR

# External dependencies (optional, for full format support):
# - Linux: sudo apt-get install poppler-utils tesseract-ocr
# - macOS: brew install poppler tesseract
# - Windows: choco install poppler tesseract

# Build with transmutation support:
# cargo build --release --features transmutation

# =============================================================================
# TEXT NORMALIZATION CONFIGURATION
# =============================================================================
normalization:
  # Enable/disable text normalization globally
  enabled: true

  # Normalization level: conservative/moderate/aggressive
  # - conservative: Only fixes line endings (CRLF -> LF), preserves structure
  # - moderate: Collapses whitespace, normalizes unicode, fixes line endings
  # - aggressive: All moderate + removes extra spaces, normalizes quotes
  level: "conservative"

  # Line ending normalization
  line_endings:
    normalize_crlf: true # Normalize CRLF to LF
    normalize_cr: true # Normalize CR to LF
    collapse_multiple_newlines: true # Collapse 3+ newlines to 2
    trim_trailing_whitespace: true # Remove trailing spaces from lines

  # Content-specific normalization
  content_detection:
    enabled: true # Auto-detect content type (code/text/markdown)
    preserve_code_structure: true # Don't normalize indentation in code blocks
    preserve_markdown_format: true # Preserve markdown formatting

  # Normalization cache
  cache:
    enabled: true # Enable normalization result caching
    max_entries: 10000 # Maximum cache entries
    ttl_seconds: 3600 # Cache entry TTL (1 hour)

  # Apply normalization at different stages
  stages:
    on_file_read: true # Normalize when reading files
    on_chunk_creation: true # Normalize when creating chunks
    on_payload_return: true # Normalize when returning payloads
    on_cache_load: true # Normalize when loading from cache

# =============================================================================
# PERFORMANCE OPTIMIZATION CONFIGURATION
# =============================================================================
performance:
  # CPU optimization settings
  cpu:
    max_threads: 8 # Maximum CPU threads for parallel operations
    enable_simd: true # Enable SIMD optimizations
    memory_pool_size_mb: 512 # Memory pool size for allocations (RAM limit)

  # SIMD (Single Instruction Multiple Data) configuration
  simd:
    enabled: true # Enable SIMD optimizations globally
    # SIMD is automatically used for:
    # - Vector dot product calculations
    # - Euclidean distance calculations
    # - Cosine similarity calculations
    # Runtime CPU feature detection enables SIMD when available

  # Batch processing
  batch:
    default_size: 100 # Default batch size for operations
    max_size: 1000 # Maximum batch size
    parallel_processing: true # Enable parallel batch processing

  # Query result caching
  query_cache:
    enabled: true # Enable LRU query result caching
    max_size: 1000 # Maximum number of cached queries
    ttl_seconds: 300 # Cache entry TTL (5 minutes)
    warmup_enabled: false # Enable cache warmup on startup

# =============================================================================
# WORKSPACE CONFIGURATION
# =============================================================================
workspace:
  # Enable workspace functionality
  enabled: false

  # Default workspace file
  default_workspace_file: "./workspace.yml"

# =============================================================================
# API CONFIGURATION
# =============================================================================
api:
  # REST API settings
  rest:
    enabled: true # Enable REST API
    cors_enabled: true # Enable CORS
    max_request_size_mb: 10 # Maximum request size
    timeout_seconds: 30 # Request timeout

  # MCP (Model Context Protocol) settings
  mcp:
    enabled: true # Enable MCP server
    port: 15002 # MCP server port
    max_connections: 100 # Maximum concurrent connections

  # gRPC API settings
  grpc:
    enabled: true # Enable gRPC server
    port: 15003 # gRPC server port (default: REST port + 1)
    max_concurrent_streams: 100 # Maximum concurrent gRPC streams
    max_message_size_mb: 10 # Maximum gRPC message size in MB

# =============================================================================
# AUTHENTICATION CONFIGURATION
# =============================================================================
# Authentication provides JWT and API key based access control.
# When enabled, all API endpoints (except /health and /metrics) require authentication.

auth:
  # Enable/disable authentication globally
  # When false, all endpoints are publicly accessible (development mode)
  # When true, authentication is required for all protected endpoints
  enabled: false

  # JWT (JSON Web Token) configuration
  # Used for user authentication via login endpoint
  jwt_secret: "your-secret-key-change-in-production"  # IMPORTANT: Change in production!
  jwt_expiration: 3600  # Token expiration in seconds (default: 1 hour)

  # API Key configuration
  # Used for machine-to-machine authentication
  api_key_length: 32  # Length of generated API keys

  # Rate limiting per API key
  # Prevents abuse and ensures fair usage
  rate_limit_per_minute: 100  # Maximum requests per minute per key
  rate_limit_per_hour: 1000   # Maximum requests per hour per key

# Authentication endpoints (when auth.enabled: true):
# - POST /auth/login     - Login with username/password, returns JWT token
# - GET  /auth/me        - Get current user info (requires auth)
# - POST /auth/keys      - Create new API key (requires admin)
# - GET  /auth/keys      - List API keys for current user
# - DELETE /auth/keys/{id} - Revoke an API key

# Usage examples:
# 1. JWT Authentication:
#    curl -H "Authorization: Bearer <jwt_token>" http://localhost:15002/api/collections
#
# 2. API Key Authentication (header):
#    curl -H "Authorization: <api_key>" http://localhost:15002/api/collections
#
# 3. API Key Authentication (query parameter):
#    curl http://localhost:15002/api/collections?api_key=<api_key>

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================
security:
  # Rate limiting
  rate_limiting:
    enabled: true # Enable rate limiting
    requests_per_second: 100 # Requests per second per API key
    burst_size: 200 # Allow burst up to this size

  # TLS/mTLS
  tls:
    enabled: false # Enable TLS (requires certificate files)
    cert_path: "" # Path to TLS certificate
    key_path: "" # Path to TLS private key
    mtls_enabled: false # Enable mutual TLS (client certificates)
    client_ca_path: "" # Path to client CA certificate

  # Audit logging
  audit:
    enabled: true # Enable audit logging
    max_entries: 10000 # Maximum audit log entries in memory
    log_auth_attempts: true # Log all authentication attempts
    log_failed_requests: true # Log failed requests
    log_admin_actions: true # Log administrative actions

  # Role-Based Access Control (RBAC)
  rbac:
    enabled: false # Enable RBAC (requires role assignments)
    default_role: "Viewer" # Default role for new API keys
    # Available roles: Viewer, Editor, Admin
    # Viewer: Read-only access
    # Editor: Read/write access (no admin)
    # Admin: Full access including configuration

# =============================================================================
# STORAGE CONFIGURATION
# =============================================================================
storage:
  # Memory-Mapped File (MMap) storage configuration
  mmap:
    enabled: true # Enable MMAP storage for collections
    # When enabled, collections can use MMAP storage instead of in-memory
    # Benefits: Lower memory usage, persistence, larger dataset support
    # Trade-off: Slightly slower than pure in-memory storage
    default_for_new_collections: true # Use MMAP by default for new collections

  # Write-Ahead Log (WAL) configuration
  wal:
    enabled: true # Enable Write-Ahead Logging
    # WAL provides:
    # - Crash recovery
    # - Atomic operations
    # - Transaction support
    checkpoint_interval: 1000 # Checkpoint after N operations
    checkpoint_interval_secs: 300 # Checkpoint after N seconds (5 minutes)
    max_wal_size_mb: 100 # Maximum WAL file size before rotation
    wal_dir: "./data/wal" # Directory for WAL files

  # Product Quantization (PQ) configuration
  quantization:
    # Global PQ settings (can be overridden per collection)
    pq:
      enabled: true # Enable Product Quantization globally
      # PQ reduces memory usage by 75% with minimal quality loss
      # Collection-level PQ settings override global settings
      default_subquantizers: 8 # Default number of subquantizers
      default_centroids: 256 # Default number of centroids per subquantizer
      # PQ is recommended for:
      # - Large collections (>1M vectors)
      # - Memory-constrained environments
      # - Collections where slight quality loss is acceptable

  # Sharding configuration
  sharding:
    enabled: true # Enable distributed sharding globally
    # Sharding distributes collections across multiple shards for:
    # - Horizontal scaling
    # - Better performance with large datasets
    # - Load distribution
    default_shard_count: 4 # Default number of shards for new collections
    default_virtual_nodes: 100 # Default virtual nodes per shard (consistent hashing)
    default_rebalance_threshold: 0.2 # Default rebalance threshold (20% deviation)
    # Sharding can be enabled per-collection in CollectionConfig
    # When enabled globally, all new collections use sharding by default

# =============================================================================
# REPLICATION CONFIGURATION (Master-Replica Architecture)
# =============================================================================
replication:
  # Enable/disable replication
  enabled: false

  # Node role in replication topology
  # - standalone: No replication (default)
  # - master: Accepts writes, replicates to replicas
  # - replica: Read-only, receives from master
  role: "standalone"

  # Master node settings (role=master)
  # bind_address: "0.0.0.0:7001"  # TCP address for replicas to connect

  # Replica node settings (role=replica)
  # master_address: "127.0.0.1:7001"  # Master address to connect to

  # Heartbeat interval (seconds)
  heartbeat_interval_secs: 5

  # Replica timeout (seconds)
  # Replicas are disconnected if no heartbeat received within this time
  replica_timeout_secs: 30

  # Replication log size (number of operations)
  # Circular buffer for incremental sync (Redis-style)
  # Default: 1M operations (~240MB for typical operations)
  log_size: 1000000

  # Auto-reconnect interval for replicas (seconds)
  reconnect_interval_secs: 5
# =============================================================================
# REPLICATION EXAMPLES
# =============================================================================
#
# Example 1: Master Configuration
# --------------------------------
# replication:
#   enabled: true
#   role: "master"
#   bind_address: "0.0.0.0:7001"
#   heartbeat_interval_secs: 5
#   log_size: 1000000
#
# Example 2: Replica Configuration
# ---------------------------------
# replication:
#   enabled: true
#   role: "replica"
#   master_address: "192.168.1.10:7001"
#   reconnect_interval_secs: 5
#
# Example 3: Docker Compose Deployment
# -------------------------------------
# services:
#   vectorizer-master:
#     image: vectorizer:latest
#     environment:
#       - REPLICATION_ROLE=master
#       - REPLICATION_BIND_ADDRESS=0.0.0.0:7001
#     ports:
#       - "15002:15002"  # REST API
#       - "7001:7001"    # Replication
#
#   vectorizer-replica-1:
#     image: vectorizer:latest
#     environment:
#       - REPLICATION_ROLE=replica
#       - REPLICATION_MASTER_ADDRESS=vectorizer-master:7001
#     ports:
#       - "15003:15002"
#
# For more information, see docs/REPLICATION.md

# =============================================================================
# HIVEHUB CLOUD INTEGRATION (Multi-Tenant Cluster Mode)
# =============================================================================
# HiveHub integration enables Vectorizer to operate as a managed service
# through HiveHub.Cloud with proper user isolation, authentication,
# quota management, and usage tracking.
#
# In cluster mode, the Vectorizer runs locally and HiveHub handles all
# external authentication. Internal requests from HiveHub use the
# x-hivehub-service header to bypass authentication.

hub:
  # Enable/disable HiveHub integration
  # When enabled, the server integrates with HiveHub.Cloud for multi-tenancy
  enabled: true

  # HiveHub API URL
  # Can also be set via HIVEHUB_API_URL environment variable
  api_url: "http://localhost:12000"

  # Service API key for server-to-hub communication
  # IMPORTANT: Set via HIVEHUB_SERVICE_API_KEY environment variable in production!
  # This key authenticates the Vectorizer server with HiveHub
  service_api_key: "test-service-key"  # Development key

  # Request timeout in seconds for HiveHub API calls
  timeout_seconds: 30

  # Number of retries for failed HiveHub API requests
  retries: 3

  # Usage reporting interval in seconds
  # Determines how often usage metrics are sent to HiveHub
  usage_report_interval: 300  # 5 minutes

  # Tenant isolation mode
  # Options:
  #   - none: No tenant isolation (single-tenant mode)
  #   - collection: Collection-level isolation with user_ prefix
  #   - storage: Full storage-level isolation with separate paths
  tenant_isolation: "collection"

  # Cache configuration for HiveHub API responses
  cache:
    enabled: true  # Enable caching to reduce API calls
    api_key_ttl_seconds: 300  # API key validation cache TTL (5 minutes)
    quota_ttl_seconds: 60  # Quota cache TTL (1 minute)
    max_entries: 10000  # Maximum cached entries

  # Connection pool configuration
  connection_pool:
    max_idle_per_host: 10  # Maximum idle connections per host
    pool_timeout_seconds: 30  # Pool timeout

# =============================================================================
# HIVEHUB INTEGRATION EXAMPLES
# =============================================================================
#
# Example 1: Basic HiveHub Integration
# ------------------------------------
# hub:
#   enabled: true
#   api_url: "https://api.hivehub.cloud"
#   tenant_isolation: "collection"
#
# # Set environment variable:
# # export HIVEHUB_SERVICE_API_KEY="your-service-api-key"
#
# Example 2: Development/Testing Setup
# ------------------------------------
# hub:
#   enabled: true
#   api_url: "http://localhost:3000"  # Local HiveHub instance
#   tenant_isolation: "none"
#   usage_report_interval: 60  # Faster reporting for testing
#
# Example 3: Production with Full Isolation
# -----------------------------------------
# hub:
#   enabled: true
#   api_url: "https://api.hivehub.cloud"
#   timeout_seconds: 10  # Lower timeout for production
#   retries: 5  # More retries for reliability
#   tenant_isolation: "storage"
#   cache:
#     enabled: true
#     api_key_ttl_seconds: 600  # Longer cache for production
#     quota_ttl_seconds: 120
#
# For more information, see docs/HUB_INTEGRATION.md
