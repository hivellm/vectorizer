[package]
name = "vectorizer"
version = "0.1.0"
edition = "2024"
authors = ["HiveLLM Contributors"]
description = "High-performance, in-memory vector database written in Rust"
license = "MIT"
repository = "https://github.com/hivellm/vectorizer"
keywords = ["vector-database", "semantic-search", "embeddings", "hnsw", "similarity-search"]
categories = ["database", "science"]

[dependencies]
# Core dependencies
tokio = { version = "1.40", features = ["full"] }
axum = "0.7"
tower = "0.5"
tower-http = { version = "0.6", features = ["cors", "trace"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
bincode = "1.3"

# Index and vector operations
hnsw_rs = "0.3"

# Linear algebra for basic matrix operations
ndarray = "0.15"

# Parallel processing
rayon = "1.10"
crossbeam = "0.8"
num_cpus = "1.16"

# Data structures
dashmap = "6.1"
parking_lot = "0.12"
once_cell = "1.19"
arc-swap = "1.7"

# Error handling and logging
anyhow = { version = "1.0", features = ["backtrace"] }
thiserror = "1.0"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# CLI
clap = { version = "4.5", features = ["derive"] }

# Compression and caching
lz4_flex = "0.11"
memmap2 = "0.9"
xxhash-rust = { version = "0.8", features = ["xxh3"] }

# Configuration
serde_yaml = "0.9"

# Date and time
chrono = { version = "0.4", features = ["serde"] }

# Optional ML dependencies
candle-core = { version = "0.9.1", optional = true }
candle-nn = { version = "0.9.1", optional = true }
candle-transformers = { version = "0.9.1", optional = true }
tokenizers = { version = "0.22.1", optional = true }
hf-hub = { version = "0.4.3", optional = true }

# ONNX Runtime for high-performance inference
ort = { version = "2.0.0-rc.10", optional = true, features = ["half"] }

# Additional serialization formats
arrow = { version = "54", optional = true }
parquet = { version = "54", optional = true }

[dev-dependencies]
criterion = { version = "0.5", features = ["html_reports"] }
proptest = "1.5"
tempfile = "3.13"
reqwest = { version = "0.12", features = ["json"] }
rand = "0.8"

[[bin]]
name = "benchmark_embeddings"
path = "benchmark/scripts/benchmark_embeddings.rs"

[[bin]]
name = "download_models"
path = "scripts/download_models.rs"

[[bench]]
name = "vector_store"
harness = false

[[bench]]
name = "throughput_benchmark"
harness = false

[features]
default = []
candle-core = ["dep:candle-core"]
candle-nn = ["dep:candle-nn"]
candle-transformers = ["dep:candle-transformers"]
tokenizers = ["dep:tokenizers"]
hf-hub = ["dep:hf-hub"]
ort = ["dep:ort"]
arrow = ["dep:arrow"]
parquet = ["dep:parquet", "arrow"]
real-models = [
    "tokenizers",
    "hf-hub"
]
onnx-models = [
    "ort",
    "tokenizers",
    "hf-hub"
]
candle-models = [
    "candle-core",
    "candle-nn",
    "candle-transformers",
    "tokenizers",
    "hf-hub"
]
full = ["real-models", "onnx-models", "arrow", "parquet"]
