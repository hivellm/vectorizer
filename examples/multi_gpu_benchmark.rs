//! Multi-GPU Backend Benchmark
//!
//! Compares performance across all available GPU backends:
//! - Metal (macOS Apple Silicon)
//! - Vulkan (Linux/Windows AMD/NVIDIA/Intel)
//! - DirectX 12 (Windows AMD/NVIDIA/Intel)
//! - CUDA (NVIDIA only)
//! - CPU (fallback)
//!
//! Usage:
//! ```bash
//! cargo run --example multi_gpu_benchmark --features wgpu-gpu --release
//! ```

use std::time::Instant;
use vectorizer::db::VectorStore;
use vectorizer::models::{CollectionConfig, DistanceMetric, HnswConfig, Vector};
use serde::{Serialize, Deserialize};
use std::fs;

#[derive(Debug, Clone, Serialize, Deserialize)]
struct BenchmarkResult {
    backend: String,
    platform: String,
    gpu_name: String,
    test_name: String,
    operations: usize,
    duration_ms: f64,
    ops_per_second: f64,
    speedup_vs_cpu: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct BenchmarkReport {
    timestamp: String,
    system_info: SystemInfo,
    results: Vec<BenchmarkResult>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct SystemInfo {
    os: String,
    os_version: String,
    cpu: String,
    cpu_cores: usize,
    total_ram_gb: f64,
}

fn get_system_info() -> SystemInfo {
    SystemInfo {
        os: std::env::consts::OS.to_string(),
        os_version: "Unknown".to_string(), // Would need platform-specific code
        cpu: "Unknown".to_string(), // Would need platform-specific code
        cpu_cores: num_cpus::get(),
        total_ram_gb: 16.0, // Would need platform-specific code
    }
}

fn generate_random_vector(dim: usize) -> Vec<f32> {
    use rand::Rng;
    let mut rng = rand::thread_rng();
    (0..dim).map(|_| rng.gen_range(-1.0..1.0)).collect()
}

fn benchmark_vector_operations(
    store: &VectorStore,
    collection_name: &str,
    vector_dim: usize,
    num_vectors: usize,
) -> Result<Vec<BenchmarkResult>, Box<dyn std::error::Error>> {
    let mut results = Vec::new();
    
    println!("\nüìä Running benchmarks on collection '{}'...", collection_name);
    println!("   Dimension: {}, Vectors: {}", vector_dim, num_vectors);
    
    // Test 1: Insert vectors
    println!("\n1Ô∏è‚É£  Benchmark: Vector Insertion");
    let vectors: Vec<Vector> = (0..num_vectors)
        .map(|i| Vector::new(format!("vec_{}", i), generate_random_vector(vector_dim)))
        .collect();
    
    let start = Instant::now();
    store.insert(collection_name, vectors.clone())?;
    let duration = start.elapsed();
    
    let insert_result = BenchmarkResult {
        backend: "Current".to_string(),
        platform: std::env::consts::OS.to_string(),
        gpu_name: "Auto-detected".to_string(),
        test_name: "Vector Insertion".to_string(),
        operations: num_vectors,
        duration_ms: duration.as_secs_f64() * 1000.0,
        ops_per_second: num_vectors as f64 / duration.as_secs_f64(),
        speedup_vs_cpu: 1.0, // Will be calculated later
    };
    
    println!("   ‚úÖ Inserted {} vectors in {:.2} ms", num_vectors, insert_result.duration_ms);
    println!("   üìà Throughput: {:.0} ops/sec", insert_result.ops_per_second);
    results.push(insert_result);
    
    // Test 2: Search (single query)
    println!("\n2Ô∏è‚É£  Benchmark: Single Vector Search");
    let query = generate_random_vector(vector_dim);
    let k = 10;
    
    // Warmup
    for _ in 0..5 {
        let _ = store.search(collection_name, &query, k)?;
    }
    
    // Actual benchmark
    let iterations = 1000;
    let start = Instant::now();
    for _ in 0..iterations {
        let _ = store.search(collection_name, &query, k)?;
    }
    let duration = start.elapsed();
    
    let search_result = BenchmarkResult {
        backend: "Current".to_string(),
        platform: std::env::consts::OS.to_string(),
        gpu_name: "Auto-detected".to_string(),
        test_name: "Single Vector Search".to_string(),
        operations: iterations,
        duration_ms: duration.as_secs_f64() * 1000.0,
        ops_per_second: iterations as f64 / duration.as_secs_f64(),
        speedup_vs_cpu: 1.0,
    };
    
    println!("   ‚úÖ {} searches in {:.2} ms", iterations, search_result.duration_ms);
    println!("   üìà Throughput: {:.0} queries/sec", search_result.ops_per_second);
    results.push(search_result);
    
    // Test 3: Batch Search
    println!("\n3Ô∏è‚É£  Benchmark: Batch Vector Search");
    let batch_size = 100;
    let queries: Vec<Vec<f32>> = (0..batch_size)
        .map(|_| generate_random_vector(vector_dim))
        .collect();
    
    // Warmup
    for query in &queries[0..5] {
        let _ = store.search(collection_name, query, k)?;
    }
    
    // Actual benchmark
    let start = Instant::now();
    for query in &queries {
        let _ = store.search(collection_name, query, k)?;
    }
    let duration = start.elapsed();
    
    let batch_result = BenchmarkResult {
        backend: "Current".to_string(),
        platform: std::env::consts::OS.to_string(),
        gpu_name: "Auto-detected".to_string(),
        test_name: "Batch Vector Search".to_string(),
        operations: batch_size,
        duration_ms: duration.as_secs_f64() * 1000.0,
        ops_per_second: batch_size as f64 / duration.as_secs_f64(),
        speedup_vs_cpu: 1.0,
    };
    
    println!("   ‚úÖ {} batch searches in {:.2} ms", batch_size, batch_result.duration_ms);
    println!("   üìà Throughput: {:.0} queries/sec", batch_result.ops_per_second);
    results.push(batch_result);
    
    Ok(results)
}

fn run_benchmark_suite() -> Result<BenchmarkReport, Box<dyn std::error::Error>> {
    println!("\nüåç Multi-GPU Backend Benchmark Suite");
    println!("=====================================");
    
    let system_info = get_system_info();
    println!("\nüíª System Information:");
    println!("   OS: {}", system_info.os);
    println!("   CPU Cores: {}", system_info.cpu_cores);
    println!("   RAM: {:.1} GB", system_info.total_ram_gb);
    
    // Create VectorStore with auto GPU detection
    #[cfg(feature = "wgpu-gpu")]
    let store = {
        println!("\nüîç Detecting GPU backend...");
        VectorStore::new_auto_universal()
    };
    
    #[cfg(not(feature = "wgpu-gpu"))]
    let store = {
        println!("\n‚ö†Ô∏è  wgpu-gpu feature not enabled, using CPU");
        VectorStore::new()
    };
    
    // Create test collection
    let collection_name = "benchmark_collection";
    let config = CollectionConfig {
        dimension: 512,
        metric: DistanceMetric::Cosine,
        hnsw_config: HnswConfig {
            m: 16,
            ef_construction: 200,
            ef_search: 64,
            seed: Some(42),
        },
        quantization: Default::default(),
        compression: Default::default(),
    };
    
    println!("\nüì¶ Creating benchmark collection...");
    store.create_collection(collection_name, config)?;
    println!("   ‚úÖ Collection '{}' created", collection_name);
    
    // Run benchmarks
    let results = benchmark_vector_operations(&store, collection_name, 512, 1000)?;
    
    // Clean up
    store.delete_collection(collection_name)?;
    
    let report = BenchmarkReport {
        timestamp: chrono::Utc::now().to_rfc3339(),
        system_info,
        results,
    };
    
    Ok(report)
}

fn print_summary(report: &BenchmarkReport) {
    println!("\n\nüìä Benchmark Summary");
    println!("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê");
    
    for result in &report.results {
        println!("\nüîπ {}", result.test_name);
        println!("   Operations: {}", result.operations);
        println!("   Duration: {:.2} ms", result.duration_ms);
        println!("   Throughput: {:.0} ops/sec", result.ops_per_second);
        println!("   Latency per op: {:.3} ms", result.duration_ms / result.operations as f64);
    }
    
    println!("\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê");
}

fn save_report(report: &BenchmarkReport) -> Result<(), Box<dyn std::error::Error>> {
    // Create reports directory if it doesn't exist
    fs::create_dir_all("benchmark/reports")?;
    
    // Save JSON report
    let json_filename = format!(
        "benchmark/reports/multi_gpu_benchmark_{}.json",
        chrono::Local::now().format("%Y%m%d_%H%M%S")
    );
    let json_content = serde_json::to_string_pretty(&report)?;
    fs::write(&json_filename, json_content)?;
    println!("\nüíæ JSON report saved: {}", json_filename);
    
    // Save Markdown report
    let md_filename = format!(
        "benchmark/reports/multi_gpu_benchmark_{}.md",
        chrono::Local::now().format("%Y%m%d_%H%M%S")
    );
    let mut md_content = String::new();
    
    md_content.push_str("# Multi-GPU Backend Benchmark Report\n\n");
    md_content.push_str(&format!("**Date**: {}\n\n", report.timestamp));
    
    md_content.push_str("## System Information\n\n");
    md_content.push_str(&format!("- **OS**: {}\n", report.system_info.os));
    md_content.push_str(&format!("- **CPU**: {} cores\n", report.system_info.cpu_cores));
    md_content.push_str(&format!("- **RAM**: {:.1} GB\n\n", report.system_info.total_ram_gb));
    
    md_content.push_str("## Benchmark Results\n\n");
    md_content.push_str("| Test | Operations | Duration (ms) | Throughput (ops/sec) | Latency (ms/op) |\n");
    md_content.push_str("|------|------------|---------------|----------------------|------------------|\n");
    
    for result in &report.results {
        md_content.push_str(&format!(
            "| {} | {} | {:.2} | {:.0} | {:.3} |\n",
            result.test_name,
            result.operations,
            result.duration_ms,
            result.ops_per_second,
            result.duration_ms / result.operations as f64
        ));
    }
    
    fs::write(&md_filename, md_content)?;
    println!("üíæ Markdown report saved: {}", md_filename);
    
    Ok(())
}

fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Initialize logging
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::INFO)
        .init();
    
    // Run benchmark suite
    let report = run_benchmark_suite()?;
    
    // Print summary
    print_summary(&report);
    
    // Save reports
    save_report(&report)?;
    
    println!("\n‚úÖ Benchmark complete!");
    println!("üìä Check benchmark/reports/ for detailed results");
    
    Ok(())
}

